{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirpaia/blenderbot/blob/main/blender_90m_with_double_sized_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SONwSWMp6qPv"
      },
      "source": [
        "# 0.Installing prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d-SZ_On6Kxg",
        "outputId": "92a4ddfe-51ba-4b25-d8e5-fa947cfc5951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 31 13:08:11 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P0    34W /  70W |  14214MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BegaSUz6iUz",
        "outputId": "f57961bc-723b-4d3b-cec5-e800f74f8404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SzGRXHQ6kDQ",
        "outputId": "919ae696-6da5-4538-d0d4-070885569ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWDakYmy6mIQ",
        "outputId": "e76b06ab-2996-475d-cc42-8e9832b4d978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.4.24)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.0.12)\n"
          ]
        }
      ],
      "source": [
        "mydrive_path = '/content/drive/MyDrive/colabs/blender-models/'\n",
        "# !pip uninstall -q parlai\n",
        "!pip install -q parlai\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIJEq9_r63hi"
      },
      "source": [
        "# 1. Preparing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R-fgBUdcPX5"
      },
      "source": [
        "## Genreal Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47u8M3RK65m_",
        "outputId": "e2a4f232-e633-499b-ea18-b3b8ab21b43f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:hello\tlabels:how are you\n",
            "text:good\tlabels:bye\tepisode_done:True\n",
            "\n",
            "text:hello\tlabels:how are you\n",
            "text:good\tlabels:bye\tepisode_done:True\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def transfer_list_of_turns_to_dialog(d):\n",
        "    if len(d)%2 !=0: d = d[:-1]\n",
        "    t = \"\"\n",
        "    for i in range(0,len(d),2):\n",
        "        u1 = d[i]\n",
        "        u2 = d[i+1]\n",
        "\n",
        "        if (i+2) != len(d):\n",
        "            t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\n\"\n",
        "        else:\n",
        "            t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\t\"+\"episode_done:True\"+\"\\n\"\n",
        "    return t\n",
        "\n",
        "def transfer_list_of_pairs_to_dialog(d):\n",
        "  t = \"\"\n",
        "  for i, text_label_pair in enumerate(d):\n",
        "    u1 = text_label_pair[0]\n",
        "    u2 = text_label_pair[1]\n",
        "\n",
        "    if i != (len(d) - 1):\n",
        "      t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\n\"\n",
        "    else:\n",
        "      t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\t\"+\"episode_done:True\"+\"\\n\"\n",
        "\n",
        "  return t\n",
        "\n",
        "def convert_parlai_format_to_list_of_turns(lines):\n",
        "    result = []\n",
        "    for line in lines:\n",
        "        text_label = line.split(\"\\t\")\n",
        "        result.append(text_label[0].replace(\"text:\", \"\"))\n",
        "        result.append(text_label[1].replace(\"labels:\", \"\").replace(\"\\n\",\"\"))\n",
        "    return result\n",
        "\n",
        "t = ['hello','how are you','good','bye','test']\n",
        "print(transfer_list_of_turns_to_dialog(t))\n",
        "\n",
        "t = [['hello','how are you'],['good','bye']]\n",
        "print(transfer_list_of_pairs_to_dialog(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIROa77CJtG9"
      },
      "outputs": [],
      "source": [
        "# def make_dataset_double_sided(lines, path, filename): \n",
        "#     # train[:10]\n",
        "#     all_dialogs_parlai_format = []\n",
        "#     dialog = []\n",
        "#     for line in lines:\n",
        "#         dialog.append(line)\n",
        "#         if 'episode_done:True' in line:\n",
        "#             turns = convert_parlai_format_to_list_of_turns(dialog)\n",
        "#             first_parlai_dialog = transfer_list_of_turns_to_dialog(turns)\n",
        "#             second_parlai_dialog = transfer_list_of_turns_to_dialog(turns[1:])\n",
        "\n",
        "#             all_dialogs_parlai_format.append(first_parlai_dialog)\n",
        "#             all_dialogs_parlai_format.append(second_parlai_dialog)\n",
        "\n",
        "#             dialog = []\n",
        "#             # break\n",
        "\n",
        "#     print(len(all_dialogs_parlai_format))\n",
        "\n",
        "#     with open(f\"{path}{filename}\", \"w\") as f:\n",
        "#         f.writelines(all_dialogs_parlai_format[:10])\n",
        "\n",
        "# !mkdir /content/dataset_french_bst/\n",
        "# make_dataset_double_sided(lines,\"/content/dataset_french_bst/\", \"train.txt\")\n",
        "\n",
        "\n",
        "\n",
        "# # import os.path\n",
        "# # from os import path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE45ZyKC8WjC"
      },
      "source": [
        "## XPersona"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZmSJtQG8Y1o",
        "outputId": "301e38b8-aa3b-44d5-bbb5-54a42c41a43c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Xpersona' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HLTCHKUST/Xpersona.git\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "with open('Xpersona/dataset/Fr_persona_train_corrected.json','r') as f:\n",
        "   train_data = json.load(f)\n",
        "\n",
        "dialogs_train = pd.DataFrame(train_data)['dialogue'].tolist()\n",
        "\n",
        "with open('Xpersona/dataset/Fr_persona_split_valid_human_annotated.json','r') as f:\n",
        "   valid_data = json.load(f)\n",
        "\n",
        "dialogs_valid = pd.DataFrame(valid_data)['dialogue'].tolist()\n",
        "\n",
        "with open('Xpersona/dataset/Fr_persona_split_test_human_annotated.json','r') as f:\n",
        "   test_data = json.load(f)\n",
        "\n",
        "dialogs_test = pd.DataFrame(test_data)['dialogue'].tolist()\n",
        "\n",
        "# dialogs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plw61KMBJU4I",
        "outputId": "7a0f8ee4-a06d-4613-a988-c7015da1da48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33756\n",
            "496\n",
            "498\n"
          ]
        }
      ],
      "source": [
        "data_path = \"/content/dataset_french_xpersona/\"\n",
        "!rm -R $data_path\n",
        "!mkdir $data_path\n",
        "\n",
        "def convert_xpersona_dialogs_to_parlai_format_file_and_double_sided(dialogs, filename):\n",
        "    all_dialogs_parlai_format = []\n",
        "    import numpy as np\n",
        "    for d in dialogs:\n",
        "        turns = np.reshape(d, (-1)).tolist()\n",
        "        all_dialogs_parlai_format.append(transfer_list_of_turns_to_dialog(turns))\n",
        "        all_dialogs_parlai_format.append(transfer_list_of_turns_to_dialog(turns[1:]))\n",
        "\n",
        "    print(len(all_dialogs_parlai_format))\n",
        "\n",
        "    with open(f\"{data_path}{filename}\",\"w\") as f:\n",
        "        f.writelines(all_dialogs_parlai_format)\n",
        "\n",
        "convert_xpersona_dialogs_to_parlai_format_file_and_double_sided(dialogs_train, \"train.txt\")\n",
        "convert_xpersona_dialogs_to_parlai_format_file_and_double_sided(dialogs_valid, \"valid.txt\")\n",
        "convert_xpersona_dialogs_to_parlai_format_file_and_double_sided(dialogs_test, \"test.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "wKlGi0f08zQc"
      },
      "outputs": [],
      "source": [
        "# data_path = \"/content/dataset_french_xpersona/\"\n",
        "# !rm -R $data_path\n",
        "# !mkdir $data_path\n",
        "\n",
        "# #region Training\n",
        "# data_train = \"\"\n",
        "# for d in dialogs_train:\n",
        "#   data_train += transfer_list_of_pairs_to_dialog(d)\n",
        "\n",
        "# file_train = open(f\"{data_path}train.txt\",\"w\")\n",
        "# print(\"Training Set:\", file_train.write(data_train))\n",
        "# #endregion \n",
        "    \n",
        "# #region Validation\n",
        "# data_valid = \"\"\n",
        "# for d in dialogs_valid:\n",
        "#   data_valid += transfer_list_of_pairs_to_dialog(d)\n",
        "\n",
        "# file_valid = open(f\"{data_path}valid.txt\",\"w\")\n",
        "# print(\"Validation Set:\", file_valid.write(data_valid))\n",
        "# #endregion\n",
        "\n",
        "# #region Test\n",
        "# data_test = \"\"\n",
        "# for d in dialogs_test:\n",
        "#   data_test += transfer_list_of_pairs_to_dialog(d)\n",
        "\n",
        "# file_test = open(f\"{data_path}test.txt\",\"w\")\n",
        "# print(\"Test Set:\", file_test.write(data_test))\n",
        "# #endregion \n",
        "\n",
        "# # print(len(data_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoSv5zhs8ZIv"
      },
      "source": [
        "## ED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mISEjZbP8dN-",
        "outputId": "84454aeb-d6d0-44c6-d45f-9c77a581f29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_empathetic_dialogues/test.txt' -> '/content/dataset_french_ed/test.txt'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_empathetic_dialogues/train.txt' -> '/content/dataset_french_ed/train.txt'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_empathetic_dialogues/valid.txt' -> '/content/dataset_french_ed/valid.txt'\n"
          ]
        }
      ],
      "source": [
        "googledrive_data_path = \"/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_empathetic_dialogues/\"\n",
        "data_path = \"/content/dataset_french_ed/\"\n",
        "!rm -R $data_path\n",
        "!mkdir $data_path\n",
        "!cp -rv $googledrive_data_path* $data_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNbq22L-Khmg",
        "outputId": "7183e24f-74a6-4386-c421-51b755e362c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64636\n",
            "39057 5537 5093 49687\n"
          ]
        }
      ],
      "source": [
        "# with open(f\"{googledrive_data_path}train.txt\") as f:\n",
        "#     train = f.readlines()\n",
        "\n",
        "# with open(f\"{googledrive_data_path}valid.txt\") as f:\n",
        "#     valid = f.readlines()\n",
        "\n",
        "# with open(f\"{googledrive_data_path}test.txt\") as f:\n",
        "#     test = f.readlines()\n",
        "\n",
        "\n",
        "# print(len(train))\n",
        "# a, b, c = sum([1 for a in train if 'episode_done:True' in a]), sum([1 for a in valid if 'episode_done:True' in a]), sum([1 for a in test if 'episode_done:True' in a])\n",
        "# print(a,b,c,a+b+c)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUxXs_Oe8dda"
      },
      "source": [
        "## BST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIRVhsq88e7A",
        "outputId": "0fda82f2-9617-40ec-8cc6-4f5da4a1817b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/test.txt' -> '/content/dataset_french_bst/test.txt'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/train.txt' -> '/content/dataset_french_bst/train.txt'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/valid.txt' -> '/content/dataset_french_bst/valid.txt'\n"
          ]
        }
      ],
      "source": [
        "googledrive_data_path = \"/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/\"\n",
        "data_path = \"/content/dataset_french_bst/\"\n",
        "!rm -R $data_path\n",
        "!mkdir $data_path\n",
        "!cp -rv $googledrive_data_path* $data_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuQo9hiTRT0Y",
        "outputId": "cff15949-eca5-4971-9bbf-0c9e31157abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59700\n",
            "9638 2018 1958 13614\n"
          ]
        }
      ],
      "source": [
        "googledrive_data_path = \"/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/\"\n",
        "with open(f\"{googledrive_data_path}train.txt\") as f:\n",
        "    train = f.readlines()\n",
        "\n",
        "with open(f\"{googledrive_data_path}valid.txt\") as f:\n",
        "    valid = f.readlines()\n",
        "\n",
        "with open(f\"{googledrive_data_path}test.txt\") as f:\n",
        "    test = f.readlines()\n",
        "\n",
        "\n",
        "print(len(train))\n",
        "a, b, c = sum([1 for a in train if 'episode_done:True' in a]), sum([1 for a in valid if 'episode_done:True' in a]), sum([1 for a in test if 'episode_done:True' in a])\n",
        "print(a, b, c, a+b+c)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PQfT57Q8I2u"
      },
      "source": [
        "# 2. Creating new Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oVPKrhO8ISe",
        "outputId": "a241569b-9f84-4a92-912f-fcf71fa934b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/agents.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/agents.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/build.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/build.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/__init__.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/__init__.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/LICENSE_DOCUMENTATION' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/LICENSE_DOCUMENTATION'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/README.md' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/README.md'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test/empathetic_dialogues_test.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test/empathetic_dialogues_test.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test/empathetic_dialogues_train.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test/empathetic_dialogues_train.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test/empathetic_dialogues_valid.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test/empathetic_dialogues_valid.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/worlds.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/worlds.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/agents.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/agents.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/build.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/build.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/__init__.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/__init__.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/LICENSE_DOCUMENTATION' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/LICENSE_DOCUMENTATION'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/README.md' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/README.md'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test/empathetic_dialogues_test.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test/empathetic_dialogues_test.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test/empathetic_dialogues_train.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test/empathetic_dialogues_train.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test/empathetic_dialogues_valid.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test/empathetic_dialogues_valid.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/worlds.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/worlds.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/agents.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/agents.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/build.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/build.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/__init__.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/__init__.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/LICENSE_DOCUMENTATION' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/LICENSE_DOCUMENTATION'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/README.md' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/README.md'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test/empathetic_dialogues_test.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test/empathetic_dialogues_test.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test/empathetic_dialogues_train.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test/empathetic_dialogues_train.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test/empathetic_dialogues_valid.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test/empathetic_dialogues_valid.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/worlds.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/worlds.py'\n"
          ]
        }
      ],
      "source": [
        "#region XPersona\n",
        "task_path = \"/usr/local/lib/python3.7/dist-packages/parlai/tasks/\"\n",
        "\n",
        "!rm -R $task_path'french_xpersona/'\n",
        "!mkdir $task_path'french_xpersona'\n",
        "!cp -ruv /content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/* $task_path'french_xpersona/'\n",
        "#endregion\n",
        "\n",
        "\n",
        "#region ED\n",
        "task_path = \"/usr/local/lib/python3.7/dist-packages/parlai/tasks/\"\n",
        "\n",
        "!rm -R $task_path'french_empathetic_dialogues/'\n",
        "!mkdir $task_path'french_empathetic_dialogues'\n",
        "!cp -ruv /content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/* $task_path'french_empathetic_dialogues/'\n",
        "#endregion\n",
        "\n",
        "\n",
        "#region BST\n",
        "task_path = \"/usr/local/lib/python3.7/dist-packages/parlai/tasks/\"\n",
        "\n",
        "!rm -R $task_path'french_blended_skill_talk/'\n",
        "!mkdir $task_path'french_blended_skill_talk'\n",
        "!cp -ruv /content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/* $task_path'french_blended_skill_talk/'\n",
        "#endregion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGoTqdFD7x_3"
      },
      "source": [
        "# 3. Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "65rK6pfj70Px",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9728311-2c9d-4dc5-b250-4e53497d1049"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "finetuned_model_path = f'{mydrive_path}finetuned-multitask-400m-double-sided'\n",
        "init_model = 'zoo:blender/blender_400Mdistill/model'\n",
        "dict_file  = 'zoo:blender/blender_400Mdistill/model.dict'\n",
        "finetuned_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zArppuSCGS7"
      },
      "outputs": [],
      "source": [
        "# !mkdir copied_dataset_french_bst\n",
        "# !cp dataset_french_bst/* copied_dataset_french_bst\n",
        "# !mv copied_dataset_french_bst/test.txt copied_dataset_french_bst/_test.txt\n",
        "# !mv copied_dataset_french_bst/train.txt copied_dataset_french_bst/_train.txt\n",
        "# !mv copied_dataset_french_bst/valid.txt copied_dataset_french_bst/_valid.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7vLiYpF8HbF"
      },
      "outputs": [],
      "source": [
        "# 90M settings\n",
        "# !rm -rf $finetuned_model_path\n",
        "!mkdir -p $finetuned_model_path\n",
        "\n",
        "\n",
        "from parlai.scripts.train_model import TrainModel\n",
        "\n",
        "TrainModel.main(\n",
        "    # task\n",
        "    task= \"french_blended_skill_talk,french_xpersona,french_empathetic_dialogues\",\n",
        "    multitask_weights= \"1,3,3\",\n",
        "\n",
        "    # task='fromfile:parlaiformat', \n",
        "    # fromfile_datapath='copied_dataset_french_bst/',\n",
        "    # fromfile_datatype_extension=True,\n",
        "\n",
        "    model='transformer/generator',\n",
        "    model_file= f'{finetuned_model_path}/model',\n",
        "    \n",
        "    # initialize with a pretrained model\n",
        "    init_model= init_model,\n",
        "    dict_file=dict_file,\n",
        "    \n",
        "    # arguments we get from the pretrained model.\n",
        "    # Unfortunately, these must be looked up separately for each model.\n",
        "    n_heads=16, n_layers=8, n_positions=512, text_truncate=512,\n",
        "    label_truncate=128, ffn_size=2048, embedding_size=512,\n",
        "    activation='gelu', variant='xlm',\n",
        "    dict_lower=True, dict_tokenizer='bpe',\n",
        "    \n",
        "    # depend on your gpu. \n",
        "    validation_every_n_epochs=0.25,\n",
        "    num_epochs = 5,\n",
        "    log_every_n_secs= 60,\n",
        "    verbose = True,\n",
        "    batchsize= 8, \n",
        "    fp16= True, fp16_impl= \"mem_efficient\",\n",
        "    \n",
        "    # arguments we get from the pretrained model.\n",
        "    \n",
        "    # speeds up validation\n",
        "    skip_generation=True,\n",
        "    vp= 10,\n",
        "    validation_metric= \"ppl\", #vmt = \"ppl\"\n",
        "    validation_metric_mode= \"min\", # vmm= \"min\"\n",
        "    \n",
        "    # helps us cram more examples into our gpu at a time\n",
        "    dynamic_batching='full',\n",
        "\n",
        "    \n",
        "    # some training arguments, specific to this fine-tuning\n",
        "    lr=1e-5, optimizer='adam',\n",
        "    attention_dropout= 0.0, \n",
        "    model_parallel= False,\n",
        "    warmup_updates=100,\n",
        "\n",
        "    # customized parameters\n",
        "    # inference= \"beam\"\n",
        "    # beam_min_length= 20,\n",
        "    # beam_block_ngram= 3,\n",
        "    # beam_context_block_ngram= 3,\n",
        "    # beam_size= 10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mydrive_path = '/content/finetuned-multitask-400m-double-sided-2epochs'\n",
        "# mydrive_path = '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/'"
      ],
      "metadata": {
        "id": "mxL0-1x1YsQe"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jNZE5ta2pO-X",
        "outputId": "2d3d2688-7d84-42d8-f987-ac902c21d368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16:13:43 | building dictionary first...\n",
            "16:13:43 | \u001b[33mOverriding opt[\"multitask_weights\"] to (1.0, 3.0, 3.0) (previously: [1.0, 3.0, 3.0])\u001b[0m\n",
            "16:13:43 | \u001b[33mOverriding opt[\"model_file\"] to /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model (previously: /content/finetuned-multitask-400m-double-sided/model)\u001b[0m\n",
            "16:13:43 | \u001b[33mOverriding opt[\"init_model\"] to zoo:blender/blender_400Mdistill/model (previously: /content/finetuned-multitask-400m-double-sided/model.checkpoint)\u001b[0m\n",
            "16:13:43 | \u001b[33mOverriding opt[\"dict_file\"] to /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_400Mdistill/model.dict (previously: /content/finetuned-multitask-400m-double-sided/model.checkpoint.dict)\u001b[0m\n",
            "16:13:43 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: verbose: True,download_path: None,datapath: /usr/local/lib/python3.7/dist-packages/data,load_from_checkpoint: True,interactive_mode: False\u001b[0m\n",
            "16:13:43 | Using CUDA\n",
            "16:13:43 | loading dictionary from /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.checkpoint.dict\n",
            "16:13:43 | num words = 8008\n",
            "16:13:50 | Total parameters: 364,802,560 (364,474,880 trainable)\n",
            "16:13:50 | Loading existing model params from /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.checkpoint\n",
            "16:14:06 | Opt:\n",
            "16:14:06 |     activation: gelu\n",
            "16:14:06 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "16:14:06 |     adam_eps: 1e-08\n",
            "16:14:06 |     add_p1_after_newln: False\n",
            "16:14:06 |     aggregate_micro: False\n",
            "16:14:06 |     allow_missing_init_opts: False\n",
            "16:14:06 |     attention_dropout: 0.0\n",
            "16:14:06 |     batchsize: 16\n",
            "16:14:06 |     beam_block_full_context: True\n",
            "16:14:06 |     beam_block_list_filename: None\n",
            "16:14:06 |     beam_block_ngram: -1\n",
            "16:14:06 |     beam_context_block_ngram: -1\n",
            "16:14:06 |     beam_delay: 30\n",
            "16:14:06 |     beam_length_penalty: 0.65\n",
            "16:14:06 |     beam_min_length: 1\n",
            "16:14:06 |     beam_size: 1\n",
            "16:14:06 |     betas: '[0.9, 0.999]'\n",
            "16:14:06 |     bpe_add_prefix_space: None\n",
            "16:14:06 |     bpe_debug: False\n",
            "16:14:06 |     bpe_dropout: None\n",
            "16:14:06 |     bpe_merge: /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.checkpoint.dict-merges.txt\n",
            "16:14:06 |     bpe_vocab: /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.checkpoint.dict-vocab.json\n",
            "16:14:06 |     checkpoint_activations: False\n",
            "16:14:06 |     compute_tokenized_bleu: False\n",
            "16:14:06 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "16:14:06 |     datatype: train\n",
            "16:14:06 |     delimiter: '  '\n",
            "16:14:06 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "16:14:06 |     dict_endtoken: __end__\n",
            "16:14:06 |     dict_file: /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.checkpoint.dict\n",
            "16:14:06 |     dict_include_test: False\n",
            "16:14:06 |     dict_include_valid: False\n",
            "16:14:06 |     dict_initpath: None\n",
            "16:14:06 |     dict_language: english\n",
            "16:14:06 |     dict_loaded: True\n",
            "16:14:06 |     dict_lower: False\n",
            "16:14:06 |     dict_max_ngram_size: -1\n",
            "16:14:06 |     dict_maxexs: -1\n",
            "16:14:06 |     dict_maxtokens: -1\n",
            "16:14:06 |     dict_minfreq: 0\n",
            "16:14:06 |     dict_nulltoken: __null__\n",
            "16:14:06 |     dict_starttoken: __start__\n",
            "16:14:06 |     dict_textfields: text,labels\n",
            "16:14:06 |     dict_tokenizer: bytelevelbpe\n",
            "16:14:06 |     dict_unktoken: __unk__\n",
            "16:14:06 |     display_examples: False\n",
            "16:14:06 |     download_path: None\n",
            "16:14:06 |     dropout: 0.1\n",
            "16:14:06 |     dynamic_batching: None\n",
            "16:14:06 |     embedding_projection: random\n",
            "16:14:06 |     embedding_size: 1280\n",
            "16:14:06 |     embedding_type: random\n",
            "16:14:06 |     embeddings_scale: True\n",
            "16:14:06 |     eval_batchsize: None\n",
            "16:14:06 |     eval_dynamic_batching: None\n",
            "16:14:06 |     evaltask: None\n",
            "16:14:06 |     ffn_size: 5120\n",
            "16:14:06 |     final_extra_opt: \n",
            "16:14:06 |     force_fp16_tokens: True\n",
            "16:14:06 |     fp16: True\n",
            "16:14:06 |     fp16_impl: mem_efficient\n",
            "16:14:06 |     gpu: -1\n",
            "16:14:06 |     gradient_clip: 0.1\n",
            "16:14:06 |     hide_labels: False\n",
            "16:14:06 |     history_add_global_end_token: end\n",
            "16:14:06 |     history_reversed: False\n",
            "16:14:06 |     history_size: -1\n",
            "16:14:06 |     image_cropsize: 224\n",
            "16:14:06 |     image_mode: raw\n",
            "16:14:06 |     image_size: 256\n",
            "16:14:06 |     inference: greedy\n",
            "16:14:06 |     init_model: /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.checkpoint\n",
            "16:14:06 |     init_opt: None\n",
            "16:14:06 |     interactive_mode: False\n",
            "16:14:06 |     invsqrt_lr_decay_gamma: -1\n",
            "16:14:06 |     is_debug: False\n",
            "16:14:06 |     label_truncate: 128\n",
            "16:14:06 |     learn_positional_embeddings: False\n",
            "16:14:06 |     learningrate: 7e-06\n",
            "16:14:06 |     load_from_checkpoint: True\n",
            "16:14:06 |     log_every_n_secs: 60.0\n",
            "16:14:06 |     log_every_n_steps: 50\n",
            "16:14:06 |     log_keep_fields: all\n",
            "16:14:06 |     loglevel: info\n",
            "16:14:06 |     lr_scheduler: reduceonplateau\n",
            "16:14:06 |     lr_scheduler_decay: 0.5\n",
            "16:14:06 |     lr_scheduler_patience: 3\n",
            "16:14:06 |     max_train_steps: -1\n",
            "16:14:06 |     max_train_time: -1\n",
            "16:14:06 |     metrics: default\n",
            "16:14:06 |     model: transformer/generator\n",
            "16:14:06 |     model_file: /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model\n",
            "16:14:06 |     model_parallel: False\n",
            "16:14:06 |     momentum: 0\n",
            "16:14:06 |     multitask_weights: '(1.0, 3.0, 3.0)'\n",
            "16:14:06 |     mutators: None\n",
            "16:14:06 |     n_decoder_layers: 12\n",
            "16:14:06 |     n_encoder_layers: 2\n",
            "16:14:06 |     n_heads: 32\n",
            "16:14:06 |     n_layers: 2\n",
            "16:14:06 |     n_positions: 128\n",
            "16:14:06 |     n_segments: 0\n",
            "16:14:06 |     nesterov: True\n",
            "16:14:06 |     no_cuda: False\n",
            "16:14:06 |     num_epochs: 5.0\n",
            "16:14:06 |     num_workers: 0\n",
            "16:14:06 |     nus: [0.7]\n",
            "16:14:06 |     optimizer: mem_eff_adam\n",
            "16:14:06 |     output_scaling: 1.0\n",
            "16:14:06 |     override: \"{'task': 'french_blended_skill_talk,french_xpersona,french_empathetic_dialogues', 'multitask_weights': (1.0, 3.0, 3.0), 'model': 'transformer/generator', 'model_file': '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model', 'init_model': 'zoo:blender/blender_400Mdistill/model', 'dict_file': '/usr/local/lib/python3.7/dist-packages/data/models/blender/blender_400Mdistill/model.dict', 'validation_every_n_epochs': 0.25, 'num_epochs': 5.0, 'log_every_n_secs': 60.0, 'verbose': True, 'attention_dropout': 0.0, 'batchsize': 16, 'fp16': True, 'fp16_impl': 'mem_efficient', 'embedding_size': 1280, 'ffn_size': 5120, 'variant': 'prelayernorm', 'n_heads': 32, 'n_positions': 128, 'n_encoder_layers': 2, 'n_decoder_layers': 12, 'label_truncate': 128, 'text_truncate': 128, 'truncate': 128, 'activation': 'gelu', 'history_add_global_end_token': 'end', 'delimiter': '  ', 'dict_tokenizer': 'bytelevelbpe', 'dropout': 0.1, 'learningrate': 7e-06, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'optimizer': 'mem_eff_adam', 'relu_dropout': 0.0, 'model_parallel': False, 'warmup_updates': 100, 'update_freq': 2, 'gradient_clip': 0.1, 'skip_generation': True, 'validation_patience': 10, 'validation_metric': 'ppl', 'validation_metric_mode': 'min'}\"\n",
            "16:14:06 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "16:14:06 |     person_tokens: False\n",
            "16:14:06 |     rank_candidates: False\n",
            "16:14:06 |     relu_dropout: 0.0\n",
            "16:14:06 |     save_after_valid: True\n",
            "16:14:06 |     save_every_n_secs: -1\n",
            "16:14:06 |     save_format: conversations\n",
            "16:14:06 |     share_word_embeddings: True\n",
            "16:14:06 |     short_final_eval: False\n",
            "16:14:06 |     skip_generation: True\n",
            "16:14:06 |     special_tok_lst: None\n",
            "16:14:06 |     split_lines: False\n",
            "16:14:06 |     starttime: May31_06-42\n",
            "16:14:06 |     task: french_blended_skill_talk,french_xpersona,french_empathetic_dialogues\n",
            "16:14:06 |     temperature: 1.0\n",
            "16:14:06 |     tensorboard_log: False\n",
            "16:14:06 |     tensorboard_logdir: None\n",
            "16:14:06 |     text_truncate: 128\n",
            "16:14:06 |     topk: 10\n",
            "16:14:06 |     topp: 0.9\n",
            "16:14:06 |     truncate: 128\n",
            "16:14:06 |     update_freq: 2\n",
            "16:14:06 |     use_reply: label\n",
            "16:14:06 |     validation_cutoff: 1.0\n",
            "16:14:06 |     validation_every_n_epochs: 0.25\n",
            "16:14:06 |     validation_every_n_secs: -1\n",
            "16:14:06 |     validation_every_n_steps: -1\n",
            "16:14:06 |     validation_max_exs: -1\n",
            "16:14:06 |     validation_metric: ppl\n",
            "16:14:06 |     validation_metric_mode: min\n",
            "16:14:06 |     validation_patience: 10\n",
            "16:14:06 |     validation_share_agent: False\n",
            "16:14:06 |     variant: prelayernorm\n",
            "16:14:06 |     verbose: True\n",
            "16:14:06 |     wandb_entity: None\n",
            "16:14:06 |     wandb_log: False\n",
            "16:14:06 |     wandb_name: None\n",
            "16:14:06 |     wandb_project: None\n",
            "16:14:06 |     warmup_rate: 0.0001\n",
            "16:14:06 |     warmup_updates: 100\n",
            "16:14:06 |     weight_decay: None\n",
            "16:14:06 |     world_logs: \n",
            "16:14:07 | creating task(s): french_blended_skill_talk,french_xpersona,french_empathetic_dialogues\n",
            "16:14:07 | Loading ParlAI text data: /content/dataset_french_bst/train.txt\n",
            "16:14:08 | Loading ParlAI text data: /content/dataset_french_xpersona/train.txt\n",
            "16:14:10 | Loading ParlAI text data: /content/dataset_french_ed/train.txt\n",
            "16:14:12 | training...\n",
            "16:14:44 | time:32s total_exs:1600 total_steps:50 epochs:0.00 time_left:35450s\n",
            "                                clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  \\\n",
            "   all                         170.8     1  1542  4831   .4844      79.95 50.15 1600             65536  5.269    .7689 34.39   \n",
            "   french_blended_skill_talk   251.3                     .7000      143.2        310                                   39.86   \n",
            "   french_empathetic_dialogues    70                     .1346      6.865        260                                   36.25   \n",
            "   french_xpersona               191                     .6184      89.77       1030                                   27.07   \n",
            "                                loss       lr  ltpb  ltps  ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  \\\n",
            "   all                           2.6 6.93e-06   496  1554 .002564      .0859  13.5      .4545         0                16724   \n",
            "   french_blended_skill_talk   2.638                            0          0 13.98      .4515         0                        \n",
            "   french_empathetic_dialogues 2.663                      .007692      .2577 14.34      .4402         0                        \n",
            "   french_xpersona               2.5                            0          0 12.19      .4718         0                        \n",
            "                                tpb  tps   ups  \n",
            "   all                         2037 6386 1.567  \n",
            "   french_blended_skill_talk                    \n",
            "   french_empathetic_dialogues                  \n",
            "   french_xpersona\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-42d10378ad5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mvp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mvalidation_metric\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"ppl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#vmt = \"ppl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mvalidation_metric_mode\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# vmm= \"min\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# customized parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_kwargs\u001b[0;34m(cls, kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_from_parser_and_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_from_parser_and_opt\u001b[0;34m(cls, opt, parser)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    998\u001b[0m         \"\"\"\n\u001b[1;32m    999\u001b[0m         \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_train_log\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m             \u001b[0;31m# we've already done what we need in these\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36mtrain_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0;31m# do one example / batch of examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                     \u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparley\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopTrainException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Stopping from {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/worlds.py\u001b[0m in \u001b[0;36mparley\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0magent_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0;31m# The agent acts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m             \u001b[0mbatch_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_observations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_act\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0;31m# We possibly execute this action in the world.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/worlds.py\u001b[0m in \u001b[0;36mbatch_act\u001b[0;34m(self, agent_idx, batch_observation)\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch_act'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0mbatch_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_observation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m             \u001b[0;31m# Store the actions locally in each world.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworlds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/torch_agent.py\u001b[0m in \u001b[0;36mbatch_act\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m   2231\u001b[0m         \u001b[0;31m# move to GPU if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2233\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gpu'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gpu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/torch_agent.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, dev)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 400M settings\n",
        "# !rm -rf $finetuned_model_path\n",
        "!mkdir -p $finetuned_model_path\n",
        "\n",
        "\n",
        "from parlai.scripts.train_model import TrainModel\n",
        "\n",
        "TrainModel.main(\n",
        "    # task\n",
        "    task= \"french_blended_skill_talk,french_xpersona,french_empathetic_dialogues\",\n",
        "    multitask_weights= \"1,3,3\",\n",
        "\n",
        "    # task='fromfile:parlaiformat', \n",
        "    # fromfile_datapath='copied_dataset_french_bst/',\n",
        "    # fromfile_datatype_extension=True,\n",
        "\n",
        "    model='transformer/generator',\n",
        "    model_file= f'{finetuned_model_path}/model',\n",
        "    \n",
        "    # initialize with a pretrained model\n",
        "    init_model= init_model,\n",
        "    dict_file=dict_file,\n",
        "    \n",
        "    # depend on your gpu\n",
        "    validation_every_n_epochs=0.25, # veps= 0.25, \n",
        "    num_epochs = 5,\n",
        "    log_every_n_secs= 60,\n",
        "    verbose = True,\n",
        "    attention_dropout= 0.0, \n",
        "    batchsize= 16, \n",
        "    fp16= True, fp16_impl= \"mem_efficient\",\n",
        "    # save_after_valid= True,\n",
        "\n",
        "    # arguments we get from the pretrained model. \"from recipes page for 2.7B model\" \n",
        "    embedding_size= 1280, ffn_size= 5120,\n",
        "    variant= \"prelayernorm\",\n",
        "    n_heads= 32, n_positions= 128, \n",
        "    n_encoder_layers= 2, n_decoder_layers= 12,\n",
        "\n",
        "    label_truncate= 128, text_truncate= 128, truncate= 128,\n",
        "    activation= \"gelu\",\n",
        "    history_add_global_end_token= \"end\", \n",
        "    delimiter= '  ', \n",
        "    dict_tokenizer= \"bytelevelbpe\",\n",
        "    dropout= 0.1,\n",
        "    \n",
        "    # some training arguments, specific to this fine-tuning\n",
        "    lr= 7e-06, lr_scheduler= \"reduceonplateau\", lr_scheduler_patience= 3,\n",
        "    optimizer= \"mem_eff_adam\",\n",
        "    relu_dropout= 0.0, \n",
        "    model_parallel= False,\n",
        "    warmup_updates= 100,\n",
        "    update_freq= 2,\n",
        "    gradient_clip= 0.1, \n",
        "\n",
        "    # speeds up validation\n",
        "    skip_generation= True,\n",
        "    vp= 10,\n",
        "    validation_metric= \"ppl\", #vmt = \"ppl\"\n",
        "    validation_metric_mode= \"min\", # vmm= \"min\"\n",
        "\n",
        "    # customized parameters\n",
        "    # inference = 'topk', \n",
        "    # temperature = 0.7, \n",
        "    # topk=30, \n",
        "    # beam_length_penalty=1.03\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -rv /content/finetuned-multitask-400m-double-sided-2epochs/* /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/\n",
        "# !ls -lah /content/finetuned-multitask-400m-double-sided-2epochs/\n",
        "# !ls -lah /content/finetuned-multitask-400m-double-sided/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1S0kRk3W63i",
        "outputId": "fa8ea32a-ba14-411b-b717-3eef213c33ab"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.checkpoint' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.checkpoint'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.checkpoint.dict' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.checkpoint.dict'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.checkpoint.dict-merges.txt' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.checkpoint.dict-merges.txt'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.checkpoint.dict.opt' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.checkpoint.dict.opt'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.checkpoint.dict-vocab.json' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.checkpoint.dict-vocab.json'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.checkpoint.opt' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.checkpoint.opt'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.checkpoint.trainstats' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.checkpoint.trainstats'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.dict' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.dict'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.dict-merges.txt' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.dict-merges.txt'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.dict.opt' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.dict.opt'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.dict-vocab.json' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.dict-vocab.json'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.opt' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.opt'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.test' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.test'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.trainstats' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.trainstats'\n",
            "'/content/finetuned-multitask-400m-double-sided-2epochs/model.valid' -> '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/model.valid'\n",
            "total 6.8G\n",
            "drwxr-xr-x 2 root root 4.0K May 31 15:54 .\n",
            "drwxr-xr-x 1 root root 4.0K May 31 13:50 ..\n",
            "-rw-r--r-- 1 root root 3.4G May 31 15:54 model\n",
            "-rw-r--r-- 1 root root 3.4G May 31 13:48 model.checkpoint\n",
            "-rw------- 1 root root  71K May 31 12:52 model.checkpoint.dict\n",
            "-rw------- 1 root root  62K May 31 12:52 model.checkpoint.dict-merges.txt\n",
            "-rw------- 1 root root 6.6K May 31 12:52 model.checkpoint.dict.opt\n",
            "-rw------- 1 root root 109K May 31 12:52 model.checkpoint.dict-vocab.json\n",
            "-rw------- 1 root root 4.6K May 31 13:48 model.checkpoint.opt\n",
            "-rw------- 1 root root 1.1M May 31 13:48 model.checkpoint.trainstats\n",
            "-rw------- 1 root root  71K May 31 12:52 model.dict\n",
            "-rw------- 1 root root  62K May 31 12:52 model.dict-merges.txt\n",
            "-rw------- 1 root root 6.4K May 31 12:52 model.dict.opt\n",
            "-rw------- 1 root root 109K May 31 12:52 model.dict-vocab.json\n",
            "-rw------- 1 root root 4.6K May 31 15:54 model.opt\n",
            "-rw------- 1 root root 1.2K May 31 12:52 model.test\n",
            "-rw------- 1 root root 1.7M May 31 15:54 model.trainstats\n",
            "-rw------- 1 root root 1.2K May 31 12:52 model.valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVPS6p4XzPh4"
      },
      "source": [
        "# 3. Display Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9FBtnZZzPPg",
        "outputId": "c2343265-c6b1-4870-8cc4-6c58863b76de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15:06:36 | \u001b[33mOverriding opt[\"task\"] to french_blended_skill_talk (previously: french_blended_skill_talk,french_xpersona,french_empathetic_dialogues)\u001b[0m\n",
            "15:06:36 | \u001b[33mOverriding opt[\"skip_generation\"] to False (previously: True)\u001b[0m\n",
            "15:06:36 | Using CUDA\n",
            "15:06:36 | loading dictionary from /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m-double-sided/model.dict\n",
            "15:06:36 | num words = 54944\n",
            "15:06:38 | Total parameters: 87,508,992 (86,984,704 trainable)\n",
            "15:06:38 | Loading existing model params from /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m-double-sided/model\n",
            "15:06:42 | creating task(s): french_blended_skill_talk\n",
            "15:06:42 | Loading ParlAI text data: /content/dataset_french_bst/valid.txt\n",
            "15:06:42 | Opt:\n",
            "15:06:42 |     activation: gelu\n",
            "15:06:42 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "15:06:42 |     adam_eps: 1e-08\n",
            "15:06:42 |     add_p1_after_newln: False\n",
            "15:06:42 |     aggregate_micro: False\n",
            "15:06:42 |     allow_missing_init_opts: False\n",
            "15:06:42 |     attention_dropout: 0.0\n",
            "15:06:42 |     batchsize: 8\n",
            "15:06:42 |     beam_block_full_context: True\n",
            "15:06:42 |     beam_block_list_filename: None\n",
            "15:06:42 |     beam_block_ngram: -1\n",
            "15:06:42 |     beam_context_block_ngram: -1\n",
            "15:06:42 |     beam_delay: 30\n",
            "15:06:42 |     beam_length_penalty: 0.65\n",
            "15:06:42 |     beam_min_length: 1\n",
            "15:06:42 |     beam_size: 1\n",
            "15:06:42 |     betas: '[0.9, 0.999]'\n",
            "15:06:42 |     bpe_add_prefix_space: None\n",
            "15:06:42 |     bpe_debug: False\n",
            "15:06:42 |     bpe_dropout: None\n",
            "15:06:42 |     bpe_merge: None\n",
            "15:06:42 |     bpe_vocab: None\n",
            "15:06:42 |     checkpoint_activations: False\n",
            "15:06:42 |     compute_tokenized_bleu: False\n",
            "15:06:42 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "15:06:42 |     datatype: train\n",
            "15:06:42 |     delimiter: '\\n'\n",
            "15:06:42 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "15:06:42 |     dict_endtoken: __end__\n",
            "15:06:42 |     dict_file: /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m-double-sided/model.dict\n",
            "15:06:42 |     dict_include_test: False\n",
            "15:06:42 |     dict_include_valid: False\n",
            "15:06:42 |     dict_initpath: None\n",
            "15:06:42 |     dict_language: english\n",
            "15:06:42 |     dict_loaded: True\n",
            "15:06:42 |     dict_lower: True\n",
            "15:06:42 |     dict_max_ngram_size: -1\n",
            "15:06:42 |     dict_maxexs: -1\n",
            "15:06:42 |     dict_maxtokens: -1\n",
            "15:06:42 |     dict_minfreq: 0\n",
            "15:06:42 |     dict_nulltoken: __null__\n",
            "15:06:42 |     dict_starttoken: __start__\n",
            "15:06:42 |     dict_textfields: text,labels\n",
            "15:06:42 |     dict_tokenizer: bpe\n",
            "15:06:42 |     dict_unktoken: __unk__\n",
            "15:06:42 |     display_add_fields: \n",
            "15:06:42 |     display_examples: False\n",
            "15:06:42 |     download_path: None\n",
            "15:06:42 |     dropout: 0.0\n",
            "15:06:42 |     dynamic_batching: full\n",
            "15:06:42 |     embedding_projection: random\n",
            "15:06:42 |     embedding_size: 512\n",
            "15:06:42 |     embedding_type: random\n",
            "15:06:42 |     embeddings_scale: True\n",
            "15:06:42 |     eval_batchsize: None\n",
            "15:06:42 |     eval_dynamic_batching: None\n",
            "15:06:42 |     evaltask: None\n",
            "15:06:42 |     ffn_size: 2048\n",
            "15:06:42 |     final_extra_opt: \n",
            "15:06:42 |     force_fp16_tokens: True\n",
            "15:06:42 |     fp16: True\n",
            "15:06:42 |     fp16_impl: mem_efficient\n",
            "15:06:42 |     gpu: -1\n",
            "15:06:42 |     gradient_clip: 0.1\n",
            "15:06:42 |     hide_labels: False\n",
            "15:06:42 |     history_add_global_end_token: None\n",
            "15:06:42 |     history_reversed: False\n",
            "15:06:42 |     history_size: -1\n",
            "15:06:42 |     image_cropsize: 224\n",
            "15:06:42 |     image_mode: raw\n",
            "15:06:42 |     image_size: 256\n",
            "15:06:42 |     inference: greedy\n",
            "15:06:42 |     init_model: /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model\n",
            "15:06:42 |     init_opt: None\n",
            "15:06:42 |     interactive_mode: False\n",
            "15:06:42 |     invsqrt_lr_decay_gamma: -1\n",
            "15:06:42 |     is_debug: False\n",
            "15:06:42 |     label_truncate: 128\n",
            "15:06:42 |     learn_positional_embeddings: False\n",
            "15:06:42 |     learningrate: 1e-05\n",
            "15:06:42 |     log_every_n_secs: 60.0\n",
            "15:06:42 |     log_every_n_steps: 50\n",
            "15:06:42 |     log_keep_fields: all\n",
            "15:06:42 |     loglevel: info\n",
            "15:06:42 |     lr_scheduler: reduceonplateau\n",
            "15:06:42 |     lr_scheduler_decay: 0.5\n",
            "15:06:43 |     lr_scheduler_patience: 3\n",
            "15:06:43 |     max_train_steps: -1\n",
            "15:06:43 |     max_train_time: -1\n",
            "15:06:43 |     metrics: default\n",
            "15:06:43 |     model: transformer/generator\n",
            "15:06:43 |     model_file: /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m-double-sided/model\n",
            "15:06:43 |     model_parallel: False\n",
            "15:06:43 |     momentum: 0\n",
            "15:06:43 |     multitask_weights: '[1.0, 3.0, 3.0]'\n",
            "15:06:43 |     mutators: None\n",
            "15:06:43 |     n_decoder_layers: -1\n",
            "15:06:43 |     n_encoder_layers: -1\n",
            "15:06:43 |     n_heads: 16\n",
            "15:06:43 |     n_layers: 8\n",
            "15:06:43 |     n_positions: 512\n",
            "15:06:43 |     n_segments: 0\n",
            "15:06:43 |     nesterov: True\n",
            "15:06:43 |     no_cuda: False\n",
            "15:06:43 |     num_epochs: 5.0\n",
            "15:06:43 |     num_examples: 20\n",
            "15:06:43 |     num_workers: 0\n",
            "15:06:43 |     nus: [0.7]\n",
            "15:06:43 |     optimizer: mem_eff_adam\n",
            "15:06:43 |     output_scaling: 1.0\n",
            "15:06:43 |     override: \"{'task': 'french_blended_skill_talk', 'model_file': '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m-double-sided/model', 'num_examples': '20', 'skip_generation': False}\"\n",
            "15:06:43 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "15:06:43 |     person_tokens: False\n",
            "15:06:43 |     rank_candidates: False\n",
            "15:06:43 |     relu_dropout: 0.0\n",
            "15:06:43 |     save_after_valid: False\n",
            "15:06:43 |     save_every_n_secs: -1\n",
            "15:06:43 |     save_format: conversations\n",
            "15:06:43 |     share_word_embeddings: True\n",
            "15:06:43 |     short_final_eval: False\n",
            "15:06:43 |     skip_generation: False\n",
            "15:06:43 |     special_tok_lst: None\n",
            "15:06:43 |     split_lines: False\n",
            "15:06:43 |     starttime: May25_08-36\n",
            "15:06:43 |     task: french_blended_skill_talk\n",
            "15:06:43 |     temperature: 1.0\n",
            "15:06:43 |     tensorboard_log: False\n",
            "15:06:43 |     tensorboard_logdir: None\n",
            "15:06:43 |     text_truncate: 512\n",
            "15:06:43 |     topk: 10\n",
            "15:06:43 |     topp: 0.9\n",
            "15:06:43 |     truncate: -1\n",
            "15:06:43 |     update_freq: 1\n",
            "15:06:43 |     use_reply: label\n",
            "15:06:43 |     validation_cutoff: 1.0\n",
            "15:06:43 |     validation_every_n_epochs: 0.25\n",
            "15:06:43 |     validation_every_n_secs: -1\n",
            "15:06:43 |     validation_every_n_steps: -1\n",
            "15:06:43 |     validation_max_exs: -1\n",
            "15:06:43 |     validation_metric: ppl\n",
            "15:06:43 |     validation_metric_mode: min\n",
            "15:06:43 |     validation_patience: 10\n",
            "15:06:43 |     validation_share_agent: False\n",
            "15:06:43 |     variant: xlm\n",
            "15:06:43 |     verbose: False\n",
            "15:06:43 |     wandb_entity: None\n",
            "15:06:43 |     wandb_log: False\n",
            "15:06:43 |     wandb_name: None\n",
            "15:06:43 |     wandb_project: None\n",
            "15:06:43 |     warmup_rate: 0.0001\n",
            "15:06:43 |     warmup_updates: 100\n",
            "15:06:43 |     weight_decay: None\n",
            "15:06:43 |     world_logs: \n",
            "\u001b[1;31m- - - NEW EPISODE: french_blended_skill_talk- - -\u001b[0;0m\n",
            "\u001b[0mCela semble dangereux. Cela vaut-il la peine de faire un travail aussi dangereux ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Wekk, c'est bon si vous êtes bien formé.  Il y a trois niveaux \u001b[0;0m\n",
            "\u001b[0;95m     model: oui , c ' est vrai . je ne sais pas si je peux m ' en empêcher .\u001b[0;0m\n",
            "\u001b[0mA quel niveau êtes-vous ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: J'ai reçu une formation sur le tas lorsque j'ai commencé à travailler.\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis un grand fan de la musique country .\u001b[0;0m\n",
            "\u001b[0mC'est génial ! Depuis combien de temps faites-vous ce travail ? \u001b[0;0m\n",
            "\u001b[1;94m    labels: Depuis un bon nombre d'années maintenant.\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis un étudiant de la marine .\u001b[0;0m\n",
            "\u001b[0mOn dirait que ça peut être un travail dangereux parfois.\u001b[0;0m\n",
            "\u001b[1;94m    labels: C'est vrai, surtout si vous ne prenez pas les mesures appropriées.\u001b[0;0m\n",
            "\u001b[0;95m     model: oui , c ' est vrai .\u001b[0;0m\n",
            "\u001b[0mEh bien, vous êtes entré dans un métier qui vous garantira toujours du travail.\u001b[0;0m\n",
            "\u001b[1;94m    labels: C'est vrai, surtout dans cette économie\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis un peu déçu , mais je suis un peu plus âgé que moi .\u001b[0;0m\n",
            "\u001b[0mJ'ai moi-même un emploi assez stable, mais surtout du travail de bureau.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Est-ce que ça vous plaît ?\u001b[0;0m\n",
            "\u001b[0;95m     model: c ' est bien , je suis content que tu aies pu être stable .\u001b[0;0m\n",
            "\u001b[0mJe le fais vraiment, mais parfois j'aimerais être plus actif et debout.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Je vous comprends. S'étirer le long des couloirs\u001b[0;0m\n",
            "\u001b[0;95m     model: c ' est bien , je suis sûr que vous vous êtes amusés .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: french_blended_skill_talk- - -\u001b[0;0m\n",
            "\u001b[0mWekk, c'est bon si vous êtes bien formé.  Il y a trois niveaux \u001b[0;0m\n",
            "\u001b[1;94m    labels: A quel niveau êtes-vous ?\u001b[0;0m\n",
            "\u001b[0;95m     model: oui , je suis un grand fan de la musique .\u001b[0;0m\n",
            "\u001b[0mJ'ai reçu une formation sur le tas lorsque j'ai commencé à travailler.\u001b[0;0m\n",
            "\u001b[1;94m    labels: C'est génial ! Depuis combien de temps faites-vous ce travail ? \u001b[0;0m\n",
            "\u001b[0;95m     model: c ' est génial . je suis sûr que vous avez __unk__ is à faire ça .\u001b[0;0m\n",
            "\u001b[0mDepuis un bon nombre d'années maintenant.\u001b[0;0m\n",
            "\u001b[1;94m    labels: On dirait que ça peut être un travail dangereux parfois.\u001b[0;0m\n",
            "\u001b[0;95m     model: c ' est génial ! je suis sûr que vous avez beaucoup de temps pour travailler .\u001b[0;0m\n",
            "\u001b[0mC'est vrai, surtout si vous ne prenez pas les mesures appropriées.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Eh bien, vous êtes entré dans un métier qui vous garantira toujours du travail.\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis d ' accord . je suis un peu déçu .\u001b[0;0m\n",
            "\u001b[0mC'est vrai, surtout dans cette économie\u001b[0;0m\n",
            "\u001b[1;94m    labels: J'ai moi-même un emploi assez stable, mais surtout du travail de bureau.\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis sûr que vous avez beaucoup de chance .\u001b[0;0m\n",
            "\u001b[0mEst-ce que ça vous plaît ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Je le fais vraiment, mais parfois j'aimerais être plus actif et debout.\u001b[0;0m\n",
            "\u001b[0;95m     model: oui , je suis un peu déçu .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: french_blended_skill_talk- - -\u001b[0;0m\n",
            "\u001b[0mJe me sens très bien dans ma relation avec mon partenaire. Mon partenaire apprécie mon opinion sur les choses.\u001b[0;0m\n",
            "\u001b[1;94m    labels: ok, si doux\u001b[0;0m\n",
            "\u001b[0;95m     model: c ' est bien . je suis sûr que tu es très fier de lui .\u001b[0;0m\n",
            "\u001b[0mEt vous, quelqu'un vers qui vous pouvez vous tourner ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Bien sûr, j'ai des amis avec qui je suis toujours libre de partager.\u001b[0;0m\n",
            "\u001b[0;95m     model: je ne suis pas sûr .\u001b[0;0m\n",
            "\u001b[0mJ'aime faire du vélo tout terrain avec mes amis.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Je n'ai jamais fait ça.  Je ne suis pas vraiment du genre à faire de l'activité physique, mais je serais prêt à essayer, j'imagine.\u001b[0;0m\n",
            "\u001b[0;95m     model: j ' aime aussi faire du vélo .\u001b[0;0m\n",
            "\u001b[0mJ'aime aussi aller prendre un thé à bulles, c'est tellement amusant.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Ça, c'est plus mon truc. Ça a un goût un peu étrange, mais j'aime ça.\u001b[0;0m\n",
            "\u001b[0;95m     model: je ne suis pas sûr de ce que vous aimez faire .\u001b[0;0m\n",
            "\u001b[0mExactement, c'est bizarre mais je continue à en redemander. Tellement étrange.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Oui, c'est juste une de ces choses. Une fois que vous commencez, vous ne pouvez plus vous arrêter.\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis sûr que vous avez __unk__ is à faire ça .\u001b[0;0m\n",
            "\u001b[0mY a-t-il quelque chose que vous aimez vraiment faire ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: J'aime me détendre avec des amis, boire un petit verre, ce genre de choses.\u001b[0;0m\n",
            "\u001b[0;95m     model: je ne suis pas sûr , mais je suis sûr que je vais faire ça .\u001b[0;0m\n",
            "\u001b[0mÇa semble être une chose assez cool à faire, je suis assez décontracté aussi.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Yea. Je veux dire, le monde bouge si vite, parfois vous devez juste prendre du recul et laisser le passé s'accomplir.\u001b[0;0m\n",
            "\u001b[0;95m     model: oui , c ' est vrai .\u001b[0;0m\n"
          ]
        }
      ],
      "source": [
        "from parlai.scripts.display_model import DisplayModel\n",
        "DisplayModel.main(\n",
        "    task='french_blended_skill_talk',\n",
        "    model_file= f'{finetuned_model_path}/model',\n",
        "    num_examples=20,\n",
        "    skip_generation=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap-cP0uzFF4y",
        "outputId": "d35ec469-4e4a-40ef-f059-ecad54e1ee19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12:46:14 | Opt:\n",
            "12:46:14 |     allow_missing_init_opts: False\n",
            "12:46:14 |     batchsize: 1\n",
            "12:46:14 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "12:46:14 |     datatype: train:ordered\n",
            "12:46:14 |     dict_class: None\n",
            "12:46:14 |     display_add_fields: \n",
            "12:46:14 |     download_path: None\n",
            "12:46:14 |     dynamic_batching: None\n",
            "12:46:14 |     fromfile_datapath: copied_dataset_french_bst/\n",
            "12:46:14 |     fromfile_datatype_extension: True\n",
            "12:46:14 |     hide_labels: False\n",
            "12:46:14 |     ignore_agent_reply: True\n",
            "12:46:14 |     image_cropsize: 224\n",
            "12:46:14 |     image_mode: raw\n",
            "12:46:14 |     image_size: 256\n",
            "12:46:14 |     init_model: None\n",
            "12:46:14 |     init_opt: None\n",
            "12:46:14 |     is_debug: False\n",
            "12:46:14 |     loglevel: info\n",
            "12:46:14 |     max_display_len: 1000\n",
            "12:46:14 |     model: None\n",
            "12:46:14 |     model_file: None\n",
            "12:46:14 |     multitask_weights: [1]\n",
            "12:46:14 |     mutators: None\n",
            "12:46:14 |     num_examples: 20\n",
            "12:46:14 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': 'copied_dataset_french_bst/', 'fromfile_datatype_extension': True, 'num_examples': 20}\"\n",
            "12:46:14 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "12:46:14 |     starttime: May24_12-46\n",
            "12:46:14 |     task: fromfile:parlaiformat\n",
            "12:46:14 |     verbose: False\n",
            "12:46:14 | creating task(s): fromfile:parlaiformat\n",
            "12:46:14 | Loading ParlAI text data: copied_dataset_french_bst/_train.txt\n",
            "\u001b[1;31m- - - NEW EPISODE: copied_dataset_french_bst/_train.txt - - -\u001b[0;0m\n",
            "\u001b[0mJ'aime la musique live, c'est pourquoi j'essaie d'aller aux concerts.\u001b[0;0m\n",
            "   \u001b[1;94mMoi aussi. Qu'est-ce que tu aimes ?\u001b[0;0m\n",
            "\u001b[0mJ'aime jouer la comédie, j'espère être un acteur, et vous ?\u001b[0;0m\n",
            "   \u001b[1;94mC'est bon. Vous avez des enfants ?\u001b[0;0m\n",
            "\u001b[0mNon, mais un jour.\u001b[0;0m\n",
            "   \u001b[1;94mc'est bien. J'ai 2\u001b[0;0m\n",
            "\u001b[0mLorsque j'aurai terminé mes études, je compte fonder une famille.\u001b[0;0m\n",
            "   \u001b[1;94mc'est génial ! tu seras prête\u001b[0;0m\n",
            "\u001b[0mJe l'espère, quel âge ont vos enfants ?\u001b[0;0m\n",
            "   \u001b[1;94m5 & 7. Ils me prennent beaucoup de temps.\u001b[0;0m\n",
            "\u001b[0mJ'imagine. Je suis sûr qu'ils sont de grands enfants.\u001b[0;0m\n",
            "   \u001b[1;94mheureusement, ils aiment les fleurs tout autant que moi. Nous passons beaucoup de temps dans le jardin.\u001b[0;0m\n",
            "\u001b[0mJ'aimerais avoir plus de temps pour faire ce genre de choses. L'école de médecine est épuisante. \u001b[0;0m\n",
            "   \u001b[1;94mOn dirait bien. As-tu trouvé un travail d'actrice, cependant ?\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: copied_dataset_french_bst/_train.txt - - -\u001b[0;0m\n",
            "\u001b[0mMoi aussi. Qu'est-ce que tu aimes ?\u001b[0;0m\n",
            "   \u001b[1;94mJ'aime jouer la comédie, j'espère être un acteur, et vous ?\u001b[0;0m\n",
            "\u001b[0mC'est bon. Vous avez des enfants ?\u001b[0;0m\n",
            "   \u001b[1;94mNon, mais un jour.\u001b[0;0m\n",
            "\u001b[0mc'est bien. J'ai 2\u001b[0;0m\n",
            "   \u001b[1;94mLorsque j'aurai terminé mes études, je compte fonder une famille.\u001b[0;0m\n",
            "\u001b[0mc'est génial ! tu seras prête\u001b[0;0m\n",
            "   \u001b[1;94mJe l'espère, quel âge ont vos enfants ?\u001b[0;0m\n",
            "\u001b[0m5 & 7. Ils me prennent beaucoup de temps.\u001b[0;0m\n",
            "   \u001b[1;94mJ'imagine. Je suis sûr qu'ils sont de grands enfants.\u001b[0;0m\n",
            "\u001b[0mheureusement, ils aiment les fleurs tout autant que moi. Nous passons beaucoup de temps dans le jardin.\u001b[0;0m\n",
            "   \u001b[1;94mJ'aimerais avoir plus de temps pour faire ce genre de choses. L'école de médecine est épuisante. \u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: copied_dataset_french_bst/_train.txt - - -\u001b[0;0m\n",
            "\u001b[0mOh, j'adore les lasagnes. Je fais mes propres nouilles ainsi que la sauce. \u001b[0;0m\n",
            "   \u001b[1;94mWow.  C'est incroyable.  J'ai lu que les lasagnes sont nées en Italie au Moyen-âge.  \u001b[0;0m\n",
            "\u001b[0mOh vraiment ? C'est intéressant. En fait, je suis moi-même italien.\u001b[0;0m\n",
            "   \u001b[1;94mGénial. Moi et mon partenaire venons d'acheter une maison. Je suis impatient de cuisiner dans ma cuisine.\u001b[0;0m\n",
            "\u001b[0mDéménager dans un nouvel endroit peut être très amusant. Êtes-vous un bon cuisinier ?\u001b[0;0m\n",
            "   \u001b[1;94mJ'aime à le penser. J'aime aussi faire du café pour le plaisir après le repas.\u001b[0;0m\n",
            "\u001b[0mMmm. Ça a l'air délicieux en ce moment.\u001b[0;0m\n",
            "   \u001b[1;94mQu'est-ce que vous aimez faire ?\u001b[0;0m\n",
            "\u001b[0mEh bien j'aime les tatouages et les piercings, je travaille sur mon prochain en ce moment.\u001b[0;0m\n",
            "   \u001b[1;94mLes piercings sont cool. Mais je n'ai pas de tatouages. J'ai trop peur. Je veux en avoir\u001b[0;0m\n",
            "\u001b[0mQue prendriez-vous ?\u001b[0;0m\n",
            "   \u001b[1;94mPeut-être quelque chose pour mes enfants. J'ai toujours voulu un symbole d'anarchie.\u001b[0;0m\n",
            "\u001b[0mHaha c'est une idée cool.\u001b[0;0m\n",
            "   \u001b[1;94mJ'aime penser que je suis cool aussi. Avec un peu de chance, un jour.\u001b[0;0m\n",
            "12:46:15 | loaded 9638 episodes with a total of 59700 examples\n"
          ]
        }
      ],
      "source": [
        "# from parlai.scripts.display_data import DisplayData\n",
        "# DisplayData.main(task='empathetic_dialogues', num_examples=10)\n",
        "\n",
        "from parlai.scripts.display_data import DisplayData\n",
        "DisplayData.main(\n",
        "    task='fromfile:parlaiformat',\n",
        "    fromfile_datapath='copied_dataset_french_bst/',\n",
        "    fromfile_datatype_extension=True,\n",
        "    # model_file= f'{finetuned_model_path}/model',\n",
        "    # dict_file= dict_file,\n",
        "\n",
        "    num_examples=20,\n",
        "    # skip_generation=False,\n",
        "\n",
        "    # beam_min_length= 20,\n",
        "    # beam_block_ngram= 3,\n",
        "    # beam_context_block_ngram= 3,\n",
        "    # beam_size= 10,\n",
        "\n",
        "    # inference= \"beam\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "lVPS6p4XzPh4"
      ],
      "machine_shape": "hm",
      "name": "blender-90m-with-double-sized-data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOixpObfk5Gnz8XAbwYKL62",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}