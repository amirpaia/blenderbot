{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirpaia/blenderbot/blob/main/blender_90m_with_double_sized_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SONwSWMp6qPv"
      },
      "source": [
        "# 0.Installing prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d-SZ_On6Kxg",
        "outputId": "018c13ac-a19d-4715-9feb-6668d4373627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 31 06:33:59 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BegaSUz6iUz",
        "outputId": "a7e89d4a-ee03-4ab2-a2a6-2c0a874d3e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SzGRXHQ6kDQ",
        "outputId": "b6b043af-a28d-4421-abbd-8f8811eea551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWDakYmy6mIQ",
        "outputId": "37250b56-f8b3-44e8-d21b-6b1526f6cdaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 235 kB 84.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 95 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 248 kB 86.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 132 kB 74.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 60.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 749 kB 74.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 175 kB 85.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 74.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 68.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 70.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 346 kB 64.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 22.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 75.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 59.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 547 kB 67.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 40 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 208 kB 98.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 82.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 91.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 81.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 71.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 64.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 86.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 75.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 110 kB 74.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 100 kB 10.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 121 kB 78.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 11.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 72.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 86.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 777 kB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25h  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docformatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for untokenize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.4.24)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.26.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "mydrive_path = '/content/drive/MyDrive/colabs/blender-models/'\n",
        "# !pip uninstall -q parlai\n",
        "!pip install -q parlai\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIJEq9_r63hi"
      },
      "source": [
        "# 1. Preparing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R-fgBUdcPX5"
      },
      "source": [
        "## Genreal Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47u8M3RK65m_",
        "outputId": "96227866-b1c8-487b-954c-05e4e4a44948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:hello\tlabels:how are you\n",
            "text:good\tlabels:bye\tepisode_done:True\n",
            "\n",
            "text:hello\tlabels:how are you\n",
            "text:good\tlabels:bye\tepisode_done:True\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def transfer_list_of_turns_to_dialog(d):\n",
        "    if len(d)%2 !=0: d = d[:-1]\n",
        "    t = \"\"\n",
        "    for i in range(0,len(d),2):\n",
        "        u1 = d[i]\n",
        "        u2 = d[i+1]\n",
        "\n",
        "        if (i+2) != len(d):\n",
        "            t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\n\"\n",
        "        else:\n",
        "            t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\t\"+\"episode_done:True\"+\"\\n\"\n",
        "    return t\n",
        "\n",
        "def transfer_list_of_pairs_to_dialog(d):\n",
        "  t = \"\"\n",
        "  for i, text_label_pair in enumerate(d):\n",
        "    u1 = text_label_pair[0]\n",
        "    u2 = text_label_pair[1]\n",
        "\n",
        "    if i != (len(d) - 1):\n",
        "      t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\n\"\n",
        "    else:\n",
        "      t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\t\"+\"episode_done:True\"+\"\\n\"\n",
        "\n",
        "  return t\n",
        "\n",
        "def convert_parlai_format_to_list_of_turns(lines):\n",
        "    result = []\n",
        "    for line in lines:\n",
        "        text_label = line.split(\"\\t\")\n",
        "        result.append(text_label[0].replace(\"text:\", \"\"))\n",
        "        result.append(text_label[1].replace(\"labels:\", \"\").replace(\"\\n\",\"\"))\n",
        "    return result\n",
        "\n",
        "t = ['hello','how are you','good','bye','test']\n",
        "print(transfer_list_of_turns_to_dialog(t))\n",
        "\n",
        "t = [['hello','how are you'],['good','bye']]\n",
        "print(transfer_list_of_pairs_to_dialog(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIROa77CJtG9"
      },
      "outputs": [],
      "source": [
        "# def make_dataset_double_sided(lines, path, filename): \n",
        "#     # train[:10]\n",
        "#     all_dialogs_parlai_format = []\n",
        "#     dialog = []\n",
        "#     for line in lines:\n",
        "#         dialog.append(line)\n",
        "#         if 'episode_done:True' in line:\n",
        "#             turns = convert_parlai_format_to_list_of_turns(dialog)\n",
        "#             first_parlai_dialog = transfer_list_of_turns_to_dialog(turns)\n",
        "#             second_parlai_dialog = transfer_list_of_turns_to_dialog(turns[1:])\n",
        "\n",
        "#             all_dialogs_parlai_format.append(first_parlai_dialog)\n",
        "#             all_dialogs_parlai_format.append(second_parlai_dialog)\n",
        "\n",
        "#             dialog = []\n",
        "#             # break\n",
        "\n",
        "#     print(len(all_dialogs_parlai_format))\n",
        "\n",
        "#     with open(f\"{path}{filename}\", \"w\") as f:\n",
        "#         f.writelines(all_dialogs_parlai_format[:10])\n",
        "\n",
        "# !mkdir /content/dataset_french_bst/\n",
        "# make_dataset_double_sided(lines,\"/content/dataset_french_bst/\", \"train.txt\")\n",
        "\n",
        "\n",
        "\n",
        "# # import os.path\n",
        "# # from os import path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE45ZyKC8WjC"
      },
      "source": [
        "## XPersona"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZmSJtQG8Y1o",
        "outputId": "4c5bd166-a850-4772-cb26-6679ab4908b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Xpersona'...\n",
            "remote: Enumerating objects: 285, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 285 (delta 6), reused 6 (delta 4), pack-reused 275\u001b[K\n",
            "Receiving objects: 100% (285/285), 45.01 MiB | 21.67 MiB/s, done.\n",
            "Resolving deltas: 100% (96/96), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HLTCHKUST/Xpersona.git\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "with open('Xpersona/dataset/Fr_persona_train_corrected.json','r') as f:\n",
        "   train_data = json.load(f)\n",
        "\n",
        "dialogs_train = pd.DataFrame(train_data)['dialogue'].tolist()\n",
        "\n",
        "with open('Xpersona/dataset/Fr_persona_split_valid_human_annotated.json','r') as f:\n",
        "   valid_data = json.load(f)\n",
        "\n",
        "dialogs_valid = pd.DataFrame(valid_data)['dialogue'].tolist()\n",
        "\n",
        "with open('Xpersona/dataset/Fr_persona_split_test_human_annotated.json','r') as f:\n",
        "   test_data = json.load(f)\n",
        "\n",
        "dialogs_test = pd.DataFrame(test_data)['dialogue'].tolist()\n",
        "\n",
        "# dialogs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plw61KMBJU4I",
        "outputId": "476c0bc8-6e39-4a13-ba0f-cc2f7af1dac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/dataset_french_xpersona/': No such file or directory\n",
            "33756\n",
            "496\n",
            "498\n"
          ]
        }
      ],
      "source": [
        "data_path = \"/content/dataset_french_xpersona/\"\n",
        "!rm -R $data_path\n",
        "!mkdir $data_path\n",
        "\n",
        "def convert_xpersona_dialogs_to_parlai_format_file_and_double_sided(dialogs, filename):\n",
        "    all_dialogs_parlai_format = []\n",
        "    import numpy as np\n",
        "    for d in dialogs:\n",
        "        turns = np.reshape(d, (-1)).tolist()\n",
        "        all_dialogs_parlai_format.append(transfer_list_of_turns_to_dialog(turns))\n",
        "        all_dialogs_parlai_format.append(transfer_list_of_turns_to_dialog(turns[1:]))\n",
        "\n",
        "    print(len(all_dialogs_parlai_format))\n",
        "\n",
        "    with open(f\"{data_path}{filename}\",\"w\") as f:\n",
        "        f.writelines(all_dialogs_parlai_format)\n",
        "\n",
        "convert_xpersona_dialogs_to_parlai_format_file_and_double_sided(dialogs_train, \"train.txt\")\n",
        "convert_xpersona_dialogs_to_parlai_format_file_and_double_sided(dialogs_valid, \"valid.txt\")\n",
        "convert_xpersona_dialogs_to_parlai_format_file_and_double_sided(dialogs_test, \"test.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKlGi0f08zQc",
        "outputId": "ffa999f0-6961-42f2-e60e-64defba9a506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Set: 15776427\n",
            "Validation Set: 257114\n",
            "Test Set: 262425\n"
          ]
        }
      ],
      "source": [
        "# data_path = \"/content/dataset_french_xpersona/\"\n",
        "# !rm -R $data_path\n",
        "# !mkdir $data_path\n",
        "\n",
        "# #region Training\n",
        "# data_train = \"\"\n",
        "# for d in dialogs_train:\n",
        "#   data_train += transfer_list_of_pairs_to_dialog(d)\n",
        "\n",
        "# file_train = open(f\"{data_path}train.txt\",\"w\")\n",
        "# print(\"Training Set:\", file_train.write(data_train))\n",
        "# #endregion \n",
        "    \n",
        "# #region Validation\n",
        "# data_valid = \"\"\n",
        "# for d in dialogs_valid:\n",
        "#   data_valid += transfer_list_of_pairs_to_dialog(d)\n",
        "\n",
        "# file_valid = open(f\"{data_path}valid.txt\",\"w\")\n",
        "# print(\"Validation Set:\", file_valid.write(data_valid))\n",
        "# #endregion\n",
        "\n",
        "# #region Test\n",
        "# data_test = \"\"\n",
        "# for d in dialogs_test:\n",
        "#   data_test += transfer_list_of_pairs_to_dialog(d)\n",
        "\n",
        "# file_test = open(f\"{data_path}test.txt\",\"w\")\n",
        "# print(\"Test Set:\", file_test.write(data_test))\n",
        "# #endregion \n",
        "\n",
        "# # print(len(data_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoSv5zhs8ZIv"
      },
      "source": [
        "## ED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mISEjZbP8dN-",
        "outputId": "7739a28a-1cd7-4676-8202-7c87ac2f63f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/dataset_french_ed/': No such file or directory\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_empathetic_dialogues/test.txt' -> '/content/dataset_french_ed/test.txt'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_empathetic_dialogues/train.txt' -> '/content/dataset_french_ed/train.txt'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_empathetic_dialogues/valid.txt' -> '/content/dataset_french_ed/valid.txt'\n"
          ]
        }
      ],
      "source": [
        "googledrive_data_path = \"/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_empathetic_dialogues/\"\n",
        "data_path = \"/content/dataset_french_ed/\"\n",
        "!rm -R $data_path\n",
        "!mkdir $data_path\n",
        "!cp -rv $googledrive_data_path* $data_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNbq22L-Khmg",
        "outputId": "7183e24f-74a6-4386-c421-51b755e362c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64636\n",
            "39057 5537 5093 49687\n"
          ]
        }
      ],
      "source": [
        "# with open(f\"{googledrive_data_path}train.txt\") as f:\n",
        "#     train = f.readlines()\n",
        "\n",
        "# with open(f\"{googledrive_data_path}valid.txt\") as f:\n",
        "#     valid = f.readlines()\n",
        "\n",
        "# with open(f\"{googledrive_data_path}test.txt\") as f:\n",
        "#     test = f.readlines()\n",
        "\n",
        "\n",
        "# print(len(train))\n",
        "# a, b, c = sum([1 for a in train if 'episode_done:True' in a]), sum([1 for a in valid if 'episode_done:True' in a]), sum([1 for a in test if 'episode_done:True' in a])\n",
        "# print(a,b,c,a+b+c)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUxXs_Oe8dda"
      },
      "source": [
        "## BST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIRVhsq88e7A",
        "outputId": "f5035f7d-5c78-494b-afd4-3225129738e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/dataset_french_bst/': No such file or directory\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/test.txt' -> '/content/dataset_french_bst/test.txt'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/train.txt' -> '/content/dataset_french_bst/train.txt'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/valid.txt' -> '/content/dataset_french_bst/valid.txt'\n"
          ]
        }
      ],
      "source": [
        "googledrive_data_path = \"/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/\"\n",
        "data_path = \"/content/dataset_french_bst/\"\n",
        "!rm -R $data_path\n",
        "!mkdir $data_path\n",
        "!cp -rv $googledrive_data_path* $data_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuQo9hiTRT0Y",
        "outputId": "442c3001-a30b-45e1-f8ba-828d493056b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59700\n",
            "9638 2018 1958 13614\n"
          ]
        }
      ],
      "source": [
        "googledrive_data_path = \"/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/\"\n",
        "with open(f\"{googledrive_data_path}train.txt\") as f:\n",
        "    train = f.readlines()\n",
        "\n",
        "with open(f\"{googledrive_data_path}valid.txt\") as f:\n",
        "    valid = f.readlines()\n",
        "\n",
        "with open(f\"{googledrive_data_path}test.txt\") as f:\n",
        "    test = f.readlines()\n",
        "\n",
        "\n",
        "print(len(train))\n",
        "a, b, c = sum([1 for a in train if 'episode_done:True' in a]), sum([1 for a in valid if 'episode_done:True' in a]), sum([1 for a in test if 'episode_done:True' in a])\n",
        "print(a, b, c, a+b+c)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PQfT57Q8I2u"
      },
      "source": [
        "# 2. Creating new Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oVPKrhO8ISe",
        "outputId": "203468b3-9bcd-4b83-d42c-98dc9788fe94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/': No such file or directory\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/agents.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/agents.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/build.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/build.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/__init__.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/__init__.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/LICENSE_DOCUMENTATION' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/LICENSE_DOCUMENTATION'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/README.md' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/README.md'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test/empathetic_dialogues_test.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test/empathetic_dialogues_test.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test/empathetic_dialogues_train.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test/empathetic_dialogues_train.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test/empathetic_dialogues_valid.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test/empathetic_dialogues_valid.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/worlds.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/worlds.py'\n",
            "rm: cannot remove '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/': No such file or directory\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/agents.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/agents.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/build.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/build.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/__init__.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/__init__.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/LICENSE_DOCUMENTATION' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/LICENSE_DOCUMENTATION'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/README.md' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/README.md'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test/empathetic_dialogues_test.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test/empathetic_dialogues_test.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test/empathetic_dialogues_train.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test/empathetic_dialogues_train.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test/empathetic_dialogues_valid.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test/empathetic_dialogues_valid.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/worlds.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/worlds.py'\n",
            "rm: cannot remove '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/': No such file or directory\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/agents.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/agents.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/build.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/build.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/__init__.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/__init__.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/LICENSE_DOCUMENTATION' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/LICENSE_DOCUMENTATION'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/README.md' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/README.md'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test/empathetic_dialogues_test.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test/empathetic_dialogues_test.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test/empathetic_dialogues_train.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test/empathetic_dialogues_train.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test/empathetic_dialogues_valid.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test/empathetic_dialogues_valid.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/worlds.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/worlds.py'\n"
          ]
        }
      ],
      "source": [
        "#region XPersona\n",
        "task_path = \"/usr/local/lib/python3.7/dist-packages/parlai/tasks/\"\n",
        "\n",
        "!rm -R $task_path'french_xpersona/'\n",
        "!mkdir $task_path'french_xpersona'\n",
        "!cp -ruv /content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/* $task_path'french_xpersona/'\n",
        "#endregion\n",
        "\n",
        "\n",
        "#region ED\n",
        "task_path = \"/usr/local/lib/python3.7/dist-packages/parlai/tasks/\"\n",
        "\n",
        "!rm -R $task_path'french_empathetic_dialogues/'\n",
        "!mkdir $task_path'french_empathetic_dialogues'\n",
        "!cp -ruv /content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/* $task_path'french_empathetic_dialogues/'\n",
        "#endregion\n",
        "\n",
        "\n",
        "#region BST\n",
        "task_path = \"/usr/local/lib/python3.7/dist-packages/parlai/tasks/\"\n",
        "\n",
        "!rm -R $task_path'french_blended_skill_talk/'\n",
        "!mkdir $task_path'french_blended_skill_talk'\n",
        "!cp -ruv /content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/* $task_path'french_blended_skill_talk/'\n",
        "#endregion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGoTqdFD7x_3"
      },
      "source": [
        "# 3. Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "65rK6pfj70Px"
      },
      "outputs": [],
      "source": [
        "finetuned_model_path = f'{mydrive_path}/extra-space/finetuned-multitask-400m-double-sided'\n",
        "init_model = 'zoo:blender/blender_400Mdistill/model'\n",
        "dict_file  = 'zoo:blender/blender_400Mdistill/model.dict'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zArppuSCGS7"
      },
      "outputs": [],
      "source": [
        "# !mkdir copied_dataset_french_bst\n",
        "# !cp dataset_french_bst/* copied_dataset_french_bst\n",
        "# !mv copied_dataset_french_bst/test.txt copied_dataset_french_bst/_test.txt\n",
        "# !mv copied_dataset_french_bst/train.txt copied_dataset_french_bst/_train.txt\n",
        "# !mv copied_dataset_french_bst/valid.txt copied_dataset_french_bst/_valid.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7vLiYpF8HbF"
      },
      "outputs": [],
      "source": [
        "# 90M settings\n",
        "# !rm -rf $finetuned_model_path\n",
        "!mkdir -p $finetuned_model_path\n",
        "\n",
        "\n",
        "from parlai.scripts.train_model import TrainModel\n",
        "\n",
        "TrainModel.main(\n",
        "    # task\n",
        "    task= \"french_blended_skill_talk,french_xpersona,french_empathetic_dialogues\",\n",
        "    multitask_weights= \"1,3,3\",\n",
        "\n",
        "    # task='fromfile:parlaiformat', \n",
        "    # fromfile_datapath='copied_dataset_french_bst/',\n",
        "    # fromfile_datatype_extension=True,\n",
        "\n",
        "    model='transformer/generator',\n",
        "    model_file= f'{finetuned_model_path}/model',\n",
        "    \n",
        "    # initialize with a pretrained model\n",
        "    init_model= init_model,\n",
        "    dict_file=dict_file,\n",
        "    \n",
        "    # arguments we get from the pretrained model.\n",
        "    # Unfortunately, these must be looked up separately for each model.\n",
        "    n_heads=16, n_layers=8, n_positions=512, text_truncate=512,\n",
        "    label_truncate=128, ffn_size=2048, embedding_size=512,\n",
        "    activation='gelu', variant='xlm',\n",
        "    dict_lower=True, dict_tokenizer='bpe',\n",
        "    \n",
        "    # depend on your gpu. \n",
        "    validation_every_n_epochs=0.25,\n",
        "    num_epochs = 5,\n",
        "    log_every_n_secs= 60,\n",
        "    verbose = True,\n",
        "    batchsize= 8, \n",
        "    fp16= True, fp16_impl= \"mem_efficient\",\n",
        "    \n",
        "    # arguments we get from the pretrained model.\n",
        "    \n",
        "    # speeds up validation\n",
        "    skip_generation=True,\n",
        "    vp= 10,\n",
        "    validation_metric= \"ppl\", #vmt = \"ppl\"\n",
        "    validation_metric_mode= \"min\", # vmm= \"min\"\n",
        "    \n",
        "    # helps us cram more examples into our gpu at a time\n",
        "    dynamic_batching='full',\n",
        "\n",
        "    \n",
        "    # some training arguments, specific to this fine-tuning\n",
        "    lr=1e-5, optimizer='adam',\n",
        "    attention_dropout= 0.0, \n",
        "    model_parallel= False,\n",
        "    warmup_updates=100,\n",
        "\n",
        "    # customized parameters\n",
        "    # inference= \"beam\"\n",
        "    # beam_min_length= 20,\n",
        "    # beam_block_ngram= 3,\n",
        "    # beam_context_block_ngram= 3,\n",
        "    # beam_size= 10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNZE5ta2pO-X",
        "outputId": "ff46af42-2aca-4bd6-f82d-0578eb4c41dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06:42:27 | building dictionary first...\n",
            "06:42:27 | No model with opt yet at: /content/drive/MyDrive/colabs/blender-models//extra-space/finetuned-multitask-400m-double-sided/model(.opt)\n",
            "06:42:27 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: download_path: None,verbose: True,is_debug: False,datapath: /usr/local/lib/python3.7/dist-packages/data,final_extra_opt: ,eval_dynamic_batching: None,num_workers: 0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_steps: -1,load_from_checkpoint: True,world_logs: ,save_format: conversations,log_keep_fields: all,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,mutators: None,checkpoint_activations: False,interactive_mode: False\u001b[0m\n",
            "06:42:27 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
            "--init-opt /private/home/ems/GitHub/facebookresearch/ParlAI/data/models/blender/blender_3B/model.opt --allow-missing-init-opts True --task blended_skill_talk,wizard_of_wikipedia,convai2:normalized,empathetic_dialogues --multitask-weights 1.0,3.0,3.0,3.0 --batchsize 8 --dynamic-batching full --eval-batchsize 8 --num-epochs -1 --validation-every-n-secs 900.0 --save-after-valid True --validation-every-n-epochs -1.0 --validation-patience 20 --log-every-n-secs 10.0 --distributed-world-size 8 --port 61337 --label-type response --include-knowledge True --include-checked-sentence True --include-knowledge-separator False --chosen-topic-delimiter \n",
            " --num-topics 5 --train-experiencer-only False --remove-political-convos False --teacher-model /private/home/ems/GitHub/facebookresearch/ParlAI/data/models/blender/blender_3B/model --task-loss-coeff 1.0 --encoder-loss-coeff 24.0 --hidden-loss-coeff 5.0 --pred-loss-coeff 8.0 --embedding-loss-coeff 0.35 --self-attn-loss-coeff 0.6 --enc-dec-attn-loss-coeff 3.0 --beam-size 10 --beam-min-length 20 --beam-context-block-ngram 3 --beam-block-ngram 3 --inference beam --learningrate 0.0004 --gpu 0 --bpe-vocab /checkpoint/parlai/zoo/meena/20200319_meenav0data_tall_2.7B_adamoptimizer/20200319_13.3ppl_200kupdates/model.dict-vocab.json --bpe-merge /checkpoint/parlai/zoo/meena/20200319_meenav0data_tall_2.7B_adamoptimizer/20200319_13.3ppl_200kupdates/model.dict-merges.txt --bpe-add-prefix-space True --max-lr-steps -1 --parlai-home /checkpoint/edinan/20200331/finetune_bst_gen_baseline_convai2_normal/ParlAI --show-advanced-args False --numthreads 1 --rank 0 --dict-loaded True\u001b[0m\n",
            "06:42:27 | Using CUDA\n",
            "06:42:27 | loading dictionary from /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_400Mdistill/model.dict\n",
            "06:42:27 | num words = 8008\n",
            "06:42:33 | Total parameters: 364,802,560 (364,474,880 trainable)\n",
            "06:42:33 | Loading existing model params from /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_400Mdistill/model\n",
            "06:42:35 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n",
            "06:42:35 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n",
            "06:42:35 | Opt:\n",
            "06:42:35 |     activation: gelu\n",
            "06:42:35 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "06:42:35 |     adam_eps: 1e-08\n",
            "06:42:35 |     add_p1_after_newln: False\n",
            "06:42:35 |     aggregate_micro: False\n",
            "06:42:35 |     allow_missing_init_opts: False\n",
            "06:42:35 |     attention_dropout: 0.0\n",
            "06:42:35 |     batchsize: 16\n",
            "06:42:35 |     beam_block_full_context: True\n",
            "06:42:35 |     beam_block_list_filename: None\n",
            "06:42:35 |     beam_block_ngram: -1\n",
            "06:42:35 |     beam_context_block_ngram: -1\n",
            "06:42:35 |     beam_delay: 30\n",
            "06:42:35 |     beam_length_penalty: 0.65\n",
            "06:42:35 |     beam_min_length: 1\n",
            "06:42:35 |     beam_size: 1\n",
            "06:42:35 |     betas: '(0.9, 0.999)'\n",
            "06:42:35 |     bpe_add_prefix_space: None\n",
            "06:42:35 |     bpe_debug: False\n",
            "06:42:35 |     bpe_dropout: None\n",
            "06:42:35 |     bpe_merge: /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_400Mdistill/model.dict-merges.txt\n",
            "06:42:35 |     bpe_vocab: /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_400Mdistill/model.dict-vocab.json\n",
            "06:42:35 |     checkpoint_activations: False\n",
            "06:42:35 |     compute_tokenized_bleu: False\n",
            "06:42:35 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "06:42:35 |     datatype: train\n",
            "06:42:35 |     delimiter: '  '\n",
            "06:42:35 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "06:42:35 |     dict_endtoken: __end__\n",
            "06:42:35 |     dict_file: /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_400Mdistill/model.dict\n",
            "06:42:35 |     dict_include_test: False\n",
            "06:42:35 |     dict_include_valid: False\n",
            "06:42:35 |     dict_initpath: None\n",
            "06:42:35 |     dict_language: english\n",
            "06:42:35 |     dict_loaded: True\n",
            "06:42:35 |     dict_lower: False\n",
            "06:42:35 |     dict_max_ngram_size: -1\n",
            "06:42:35 |     dict_maxexs: -1\n",
            "06:42:35 |     dict_maxtokens: -1\n",
            "06:42:35 |     dict_minfreq: 0\n",
            "06:42:35 |     dict_nulltoken: __null__\n",
            "06:42:35 |     dict_starttoken: __start__\n",
            "06:42:35 |     dict_textfields: text,labels\n",
            "06:42:35 |     dict_tokenizer: bytelevelbpe\n",
            "06:42:35 |     dict_unktoken: __unk__\n",
            "06:42:35 |     display_examples: False\n",
            "06:42:35 |     download_path: None\n",
            "06:42:35 |     dropout: 0.1\n",
            "06:42:35 |     dynamic_batching: None\n",
            "06:42:35 |     embedding_projection: random\n",
            "06:42:35 |     embedding_size: 1280\n",
            "06:42:35 |     embedding_type: random\n",
            "06:42:35 |     embeddings_scale: True\n",
            "06:42:35 |     eval_batchsize: None\n",
            "06:42:35 |     eval_dynamic_batching: None\n",
            "06:42:35 |     evaltask: None\n",
            "06:42:35 |     ffn_size: 5120\n",
            "06:42:35 |     final_extra_opt: \n",
            "06:42:35 |     force_fp16_tokens: False\n",
            "06:42:35 |     fp16: True\n",
            "06:42:35 |     fp16_impl: mem_efficient\n",
            "06:42:35 |     gpu: -1\n",
            "06:42:35 |     gradient_clip: 0.1\n",
            "06:42:35 |     hide_labels: False\n",
            "06:42:35 |     history_add_global_end_token: end\n",
            "06:42:35 |     history_reversed: False\n",
            "06:42:35 |     history_size: -1\n",
            "06:42:35 |     image_cropsize: 224\n",
            "06:42:35 |     image_mode: raw\n",
            "06:42:35 |     image_size: 256\n",
            "06:42:35 |     inference: greedy\n",
            "06:42:35 |     init_model: /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_400Mdistill/model\n",
            "06:42:35 |     init_opt: None\n",
            "06:42:35 |     interactive_mode: False\n",
            "06:42:35 |     invsqrt_lr_decay_gamma: -1\n",
            "06:42:35 |     is_debug: False\n",
            "06:42:35 |     label_truncate: 128\n",
            "06:42:35 |     learn_positional_embeddings: False\n",
            "06:42:35 |     learningrate: 7e-06\n",
            "06:42:35 |     load_from_checkpoint: True\n",
            "06:42:35 |     log_every_n_secs: 60.0\n",
            "06:42:35 |     log_every_n_steps: 50\n",
            "06:42:35 |     log_keep_fields: all\n",
            "06:42:35 |     loglevel: info\n",
            "06:42:35 |     lr_scheduler: reduceonplateau\n",
            "06:42:35 |     lr_scheduler_decay: 0.5\n",
            "06:42:35 |     lr_scheduler_patience: 3\n",
            "06:42:35 |     max_train_steps: -1\n",
            "06:42:35 |     max_train_time: -1\n",
            "06:42:35 |     metrics: default\n",
            "06:42:35 |     model: transformer/generator\n",
            "06:42:35 |     model_file: /content/drive/MyDrive/colabs/blender-models//extra-space/finetuned-multitask-400m-double-sided/model\n",
            "06:42:35 |     model_parallel: False\n",
            "06:42:35 |     momentum: 0\n",
            "06:42:35 |     multitask_weights: '(1.0, 3.0, 3.0)'\n",
            "06:42:35 |     mutators: None\n",
            "06:42:35 |     n_decoder_layers: 12\n",
            "06:42:35 |     n_encoder_layers: 2\n",
            "06:42:35 |     n_heads: 32\n",
            "06:42:35 |     n_layers: 2\n",
            "06:42:35 |     n_positions: 128\n",
            "06:42:35 |     n_segments: 0\n",
            "06:42:35 |     nesterov: True\n",
            "06:42:35 |     no_cuda: False\n",
            "06:42:35 |     num_epochs: 5.0\n",
            "06:42:35 |     num_workers: 0\n",
            "06:42:35 |     nus: (0.7,)\n",
            "06:42:35 |     optimizer: mem_eff_adam\n",
            "06:42:35 |     output_scaling: 1.0\n",
            "06:42:35 |     override: \"{'task': 'french_blended_skill_talk,french_xpersona,french_empathetic_dialogues', 'multitask_weights': (1.0, 3.0, 3.0), 'model': 'transformer/generator', 'model_file': '/content/drive/MyDrive/colabs/blender-models//extra-space/finetuned-multitask-400m-double-sided/model', 'init_model': 'zoo:blender/blender_400Mdistill/model', 'dict_file': '/usr/local/lib/python3.7/dist-packages/data/models/blender/blender_400Mdistill/model.dict', 'validation_every_n_epochs': 0.25, 'num_epochs': 5.0, 'log_every_n_secs': 60.0, 'verbose': True, 'attention_dropout': 0.0, 'batchsize': 16, 'fp16': True, 'fp16_impl': 'mem_efficient', 'embedding_size': 1280, 'ffn_size': 5120, 'variant': 'prelayernorm', 'n_heads': 32, 'n_positions': 128, 'n_encoder_layers': 2, 'n_decoder_layers': 12, 'label_truncate': 128, 'text_truncate': 128, 'truncate': 128, 'activation': 'gelu', 'history_add_global_end_token': 'end', 'delimiter': '  ', 'dict_tokenizer': 'bytelevelbpe', 'dropout': 0.1, 'learningrate': 7e-06, 'lr_scheduler': 'reduceonplateau', 'lr_scheduler_patience': 3, 'optimizer': 'mem_eff_adam', 'relu_dropout': 0.0, 'model_parallel': False, 'warmup_updates': 100, 'update_freq': 2, 'gradient_clip': 0.1, 'skip_generation': True, 'validation_patience': 10, 'validation_metric': 'ppl', 'validation_metric_mode': 'min'}\"\n",
            "06:42:35 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "06:42:35 |     person_tokens: False\n",
            "06:42:35 |     rank_candidates: False\n",
            "06:42:35 |     relu_dropout: 0.0\n",
            "06:42:35 |     save_after_valid: False\n",
            "06:42:35 |     save_every_n_secs: -1\n",
            "06:42:35 |     save_format: conversations\n",
            "06:42:35 |     share_word_embeddings: True\n",
            "06:42:35 |     short_final_eval: False\n",
            "06:42:35 |     skip_generation: True\n",
            "06:42:35 |     special_tok_lst: None\n",
            "06:42:35 |     split_lines: False\n",
            "06:42:35 |     starttime: May31_06-42\n",
            "06:42:35 |     task: french_blended_skill_talk,french_xpersona,french_empathetic_dialogues\n",
            "06:42:35 |     temperature: 1.0\n",
            "06:42:35 |     tensorboard_log: False\n",
            "06:42:35 |     tensorboard_logdir: None\n",
            "06:42:35 |     text_truncate: 128\n",
            "06:42:36 |     topk: 10\n",
            "06:42:36 |     topp: 0.9\n",
            "06:42:36 |     truncate: 128\n",
            "06:42:36 |     update_freq: 2\n",
            "06:42:36 |     use_reply: label\n",
            "06:42:36 |     validation_cutoff: 1.0\n",
            "06:42:36 |     validation_every_n_epochs: 0.25\n",
            "06:42:36 |     validation_every_n_secs: -1\n",
            "06:42:36 |     validation_every_n_steps: -1\n",
            "06:42:36 |     validation_max_exs: -1\n",
            "06:42:36 |     validation_metric: ppl\n",
            "06:42:36 |     validation_metric_mode: min\n",
            "06:42:36 |     validation_patience: 10\n",
            "06:42:36 |     validation_share_agent: False\n",
            "06:42:36 |     variant: prelayernorm\n",
            "06:42:36 |     verbose: True\n",
            "06:42:36 |     wandb_entity: None\n",
            "06:42:36 |     wandb_log: False\n",
            "06:42:36 |     wandb_name: None\n",
            "06:42:36 |     wandb_project: None\n",
            "06:42:36 |     warmup_rate: 0.0001\n",
            "06:42:36 |     warmup_updates: 100\n",
            "06:42:36 |     weight_decay: None\n",
            "06:42:36 |     world_logs: \n",
            "06:42:36 | creating task(s): french_blended_skill_talk,french_xpersona,french_empathetic_dialogues\n",
            "06:42:36 | Loading ParlAI text data: /content/dataset_french_bst/train.txt\n",
            "06:42:37 | Loading ParlAI text data: /content/dataset_french_xpersona/train.txt\n",
            "06:42:39 | Loading ParlAI text data: /content/dataset_french_ed/train.txt\n",
            "06:42:40 | training...\n",
            "06:42:41 | Overflow: setting loss scale to 65536.0\n",
            "06:42:49 | Overflow: setting loss scale to 32768.0\n",
            "06:43:09 | time:29s total_exs:1600 total_steps:50 epochs:0.00 time_left:31895s\n",
            "                                clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  \\\n",
            "   all                         159.6 .9600  1531  5334   .4642      69.79 55.74 1600             43254  16.13    .5331 31.66   \n",
            "   french_blended_skill_talk   237.9                     .6929      128.8        241                                   35.16   \n",
            "   french_empathetic_dialogues 62.55                    .08765      3.327        251                                   32.81   \n",
            "   french_xpersona             178.3                     .6119      77.28       1108                                      27   \n",
            "                                loss      lr  ltpb  ltps  ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  \\\n",
            "   all                         5.808 3.5e-06 465.6  1622 .001328     .08499 334.9      .1092         0                   50   \n",
            "   french_blended_skill_talk   5.708                           0          0 301.4      .1173         0                        \n",
            "   french_empathetic_dialogues 5.955                     .003984      .2550 385.5      .0979         0                        \n",
            "   french_xpersona             5.762                           0          0 317.8      .1124         0                        \n",
            "                                tpb  tps   ups  \n",
            "   all                         1997 6956 1.742  \n",
            "   french_blended_skill_talk                    \n",
            "   french_empathetic_dialogues                  \n",
            "   french_xpersona\n",
            "\n",
            "06:43:39 | time:59s total_exs:3200 total_steps:100 epochs:0.01 time_left:32986s\n",
            "                                clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  \\\n",
            "   all                         161.6     1  1556  5070   .4755      70.43 52.12 1600             32768  8.531    .5331 32.64   \n",
            "   french_blended_skill_talk   231.3                     .6756      124.3        299                                   36.97   \n",
            "   french_empathetic_dialogues 70.59                     .1235      6.247        243                                   35.43   \n",
            "   french_xpersona             182.8                     .6276      80.72       1058                                   25.53   \n",
            "                                loss       lr  ltpb  ltps  ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  \\\n",
            "   all                         5.273 6.93e-06 466.3  1519 .001372     .04938 194.9      .1283         0                  100   \n",
            "   french_blended_skill_talk   5.259                            0          0 192.2      .1319         0                        \n",
            "   french_empathetic_dialogues 5.297                      .004115      .1481 199.6      .1240         0                        \n",
            "   french_xpersona             5.262                            0          0 192.9      .1290         0                        \n",
            "                                tpb  tps   ups  \n",
            "   all                         2023 6589 1.629  \n",
            "   french_blended_skill_talk                    \n",
            "   french_empathetic_dialogues                  \n",
            "   french_xpersona\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 400M settings\n",
        "# !rm -rf $finetuned_model_path\n",
        "!mkdir -p $finetuned_model_path\n",
        "\n",
        "\n",
        "from parlai.scripts.train_model import TrainModel\n",
        "\n",
        "TrainModel.main(\n",
        "    # task\n",
        "    task= \"french_blended_skill_talk,french_xpersona,french_empathetic_dialogues\",\n",
        "    multitask_weights= \"1,3,3\",\n",
        "\n",
        "    # task='fromfile:parlaiformat', \n",
        "    # fromfile_datapath='copied_dataset_french_bst/',\n",
        "    # fromfile_datatype_extension=True,\n",
        "\n",
        "    model='transformer/generator',\n",
        "    model_file= f'{finetuned_model_path}/model',\n",
        "    \n",
        "    # initialize with a pretrained model\n",
        "    init_model= init_model,\n",
        "    dict_file=dict_file,\n",
        "    \n",
        "    # depend on your gpu\n",
        "    validation_every_n_epochs=0.25, # veps= 0.25, \n",
        "    num_epochs = 5,\n",
        "    log_every_n_secs= 60,\n",
        "    verbose = True,\n",
        "    attention_dropout= 0.0, \n",
        "    batchsize= 16, \n",
        "    fp16= True, fp16_impl= \"mem_efficient\",\n",
        "\n",
        "    # arguments we get from the pretrained model. \"from recipes page for 2.7B model\" \n",
        "    embedding_size= 1280, ffn_size= 5120,\n",
        "    variant= \"prelayernorm\",\n",
        "    n_heads= 32, n_positions= 128, \n",
        "    n_encoder_layers= 2, n_decoder_layers= 12,\n",
        "\n",
        "    label_truncate= 128, text_truncate= 128, truncate= 128,\n",
        "    activation= \"gelu\",\n",
        "    history_add_global_end_token= \"end\", \n",
        "    delimiter= '  ', \n",
        "    dict_tokenizer= \"bytelevelbpe\",\n",
        "    dropout= 0.1,\n",
        "    \n",
        "    # some training arguments, specific to this fine-tuning\n",
        "    lr= 7e-06, lr_scheduler= \"reduceonplateau\", lr_scheduler_patience= 3,\n",
        "    optimizer= \"mem_eff_adam\",\n",
        "    relu_dropout= 0.0, \n",
        "    model_parallel= False,\n",
        "    warmup_updates= 100,\n",
        "    update_freq= 2,\n",
        "    gradient_clip= 0.1, \n",
        "    # save_after_valid= True,\n",
        "\n",
        "    # speeds up validation\n",
        "    skip_generation= True,\n",
        "    vp= 10,\n",
        "    validation_metric= \"ppl\", #vmt = \"ppl\"\n",
        "    validation_metric_mode= \"min\", # vmm= \"min\"\n",
        "\n",
        "    # customized parameters\n",
        "    # inference = 'topk', \n",
        "    # temperature = 0.7, \n",
        "    # topk=30, \n",
        "    # beam_length_penalty=1.03\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVPS6p4XzPh4"
      },
      "source": [
        "# 3. Display Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9FBtnZZzPPg",
        "outputId": "c2343265-c6b1-4870-8cc4-6c58863b76de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15:06:36 | \u001b[33mOverriding opt[\"task\"] to french_blended_skill_talk (previously: french_blended_skill_talk,french_xpersona,french_empathetic_dialogues)\u001b[0m\n",
            "15:06:36 | \u001b[33mOverriding opt[\"skip_generation\"] to False (previously: True)\u001b[0m\n",
            "15:06:36 | Using CUDA\n",
            "15:06:36 | loading dictionary from /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m-double-sided/model.dict\n",
            "15:06:36 | num words = 54944\n",
            "15:06:38 | Total parameters: 87,508,992 (86,984,704 trainable)\n",
            "15:06:38 | Loading existing model params from /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m-double-sided/model\n",
            "15:06:42 | creating task(s): french_blended_skill_talk\n",
            "15:06:42 | Loading ParlAI text data: /content/dataset_french_bst/valid.txt\n",
            "15:06:42 | Opt:\n",
            "15:06:42 |     activation: gelu\n",
            "15:06:42 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "15:06:42 |     adam_eps: 1e-08\n",
            "15:06:42 |     add_p1_after_newln: False\n",
            "15:06:42 |     aggregate_micro: False\n",
            "15:06:42 |     allow_missing_init_opts: False\n",
            "15:06:42 |     attention_dropout: 0.0\n",
            "15:06:42 |     batchsize: 8\n",
            "15:06:42 |     beam_block_full_context: True\n",
            "15:06:42 |     beam_block_list_filename: None\n",
            "15:06:42 |     beam_block_ngram: -1\n",
            "15:06:42 |     beam_context_block_ngram: -1\n",
            "15:06:42 |     beam_delay: 30\n",
            "15:06:42 |     beam_length_penalty: 0.65\n",
            "15:06:42 |     beam_min_length: 1\n",
            "15:06:42 |     beam_size: 1\n",
            "15:06:42 |     betas: '[0.9, 0.999]'\n",
            "15:06:42 |     bpe_add_prefix_space: None\n",
            "15:06:42 |     bpe_debug: False\n",
            "15:06:42 |     bpe_dropout: None\n",
            "15:06:42 |     bpe_merge: None\n",
            "15:06:42 |     bpe_vocab: None\n",
            "15:06:42 |     checkpoint_activations: False\n",
            "15:06:42 |     compute_tokenized_bleu: False\n",
            "15:06:42 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "15:06:42 |     datatype: train\n",
            "15:06:42 |     delimiter: '\\n'\n",
            "15:06:42 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "15:06:42 |     dict_endtoken: __end__\n",
            "15:06:42 |     dict_file: /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m-double-sided/model.dict\n",
            "15:06:42 |     dict_include_test: False\n",
            "15:06:42 |     dict_include_valid: False\n",
            "15:06:42 |     dict_initpath: None\n",
            "15:06:42 |     dict_language: english\n",
            "15:06:42 |     dict_loaded: True\n",
            "15:06:42 |     dict_lower: True\n",
            "15:06:42 |     dict_max_ngram_size: -1\n",
            "15:06:42 |     dict_maxexs: -1\n",
            "15:06:42 |     dict_maxtokens: -1\n",
            "15:06:42 |     dict_minfreq: 0\n",
            "15:06:42 |     dict_nulltoken: __null__\n",
            "15:06:42 |     dict_starttoken: __start__\n",
            "15:06:42 |     dict_textfields: text,labels\n",
            "15:06:42 |     dict_tokenizer: bpe\n",
            "15:06:42 |     dict_unktoken: __unk__\n",
            "15:06:42 |     display_add_fields: \n",
            "15:06:42 |     display_examples: False\n",
            "15:06:42 |     download_path: None\n",
            "15:06:42 |     dropout: 0.0\n",
            "15:06:42 |     dynamic_batching: full\n",
            "15:06:42 |     embedding_projection: random\n",
            "15:06:42 |     embedding_size: 512\n",
            "15:06:42 |     embedding_type: random\n",
            "15:06:42 |     embeddings_scale: True\n",
            "15:06:42 |     eval_batchsize: None\n",
            "15:06:42 |     eval_dynamic_batching: None\n",
            "15:06:42 |     evaltask: None\n",
            "15:06:42 |     ffn_size: 2048\n",
            "15:06:42 |     final_extra_opt: \n",
            "15:06:42 |     force_fp16_tokens: True\n",
            "15:06:42 |     fp16: True\n",
            "15:06:42 |     fp16_impl: mem_efficient\n",
            "15:06:42 |     gpu: -1\n",
            "15:06:42 |     gradient_clip: 0.1\n",
            "15:06:42 |     hide_labels: False\n",
            "15:06:42 |     history_add_global_end_token: None\n",
            "15:06:42 |     history_reversed: False\n",
            "15:06:42 |     history_size: -1\n",
            "15:06:42 |     image_cropsize: 224\n",
            "15:06:42 |     image_mode: raw\n",
            "15:06:42 |     image_size: 256\n",
            "15:06:42 |     inference: greedy\n",
            "15:06:42 |     init_model: /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model\n",
            "15:06:42 |     init_opt: None\n",
            "15:06:42 |     interactive_mode: False\n",
            "15:06:42 |     invsqrt_lr_decay_gamma: -1\n",
            "15:06:42 |     is_debug: False\n",
            "15:06:42 |     label_truncate: 128\n",
            "15:06:42 |     learn_positional_embeddings: False\n",
            "15:06:42 |     learningrate: 1e-05\n",
            "15:06:42 |     log_every_n_secs: 60.0\n",
            "15:06:42 |     log_every_n_steps: 50\n",
            "15:06:42 |     log_keep_fields: all\n",
            "15:06:42 |     loglevel: info\n",
            "15:06:42 |     lr_scheduler: reduceonplateau\n",
            "15:06:42 |     lr_scheduler_decay: 0.5\n",
            "15:06:43 |     lr_scheduler_patience: 3\n",
            "15:06:43 |     max_train_steps: -1\n",
            "15:06:43 |     max_train_time: -1\n",
            "15:06:43 |     metrics: default\n",
            "15:06:43 |     model: transformer/generator\n",
            "15:06:43 |     model_file: /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m-double-sided/model\n",
            "15:06:43 |     model_parallel: False\n",
            "15:06:43 |     momentum: 0\n",
            "15:06:43 |     multitask_weights: '[1.0, 3.0, 3.0]'\n",
            "15:06:43 |     mutators: None\n",
            "15:06:43 |     n_decoder_layers: -1\n",
            "15:06:43 |     n_encoder_layers: -1\n",
            "15:06:43 |     n_heads: 16\n",
            "15:06:43 |     n_layers: 8\n",
            "15:06:43 |     n_positions: 512\n",
            "15:06:43 |     n_segments: 0\n",
            "15:06:43 |     nesterov: True\n",
            "15:06:43 |     no_cuda: False\n",
            "15:06:43 |     num_epochs: 5.0\n",
            "15:06:43 |     num_examples: 20\n",
            "15:06:43 |     num_workers: 0\n",
            "15:06:43 |     nus: [0.7]\n",
            "15:06:43 |     optimizer: mem_eff_adam\n",
            "15:06:43 |     output_scaling: 1.0\n",
            "15:06:43 |     override: \"{'task': 'french_blended_skill_talk', 'model_file': '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m-double-sided/model', 'num_examples': '20', 'skip_generation': False}\"\n",
            "15:06:43 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "15:06:43 |     person_tokens: False\n",
            "15:06:43 |     rank_candidates: False\n",
            "15:06:43 |     relu_dropout: 0.0\n",
            "15:06:43 |     save_after_valid: False\n",
            "15:06:43 |     save_every_n_secs: -1\n",
            "15:06:43 |     save_format: conversations\n",
            "15:06:43 |     share_word_embeddings: True\n",
            "15:06:43 |     short_final_eval: False\n",
            "15:06:43 |     skip_generation: False\n",
            "15:06:43 |     special_tok_lst: None\n",
            "15:06:43 |     split_lines: False\n",
            "15:06:43 |     starttime: May25_08-36\n",
            "15:06:43 |     task: french_blended_skill_talk\n",
            "15:06:43 |     temperature: 1.0\n",
            "15:06:43 |     tensorboard_log: False\n",
            "15:06:43 |     tensorboard_logdir: None\n",
            "15:06:43 |     text_truncate: 512\n",
            "15:06:43 |     topk: 10\n",
            "15:06:43 |     topp: 0.9\n",
            "15:06:43 |     truncate: -1\n",
            "15:06:43 |     update_freq: 1\n",
            "15:06:43 |     use_reply: label\n",
            "15:06:43 |     validation_cutoff: 1.0\n",
            "15:06:43 |     validation_every_n_epochs: 0.25\n",
            "15:06:43 |     validation_every_n_secs: -1\n",
            "15:06:43 |     validation_every_n_steps: -1\n",
            "15:06:43 |     validation_max_exs: -1\n",
            "15:06:43 |     validation_metric: ppl\n",
            "15:06:43 |     validation_metric_mode: min\n",
            "15:06:43 |     validation_patience: 10\n",
            "15:06:43 |     validation_share_agent: False\n",
            "15:06:43 |     variant: xlm\n",
            "15:06:43 |     verbose: False\n",
            "15:06:43 |     wandb_entity: None\n",
            "15:06:43 |     wandb_log: False\n",
            "15:06:43 |     wandb_name: None\n",
            "15:06:43 |     wandb_project: None\n",
            "15:06:43 |     warmup_rate: 0.0001\n",
            "15:06:43 |     warmup_updates: 100\n",
            "15:06:43 |     weight_decay: None\n",
            "15:06:43 |     world_logs: \n",
            "\u001b[1;31m- - - NEW EPISODE: french_blended_skill_talk- - -\u001b[0;0m\n",
            "\u001b[0mCela semble dangereux. Cela vaut-il la peine de faire un travail aussi dangereux ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Wekk, c'est bon si vous êtes bien formé.  Il y a trois niveaux \u001b[0;0m\n",
            "\u001b[0;95m     model: oui , c ' est vrai . je ne sais pas si je peux m ' en empêcher .\u001b[0;0m\n",
            "\u001b[0mA quel niveau êtes-vous ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: J'ai reçu une formation sur le tas lorsque j'ai commencé à travailler.\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis un grand fan de la musique country .\u001b[0;0m\n",
            "\u001b[0mC'est génial ! Depuis combien de temps faites-vous ce travail ? \u001b[0;0m\n",
            "\u001b[1;94m    labels: Depuis un bon nombre d'années maintenant.\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis un étudiant de la marine .\u001b[0;0m\n",
            "\u001b[0mOn dirait que ça peut être un travail dangereux parfois.\u001b[0;0m\n",
            "\u001b[1;94m    labels: C'est vrai, surtout si vous ne prenez pas les mesures appropriées.\u001b[0;0m\n",
            "\u001b[0;95m     model: oui , c ' est vrai .\u001b[0;0m\n",
            "\u001b[0mEh bien, vous êtes entré dans un métier qui vous garantira toujours du travail.\u001b[0;0m\n",
            "\u001b[1;94m    labels: C'est vrai, surtout dans cette économie\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis un peu déçu , mais je suis un peu plus âgé que moi .\u001b[0;0m\n",
            "\u001b[0mJ'ai moi-même un emploi assez stable, mais surtout du travail de bureau.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Est-ce que ça vous plaît ?\u001b[0;0m\n",
            "\u001b[0;95m     model: c ' est bien , je suis content que tu aies pu être stable .\u001b[0;0m\n",
            "\u001b[0mJe le fais vraiment, mais parfois j'aimerais être plus actif et debout.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Je vous comprends. S'étirer le long des couloirs\u001b[0;0m\n",
            "\u001b[0;95m     model: c ' est bien , je suis sûr que vous vous êtes amusés .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: french_blended_skill_talk- - -\u001b[0;0m\n",
            "\u001b[0mWekk, c'est bon si vous êtes bien formé.  Il y a trois niveaux \u001b[0;0m\n",
            "\u001b[1;94m    labels: A quel niveau êtes-vous ?\u001b[0;0m\n",
            "\u001b[0;95m     model: oui , je suis un grand fan de la musique .\u001b[0;0m\n",
            "\u001b[0mJ'ai reçu une formation sur le tas lorsque j'ai commencé à travailler.\u001b[0;0m\n",
            "\u001b[1;94m    labels: C'est génial ! Depuis combien de temps faites-vous ce travail ? \u001b[0;0m\n",
            "\u001b[0;95m     model: c ' est génial . je suis sûr que vous avez __unk__ is à faire ça .\u001b[0;0m\n",
            "\u001b[0mDepuis un bon nombre d'années maintenant.\u001b[0;0m\n",
            "\u001b[1;94m    labels: On dirait que ça peut être un travail dangereux parfois.\u001b[0;0m\n",
            "\u001b[0;95m     model: c ' est génial ! je suis sûr que vous avez beaucoup de temps pour travailler .\u001b[0;0m\n",
            "\u001b[0mC'est vrai, surtout si vous ne prenez pas les mesures appropriées.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Eh bien, vous êtes entré dans un métier qui vous garantira toujours du travail.\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis d ' accord . je suis un peu déçu .\u001b[0;0m\n",
            "\u001b[0mC'est vrai, surtout dans cette économie\u001b[0;0m\n",
            "\u001b[1;94m    labels: J'ai moi-même un emploi assez stable, mais surtout du travail de bureau.\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis sûr que vous avez beaucoup de chance .\u001b[0;0m\n",
            "\u001b[0mEst-ce que ça vous plaît ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Je le fais vraiment, mais parfois j'aimerais être plus actif et debout.\u001b[0;0m\n",
            "\u001b[0;95m     model: oui , je suis un peu déçu .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: french_blended_skill_talk- - -\u001b[0;0m\n",
            "\u001b[0mJe me sens très bien dans ma relation avec mon partenaire. Mon partenaire apprécie mon opinion sur les choses.\u001b[0;0m\n",
            "\u001b[1;94m    labels: ok, si doux\u001b[0;0m\n",
            "\u001b[0;95m     model: c ' est bien . je suis sûr que tu es très fier de lui .\u001b[0;0m\n",
            "\u001b[0mEt vous, quelqu'un vers qui vous pouvez vous tourner ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Bien sûr, j'ai des amis avec qui je suis toujours libre de partager.\u001b[0;0m\n",
            "\u001b[0;95m     model: je ne suis pas sûr .\u001b[0;0m\n",
            "\u001b[0mJ'aime faire du vélo tout terrain avec mes amis.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Je n'ai jamais fait ça.  Je ne suis pas vraiment du genre à faire de l'activité physique, mais je serais prêt à essayer, j'imagine.\u001b[0;0m\n",
            "\u001b[0;95m     model: j ' aime aussi faire du vélo .\u001b[0;0m\n",
            "\u001b[0mJ'aime aussi aller prendre un thé à bulles, c'est tellement amusant.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Ça, c'est plus mon truc. Ça a un goût un peu étrange, mais j'aime ça.\u001b[0;0m\n",
            "\u001b[0;95m     model: je ne suis pas sûr de ce que vous aimez faire .\u001b[0;0m\n",
            "\u001b[0mExactement, c'est bizarre mais je continue à en redemander. Tellement étrange.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Oui, c'est juste une de ces choses. Une fois que vous commencez, vous ne pouvez plus vous arrêter.\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis sûr que vous avez __unk__ is à faire ça .\u001b[0;0m\n",
            "\u001b[0mY a-t-il quelque chose que vous aimez vraiment faire ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: J'aime me détendre avec des amis, boire un petit verre, ce genre de choses.\u001b[0;0m\n",
            "\u001b[0;95m     model: je ne suis pas sûr , mais je suis sûr que je vais faire ça .\u001b[0;0m\n",
            "\u001b[0mÇa semble être une chose assez cool à faire, je suis assez décontracté aussi.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Yea. Je veux dire, le monde bouge si vite, parfois vous devez juste prendre du recul et laisser le passé s'accomplir.\u001b[0;0m\n",
            "\u001b[0;95m     model: oui , c ' est vrai .\u001b[0;0m\n"
          ]
        }
      ],
      "source": [
        "from parlai.scripts.display_model import DisplayModel\n",
        "DisplayModel.main(\n",
        "    task='french_blended_skill_talk',\n",
        "    model_file= f'{finetuned_model_path}/model',\n",
        "    num_examples=20,\n",
        "    skip_generation=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap-cP0uzFF4y",
        "outputId": "d35ec469-4e4a-40ef-f059-ecad54e1ee19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12:46:14 | Opt:\n",
            "12:46:14 |     allow_missing_init_opts: False\n",
            "12:46:14 |     batchsize: 1\n",
            "12:46:14 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "12:46:14 |     datatype: train:ordered\n",
            "12:46:14 |     dict_class: None\n",
            "12:46:14 |     display_add_fields: \n",
            "12:46:14 |     download_path: None\n",
            "12:46:14 |     dynamic_batching: None\n",
            "12:46:14 |     fromfile_datapath: copied_dataset_french_bst/\n",
            "12:46:14 |     fromfile_datatype_extension: True\n",
            "12:46:14 |     hide_labels: False\n",
            "12:46:14 |     ignore_agent_reply: True\n",
            "12:46:14 |     image_cropsize: 224\n",
            "12:46:14 |     image_mode: raw\n",
            "12:46:14 |     image_size: 256\n",
            "12:46:14 |     init_model: None\n",
            "12:46:14 |     init_opt: None\n",
            "12:46:14 |     is_debug: False\n",
            "12:46:14 |     loglevel: info\n",
            "12:46:14 |     max_display_len: 1000\n",
            "12:46:14 |     model: None\n",
            "12:46:14 |     model_file: None\n",
            "12:46:14 |     multitask_weights: [1]\n",
            "12:46:14 |     mutators: None\n",
            "12:46:14 |     num_examples: 20\n",
            "12:46:14 |     override: \"{'task': 'fromfile:parlaiformat', 'fromfile_datapath': 'copied_dataset_french_bst/', 'fromfile_datatype_extension': True, 'num_examples': 20}\"\n",
            "12:46:14 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "12:46:14 |     starttime: May24_12-46\n",
            "12:46:14 |     task: fromfile:parlaiformat\n",
            "12:46:14 |     verbose: False\n",
            "12:46:14 | creating task(s): fromfile:parlaiformat\n",
            "12:46:14 | Loading ParlAI text data: copied_dataset_french_bst/_train.txt\n",
            "\u001b[1;31m- - - NEW EPISODE: copied_dataset_french_bst/_train.txt - - -\u001b[0;0m\n",
            "\u001b[0mJ'aime la musique live, c'est pourquoi j'essaie d'aller aux concerts.\u001b[0;0m\n",
            "   \u001b[1;94mMoi aussi. Qu'est-ce que tu aimes ?\u001b[0;0m\n",
            "\u001b[0mJ'aime jouer la comédie, j'espère être un acteur, et vous ?\u001b[0;0m\n",
            "   \u001b[1;94mC'est bon. Vous avez des enfants ?\u001b[0;0m\n",
            "\u001b[0mNon, mais un jour.\u001b[0;0m\n",
            "   \u001b[1;94mc'est bien. J'ai 2\u001b[0;0m\n",
            "\u001b[0mLorsque j'aurai terminé mes études, je compte fonder une famille.\u001b[0;0m\n",
            "   \u001b[1;94mc'est génial ! tu seras prête\u001b[0;0m\n",
            "\u001b[0mJe l'espère, quel âge ont vos enfants ?\u001b[0;0m\n",
            "   \u001b[1;94m5 & 7. Ils me prennent beaucoup de temps.\u001b[0;0m\n",
            "\u001b[0mJ'imagine. Je suis sûr qu'ils sont de grands enfants.\u001b[0;0m\n",
            "   \u001b[1;94mheureusement, ils aiment les fleurs tout autant que moi. Nous passons beaucoup de temps dans le jardin.\u001b[0;0m\n",
            "\u001b[0mJ'aimerais avoir plus de temps pour faire ce genre de choses. L'école de médecine est épuisante. \u001b[0;0m\n",
            "   \u001b[1;94mOn dirait bien. As-tu trouvé un travail d'actrice, cependant ?\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: copied_dataset_french_bst/_train.txt - - -\u001b[0;0m\n",
            "\u001b[0mMoi aussi. Qu'est-ce que tu aimes ?\u001b[0;0m\n",
            "   \u001b[1;94mJ'aime jouer la comédie, j'espère être un acteur, et vous ?\u001b[0;0m\n",
            "\u001b[0mC'est bon. Vous avez des enfants ?\u001b[0;0m\n",
            "   \u001b[1;94mNon, mais un jour.\u001b[0;0m\n",
            "\u001b[0mc'est bien. J'ai 2\u001b[0;0m\n",
            "   \u001b[1;94mLorsque j'aurai terminé mes études, je compte fonder une famille.\u001b[0;0m\n",
            "\u001b[0mc'est génial ! tu seras prête\u001b[0;0m\n",
            "   \u001b[1;94mJe l'espère, quel âge ont vos enfants ?\u001b[0;0m\n",
            "\u001b[0m5 & 7. Ils me prennent beaucoup de temps.\u001b[0;0m\n",
            "   \u001b[1;94mJ'imagine. Je suis sûr qu'ils sont de grands enfants.\u001b[0;0m\n",
            "\u001b[0mheureusement, ils aiment les fleurs tout autant que moi. Nous passons beaucoup de temps dans le jardin.\u001b[0;0m\n",
            "   \u001b[1;94mJ'aimerais avoir plus de temps pour faire ce genre de choses. L'école de médecine est épuisante. \u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: copied_dataset_french_bst/_train.txt - - -\u001b[0;0m\n",
            "\u001b[0mOh, j'adore les lasagnes. Je fais mes propres nouilles ainsi que la sauce. \u001b[0;0m\n",
            "   \u001b[1;94mWow.  C'est incroyable.  J'ai lu que les lasagnes sont nées en Italie au Moyen-âge.  \u001b[0;0m\n",
            "\u001b[0mOh vraiment ? C'est intéressant. En fait, je suis moi-même italien.\u001b[0;0m\n",
            "   \u001b[1;94mGénial. Moi et mon partenaire venons d'acheter une maison. Je suis impatient de cuisiner dans ma cuisine.\u001b[0;0m\n",
            "\u001b[0mDéménager dans un nouvel endroit peut être très amusant. Êtes-vous un bon cuisinier ?\u001b[0;0m\n",
            "   \u001b[1;94mJ'aime à le penser. J'aime aussi faire du café pour le plaisir après le repas.\u001b[0;0m\n",
            "\u001b[0mMmm. Ça a l'air délicieux en ce moment.\u001b[0;0m\n",
            "   \u001b[1;94mQu'est-ce que vous aimez faire ?\u001b[0;0m\n",
            "\u001b[0mEh bien j'aime les tatouages et les piercings, je travaille sur mon prochain en ce moment.\u001b[0;0m\n",
            "   \u001b[1;94mLes piercings sont cool. Mais je n'ai pas de tatouages. J'ai trop peur. Je veux en avoir\u001b[0;0m\n",
            "\u001b[0mQue prendriez-vous ?\u001b[0;0m\n",
            "   \u001b[1;94mPeut-être quelque chose pour mes enfants. J'ai toujours voulu un symbole d'anarchie.\u001b[0;0m\n",
            "\u001b[0mHaha c'est une idée cool.\u001b[0;0m\n",
            "   \u001b[1;94mJ'aime penser que je suis cool aussi. Avec un peu de chance, un jour.\u001b[0;0m\n",
            "12:46:15 | loaded 9638 episodes with a total of 59700 examples\n"
          ]
        }
      ],
      "source": [
        "# from parlai.scripts.display_data import DisplayData\n",
        "# DisplayData.main(task='empathetic_dialogues', num_examples=10)\n",
        "\n",
        "from parlai.scripts.display_data import DisplayData\n",
        "DisplayData.main(\n",
        "    task='fromfile:parlaiformat',\n",
        "    fromfile_datapath='copied_dataset_french_bst/',\n",
        "    fromfile_datatype_extension=True,\n",
        "    # model_file= f'{finetuned_model_path}/model',\n",
        "    # dict_file= dict_file,\n",
        "\n",
        "    num_examples=20,\n",
        "    # skip_generation=False,\n",
        "\n",
        "    # beam_min_length= 20,\n",
        "    # beam_block_ngram= 3,\n",
        "    # beam_context_block_ngram= 3,\n",
        "    # beam_size= 10,\n",
        "\n",
        "    # inference= \"beam\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "blender-90m-with-double-sized-data.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyObiLx00m2f3w9QjC4g6PQQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}