{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirpaia/blenderbot/blob/main/french_reddit_data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Installation & Download the dataset"
      ],
      "metadata": {
        "id": "5_V-VgrZnr47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the kaggle.json file"
      ],
      "metadata": {
        "id": "thWPbSjnpHBQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynFAgRjBRCKC",
        "outputId": "72ed6801-19c0-4f3e-dd9d-284787d27f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "# download from kaggle\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3nnMsMtTBIu",
        "outputId": "de33125b-ee1e-466b-c0eb-17dd871d8503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading french-reddit-discussion.zip to /content\n",
            " 97% 415M/426M [00:03<00:00, 108MB/s]\n",
            "100% 426M/426M [00:04<00:00, 110MB/s]\n",
            "Archive:  french-reddit-discussion.zip\n",
            "  inflating: final_SPF_2.xml         \n",
            "  inflating: spf.tar.gz              \n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download breandan/french-reddit-discussion\n",
        "! unzip french-reddit-discussion.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoqw6eOrO4W2",
        "outputId": "7c437ce0-db1a-41e6-fa65-e518ddb5c018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Loading the dataset"
      ],
      "metadata": {
        "id": "-eTjcM7-oCFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "1upQcJAsQ3mK",
        "outputId": "5854a14e-db38-45e8-bdfd-e16d652a3e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of conversations:  556622\n",
            "number of comments:  1583083\n",
            "All done in : 26.908819913864136  seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  link_id subreddit_id      uid comment_id score parent_id  create_utc  \\\n",
              "0   8r1kz        2qhjz  1688932    c0a62uj     3     8r1kz  1244576002   \n",
              "1   8r1kz        2qhjz   786883    c0a6lmb     1   c0a62uj  1244621120   \n",
              "2   8sncs        2qhjz   390497    c0aawpk     1     8sncs  1245076061   \n",
              "3   8sncs        2qhjz    32884    c0aaxba     3   c0aawpk  1245077396   \n",
              "4   8v13c        2qhjz   796919    c0aj3ov     2     8v13c  1245830384   \n",
              "\n",
              "                                                text  \n",
              "0  Ironie : l'article disant qu'on est plus capab...  \n",
              "1  Moi-même, j'ai dû me forcer pour arriver jusqu...  \n",
              "2  Service qui sera rendu au contribuable pour la...  \n",
              "3  Eeeeh oui ! 70 millions pour une loi qui aura ...  \n",
              "4  Est-ce qu'elle a vraiment commis des crimes qu...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87e0ba61-a433-418c-a2c0-04c8bf61032b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link_id</th>\n",
              "      <th>subreddit_id</th>\n",
              "      <th>uid</th>\n",
              "      <th>comment_id</th>\n",
              "      <th>score</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>create_utc</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8r1kz</td>\n",
              "      <td>2qhjz</td>\n",
              "      <td>1688932</td>\n",
              "      <td>c0a62uj</td>\n",
              "      <td>3</td>\n",
              "      <td>8r1kz</td>\n",
              "      <td>1244576002</td>\n",
              "      <td>Ironie : l'article disant qu'on est plus capab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8r1kz</td>\n",
              "      <td>2qhjz</td>\n",
              "      <td>786883</td>\n",
              "      <td>c0a6lmb</td>\n",
              "      <td>1</td>\n",
              "      <td>c0a62uj</td>\n",
              "      <td>1244621120</td>\n",
              "      <td>Moi-même, j'ai dû me forcer pour arriver jusqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8sncs</td>\n",
              "      <td>2qhjz</td>\n",
              "      <td>390497</td>\n",
              "      <td>c0aawpk</td>\n",
              "      <td>1</td>\n",
              "      <td>8sncs</td>\n",
              "      <td>1245076061</td>\n",
              "      <td>Service qui sera rendu au contribuable pour la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8sncs</td>\n",
              "      <td>2qhjz</td>\n",
              "      <td>32884</td>\n",
              "      <td>c0aaxba</td>\n",
              "      <td>3</td>\n",
              "      <td>c0aawpk</td>\n",
              "      <td>1245077396</td>\n",
              "      <td>Eeeeh oui ! 70 millions pour une loi qui aura ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8v13c</td>\n",
              "      <td>2qhjz</td>\n",
              "      <td>796919</td>\n",
              "      <td>c0aj3ov</td>\n",
              "      <td>2</td>\n",
              "      <td>8v13c</td>\n",
              "      <td>1245830384</td>\n",
              "      <td>Est-ce qu'elle a vraiment commis des crimes qu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87e0ba61-a433-418c-a2c0-04c8bf61032b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-87e0ba61-a433-418c-a2c0-04c8bf61032b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-87e0ba61-a433-418c-a2c0-04c8bf61032b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import time \n",
        "import lxml.etree as ET\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "file_path = 'final_SPF_2.xml'\n",
        "start=time.time()\n",
        "#Initializes the parser\n",
        "parser = ET.XMLParser(recover=True)\n",
        "#Parses the file\n",
        "tree = ET.parse(file_path, parser=parser)\n",
        "xroot = tree.getroot()\n",
        "\n",
        "#One conversation -> one line in the data array\n",
        "dfcols = ['link_id', 'subreddit_id', 'uid',\"comment_id\",'score', 'parent_id', 'create_utc', 'text']\n",
        "data =np.array(\n",
        "    (\n",
        "        [\n",
        "            [\n",
        "                [\n",
        "                    node.attrib.get('link_id'),\n",
        "                    node.attrib.get('subreddit_id'), \n",
        "                    node.getchildren()[j].get('uid'), \n",
        "                    node.getchildren()[j].get('comment_id'), \n",
        "                    node.getchildren()[j].get('score'), \n",
        "                    node.getchildren()[j].get('parent_id'), \n",
        "                    node.getchildren()[j].get('create_utc'),\n",
        "                    node.getchildren()[j].text\n",
        "                ] \n",
        "                for j in range(len(node.getchildren()))\n",
        "            ] \n",
        "            for node in xroot\n",
        "        ]\n",
        "     ), \n",
        "    dtype=object)\n",
        "\n",
        "print('number of conversations: ',data.shape[0])\n",
        "\n",
        "#one comments -> one line in the data array\n",
        "data=np.array([liste for conversation in data for liste in conversation], dtype=object)\n",
        "print('number of comments: ',data.shape[0])\n",
        "\n",
        "df_xml = pd.DataFrame(data=data, columns=dfcols)\n",
        "print('All done in :',time.time()-start,' seconds')\n",
        "\n",
        "df_xml.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We assumed every thread in Reddit as a tree and this recursive functions tries to find all paths in a tree and consider each one as a dialog"
      ],
      "metadata": {
        "id": "vQk2RT5boJhk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvZx6GtCTuJC",
        "outputId": "35d40703-d96b-4921-c2fb-04a18a177089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"0\\t['c0cq7vy', 'c0cqynp', 'c0cqyze', 'c0cr17m', 'c0cr1hs']\\n\"]\n"
          ]
        }
      ],
      "source": [
        "# a recusive function to get all children\n",
        "def get_children(i, comment_id, comment_ids = []):\n",
        "    children = df_xml[df_xml['parent_id'] == comment_id]\n",
        "    if (len(children) == 0): \n",
        "        return comment_ids\n",
        "    else:\n",
        "        for child in children.values:\n",
        "            temp_comment_ids = []\n",
        "            temp_comment_ids.extend(comment_ids)\n",
        "            temp_comment_ids.append(child[3])\n",
        "            \n",
        "            path = get_children(i, child[3],temp_comment_ids)\n",
        "            if (path != None):\n",
        "                all_dialogs.append(f\"{i}\\t{path}\\n\")\n",
        "        \n",
        "\n",
        "all_dialogs = []\n",
        "get_children(0, '9gw99')\n",
        "print(all_dialogs)\n",
        "# print(get_children('c0imipv')) # root: c0imipv  | c0impi6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding all paths and save Ids in the output file"
      ],
      "metadata": {
        "id": "Ja3KOUtMozCq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFfU9d2HT2uL"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/colabs/aliae-workspace/datasets/'\n",
        "\n",
        "import os.path\n",
        "import time\n",
        "print(len(df_xml[df_xml['link_id'] == df_xml['parent_id']].values))\n",
        "\n",
        "all_dialogs = []\n",
        "starttime = time.time()\n",
        "last_index_in_file = 0\n",
        "if os.path.exists(f\"{data_path}french_reddit_all_dialog_turns_ids.txt\"):\n",
        "  with open(f\"{data_path}french_reddit_all_dialog_turns_ids.txt\") as f:\n",
        "    last_line = f.readlines()[-1]\n",
        "\n",
        "  if (last_line != \"\" or last_line != None):\n",
        "    last_index_in_file = int(last_line.split(\"\\t\")[0]) + 1\n",
        "    print(\"last_index_in_file:\" , last_index_in_file)\n",
        "\n",
        "for i, row in enumerate(df_xml[df_xml['link_id'] == df_xml['parent_id']].values[last_index_in_file:]):\n",
        "    get_children(last_index_in_file + i, row[5])\n",
        "\n",
        "    if (last_index_in_file + i) % 20 == 0 : \n",
        "        with open(f\"{data_path}french_reddit_all_dialog_turns_ids.txt\", 'a') as f:\n",
        "          f.writelines(all_dialogs)\n",
        "          print(f\"i:{i}\", f\"last index:{(last_index_in_file + i)}\", f\"dialogs: {len(all_dialogs)}\", f\"time: {round(time.time() - starttime, 2)}\")\n",
        "          all_dialogs = []\n",
        "        # starttime = time.time()\n",
        "    \n",
        "    if (last_index_in_file + i) % 50000 == 0: break\n",
        "\n",
        "print(len(all_dialogs))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Reddit Ids > Dialog > ParlAI format > Train/Valid/Test"
      ],
      "metadata": {
        "id": "C7ECLR95o_du"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Functions"
      ],
      "metadata": {
        "id": "tCqvHYTtvG38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer_dialog(d):\n",
        "    if len(d)%2 !=0: d = d[:-1]\n",
        "    t = \"\"\n",
        "    for i in range(0,len(d),2):\n",
        "        u1 = d[i]\n",
        "        u2 = d[i+1]\n",
        "\n",
        "        if (i+2) != len(d):\n",
        "            t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\n\"\n",
        "        else:\n",
        "            t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\t\"+\"episode_done:True\"+\"\\n\"\n",
        "    return t\n",
        "    \n",
        "t = ['hello','how are you','good','bye', 'to be removed']\n",
        "print(transfer_dialog(t))\n",
        "\n",
        "def colored(r, g, b, text):\n",
        "    return \"\\033[38;2;{};{};{}m{} \\033[38;2;255;255;255m\".format(r, g, b, text)\n",
        "  \n",
        "text = 'Hello, World'\n",
        "colored_text = colored(0, 255, 0, text)\n",
        "print(colored_text)\n",
        "\n",
        "def convert_parlai_format_to_list_of_turns(lines):\n",
        "    result = []\n",
        "    for line in lines:\n",
        "        text_label = line.split(\"\\t\")\n",
        "        if len(text_label) >=2:\n",
        "            result.append(text_label[0].replace(\"text:\", \"\"))\n",
        "            result.append(text_label[1].replace(\"labels:\", \"\").replace(\"\\n\",\"\"))\n",
        "\n",
        "            print(len(text_label[0].split()), colored(200,200,200, text_label[0]))\n",
        "            print(\"    \",len(text_label[1].split()) , colored(0,150,0, text_label[1]))\n",
        "    return result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei3qVOREux0X",
        "outputId": "89ac5714-5dbb-48fd-89aa-b4c275d6ad5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:hello\tlabels:how are you\n",
            "text:good\tlabels:bye\tepisode_done:True\n",
            "\n",
            "\u001b[38;2;0;255;0mHello, World \u001b[38;2;255;255;255m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_line_to_list_of_ids(line):\n",
        "    return line.split(\"\\t\")[1].replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\n\",\"\").replace(\" \",\"\").replace(\"'\",\"\").split(\",\")"
      ],
      "metadata": {
        "id": "3cIbd72cu9eb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_urls (vTEXT):\n",
        "    vTEXT = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', vTEXT, flags=re.MULTILINE)\n",
        "    return(vTEXT)\n",
        "    \n",
        "print( remove_urls(\"this is a test https://sdfs.sdfsdf.com/sdfsdf/sdfsdf/sd/sdfsdfs?bob=%20tree&jef=man lets see this too https://sdfsdf.fdf.com/sdf/f end\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqWK6bnjvDVu",
        "outputId": "53cae725-5ebb-4ce8-ab29-3d9dd50404ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is a test  lets see this too  end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/colabs/aliae-workspace/datasets/'\n",
        "with open(f\"{data_path}french_reddit_all_dialog_turns_ids.txt\") as f:\n",
        "    lines = f.readlines()"
      ],
      "metadata": {
        "id": "0VXxT5ZgpBZ5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "# print(len(lines))\n",
        "# print(sum([1 for l in lines if len(convert_line_to_list_of_ids(l)) == 10]))\n",
        "print(len(lines))\n",
        "\n",
        "number_of_all_turns = 0\n",
        "\n",
        "flag = False\n",
        "dict_xml = df_xml.set_index('comment_id').to_dict()['text']\n",
        "dialogs_in_parlai_format = []\n",
        "for index, line in enumerate(lines):\n",
        "    ids = convert_line_to_list_of_ids(line)\n",
        "\n",
        "    if len(ids) >= 6: \n",
        "    #     print(index)\n",
        "    #     break\n",
        "        turns = []\n",
        "        for ii, id in enumerate(ids):\n",
        "            text = dict_xml[id].replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
        "            text = remove_urls(text)\n",
        "            if len(text.split()) > 128:\n",
        "                # flag = True\n",
        "                turns.append(' '.join(text.split()[:128]))\n",
        "                break\n",
        "            else:\n",
        "                turns.append(text)\n",
        "        if len(turns) >= 6: \n",
        "            # print(\"\\n\",line, ii)\n",
        "            # print(\"\\n\",text)\n",
        "            # print(\"\\n\",turns)\n",
        "            # break\n",
        "            dialogs_in_parlai_format.append([transfer_dialog(turns),len(turns)])\n",
        "\n",
        "    if index > 0 and index % 100000 == 0: print(f\"index: {index}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_hdgn83p5CU",
        "outputId": "17f2666e-d75d-44b2-b319-d46ff3da5a3e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "973124\n",
            "\n",
            " 89\t['c0taiz9', 'c0tapmq', 'c0tas0l', 'c0tatby', 'c0taw1u', 'c0tax6a', 'c0tayek']\n",
            " 2\n",
            "\n",
            " \"Quant à l'épithète \"enculé\", elle stigmatise la passivité de l'homme bestialisé\" Pratiquer de l'intellectualisme aussi pédant, m'hérisse les poils. Ce genre de sophistication linguistique est pour moi de la poudre aux yeux quand on a rien à dire d'intéressant. Les insultes sont le pain quotidien de beaucoup de jeunes, ce ne sont plus des insultes mais des constructions élaborées à la sémantique nuancée et cachée. J'adore traiter mes amis de gros enculés pour un rien, c'est un acte d'amour. Ce mec n'a rien compris à la beauté de l'argot. Je dis des choses bien plus blessantes avec un registre soutenu qu'avec des insultes. Et puis, il n'y a pas de débat à avoir. Subitement l'opinion francaise s'offusque de gros mots alors que les politiques nous chient dans les bottes à longueur de journées, mais bien sûr avec verve. Encore un cache misère du désert intellectuel Français. \n",
            "\n",
            " [\"Cet article pue la condescendance bourgeoise et rétrograde, il n'ont rien d'autre à foutre au Monde? \", 'J\\'aimerais bien que tu m\\'expliques où tu vois de la \"condescendance bourgeoise et rétrograde\" dans cet article? D\\'autre part, il n\\'est pas écrit par un journaliste du monde, donc je ne vois vraiment pas ce que tu leur reproches.', '\"Quant à l\\'épithète \"enculé\", elle stigmatise la passivité de l\\'homme bestialisé\" Pratiquer de l\\'intellectualisme aussi pédant, m\\'hérisse les poils. Ce genre de sophistication linguistique est pour moi de la poudre aux yeux quand on a rien à dire d\\'intéressant. Les insultes sont le pain quotidien de beaucoup de jeunes, ce ne sont plus des insultes mais des constructions élaborées à la sémantique nuancée et cachée. J\\'adore traiter mes amis de gros enculés pour un rien, c\\'est un acte d\\'amour. Ce mec n\\'a rien compris à la beauté de l\\'argot. Je dis des choses bien plus blessantes avec un registre soutenu qu\\'avec des insultes. Et puis, il n\\'y a pas de débat à avoir. Subitement l\\'opinion francaise s\\'offusque de gros mots alors que les politiques nous chient dans les']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dialogs_in_parlai_format))\n",
        "import statistics\n",
        "# [a for a in dialogs_in_parlai_format][:5]\n",
        "print(statistics.mean([a[1] for a in dialogs_in_parlai_format]))\n",
        "print(statistics.mean([len(a[0].split()) for a in dialogs_in_parlai_format]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cM4lsECzWNO",
        "outputId": "e99a1b1d-14ac-412f-feda-777afbadb6c5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121082\n",
            "7.282841380221668\n",
            "233.61439355147752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dialogs_in_parlai_format[1]\n",
        "statistics.mean([len(a.split()) for a in convert_parlai_format_to_list_of_turns(dialogs_in_parlai_format[1][0].split(\"\\n\"))])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXGi1uSpx5zH",
        "outputId": "38e26178-2b60-41b7-c490-1095ab4ad273"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 \u001b[38;2;200;200;200mtext:Nice, ou Sophia-Antipolis? C'est pas la même chose! Je pose la question parce qu'on est sur reddit, donc il y a des chances que ce soit la première option :)Pour la banque je ne sais pas trop, pour le mobile ça dépend de ta consomation (il faut nous en dire un peu plus). Enfin pour les assurances, la sécu couvre la plupart des frais, tu peux y rajouter une bonne mutuelle (vérifie que ton employeur ne t'en fournit pas une gratuitement).Ton français n'est pas si mauvais! Si tu ne comprends pas quelque chose, n'hésite pas à demander, je peux traduire. \u001b[38;2;255;255;255m\n",
            "     49 \u001b[38;2;0;150;0mlabels:Nice, je suis etudiant a edhec, pour le mobile je besoin quel que chose qui avais le data, qu'est ce que c'est la secu?, (Je dois trouver les accents sur se l'ordinateur)Je besoin becoup de practique avec mon francais, est-ce que il y a de bonne shopping a Nice? \u001b[38;2;255;255;255m\n",
            "8 \u001b[38;2;200;200;200mtext:un conseil, n'habite pas à coté de l'Edhec. \u001b[38;2;255;255;255m\n",
            "     17 \u001b[38;2;0;150;0mlabels:Peut etre la vielle ville?est-ce que il y a raison de n'habite pas a cote de l'ledhec? \u001b[38;2;255;255;255m\n",
            "27 \u001b[38;2;200;200;200mtext:pas très beau comme quartier. un peu mort aussi.la vielle ville c'est cool très vivant, mais un peu loin de l'edhec. tu risques de galérer en bus. \u001b[38;2;255;255;255m\n",
            "     22 \u001b[38;2;0;150;0mlabels:ah, est-ce que pres de gare es bon?Je pouvais prender la train a l'ecole?Quelle part dans votre opinion es la place optimaux?  \u001b[38;2;255;255;255m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37.166666666666664"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_reddit/'\n",
        "# with open(data_path + \"train.txt\", \"w\") as f:\n",
        "#     f.writelines(dialogs_in_parlai_forma\n",
        "\n",
        "df = pd.DataFrame ([a[0] for a in dialogs_in_parlai_format], columns = ['dialog'])\n",
        "train, valid, test = np.split(df.sample(frac=1, random_state=42), \n",
        "                                 [int(.8*len(df)), \n",
        "                                  int(.9*len(df))])\n",
        "print(f\"train set: {len(train)}, validation set: {len(valid)},test set: {len(test)}\")\n",
        "\n",
        "with open(f\"{data_path}/data_train.txt\",\"w\") as f:\n",
        "    f.write('\\n'.join(a[0] for a in train.values))\n",
        "\n",
        "with open(f\"{data_path}/data_valid.txt\",\"w\") as f:\n",
        "    f.write('\\n'.join(a[0] for a in valid.values))\n",
        "\n",
        "with open(f\"{data_path}/data_test.txt\",\"w\") as f:\n",
        "    f.write('\\n'.join(a[0] for a in test.values))\n",
        "print('done!')"
      ],
      "metadata": {
        "id": "V4VtjzeXwGTl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a1c4ca-9127-40aa-cab0-f77a2831496b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: 96865, validation set: 12108,test set: 12109\n",
            "done!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "french_reddit data_preparation",
      "provenance": [],
      "authorship_tag": "ABX9TyOGvoRScQikWkioNDHWfONy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}