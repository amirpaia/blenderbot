{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirpaia/blenderbot/blob/main/blender_90m_400m_multitask_double_sided.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SONwSWMp6qPv"
      },
      "source": [
        "# 0.Installing prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9d-SZ_On6Kxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a4c20b-f15b-46b3-c106-e55a76be8f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun 23 22:11:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BegaSUz6iUz",
        "outputId": "f0731ebc-38aa-4e0f-e6cb-1346a0bfc237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SzGRXHQ6kDQ",
        "outputId": "14320eb3-d4b2-4e97-9d41-7a5b9ecc6172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AWDakYmy6mIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50966b44-8b40-4c36-e226-21fcbfc067ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-4.20.1\n"
          ]
        }
      ],
      "source": [
        "mydrive_path = '/content/drive/MyDrive/colabs/blender-models/'\n",
        "# !pip uninstall -q parlai\n",
        "!pip install -q parlai\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -v /content/drive/MyDrive/colabs/blender-models/finetuned-reddit-90m--finetuned-4tasks-5epochs/* /content/drive/MyDrive/colabs/blender-models/finetuned-reddit-90m/\n",
        "# !cp -v /content/drive/MyDrive/colabs/blender-models/finetuned-reddit_LELU-400m/* /content/drive/MyDrive/colabs/blender-models/finetuned-reddit_LELU-4tasks-400m/"
      ],
      "metadata": {
        "id": "5ye1o1VhUSxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model --task blended_skill_talk --model-file zoo:blender/blender_90M/model --batchsize 32"
      ],
      "metadata": {
        "id": "xofOAv4XPge4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIJEq9_r63hi"
      },
      "source": [
        "# 1.Preparing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R-fgBUdcPX5"
      },
      "source": [
        "## Genreal Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47u8M3RK65m_",
        "outputId": "6c8935f8-bc3a-4e78-f276-d21634a76565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:hello\tlabels:how are you\n",
            "text:good\tlabels:bye\tepisode_done:True\n",
            "\n",
            "text:hello\tlabels:how are you\n",
            "text:good\tlabels:bye\tepisode_done:True\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def transfer_list_of_turns_to_dialog(d):\n",
        "    if len(d)%2 !=0: d = d[:-1]\n",
        "    t = \"\"\n",
        "    for i in range(0,len(d),2):\n",
        "        u1 = d[i]\n",
        "        u2 = d[i+1]\n",
        "\n",
        "        if (i+2) != len(d):\n",
        "            t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\n\"\n",
        "        else:\n",
        "            t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\t\"+\"episode_done:True\"+\"\\n\"\n",
        "    return t\n",
        "\n",
        "def transfer_list_of_pairs_to_dialog(d):\n",
        "  t = \"\"\n",
        "  for i, text_label_pair in enumerate(d):\n",
        "    u1 = text_label_pair[0]\n",
        "    u2 = text_label_pair[1]\n",
        "\n",
        "    if i != (len(d) - 1):\n",
        "      t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\n\"\n",
        "    else:\n",
        "      t += \"text:\"+u1+\"\\t\"+\"labels:\"+u2+\"\\t\"+\"episode_done:True\"+\"\\n\"\n",
        "\n",
        "  return t\n",
        "\n",
        "def convert_parlai_format_to_list_of_turns(lines):\n",
        "    result = []\n",
        "    for line in lines:\n",
        "        text_label = line.split(\"\\t\")\n",
        "        result.append(text_label[0].replace(\"text:\", \"\"))\n",
        "        result.append(text_label[1].replace(\"labels:\", \"\").replace(\"\\n\",\"\"))\n",
        "    return result\n",
        "\n",
        "t = ['hello','how are you','good','bye','test']\n",
        "print(transfer_list_of_turns_to_dialog(t))\n",
        "\n",
        "t = [['hello','how are you'],['good','bye']]\n",
        "print(transfer_list_of_pairs_to_dialog(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VIROa77CJtG9"
      },
      "outputs": [],
      "source": [
        "def make_dataset_double_sided(lines, path, filename): \n",
        "    # train[:10]\n",
        "    all_dialogs_parlai_format = []\n",
        "    dialog = []\n",
        "    for line in lines:\n",
        "        dialog.append(line)\n",
        "        if 'episode_done:True' in line:\n",
        "            turns = convert_parlai_format_to_list_of_turns(dialog)\n",
        "            first_parlai_dialog = transfer_list_of_turns_to_dialog(turns)\n",
        "            second_parlai_dialog = transfer_list_of_turns_to_dialog(turns[1:])\n",
        "\n",
        "            all_dialogs_parlai_format.append(first_parlai_dialog)\n",
        "            all_dialogs_parlai_format.append(second_parlai_dialog)\n",
        "\n",
        "            dialog = []\n",
        "            # break\n",
        "    print(sum([1 for a in lines if 'episode_done:True' in a]), len(all_dialogs_parlai_format))\n",
        "\n",
        "    with open(f\"{path}{filename}\", \"w\") as f:\n",
        "        f.writelines(all_dialogs_parlai_format)\n",
        "\n",
        "# !mkdir /content/dataset_french_bst/\n",
        "# make_dataset_double_sided(lines,\"/content/dataset_french_bst/\", \"train.txt\")\n",
        "\n",
        "\n",
        "\n",
        "# # import os.path\n",
        "# # from os import path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE45ZyKC8WjC"
      },
      "source": [
        "## XPersona"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZmSJtQG8Y1o",
        "outputId": "fa893f2e-178e-4aaf-c9e6-15a30a47e026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Xpersona'...\n",
            "remote: Enumerating objects: 285, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 285 (delta 6), reused 6 (delta 4), pack-reused 275\u001b[K\n",
            "Receiving objects: 100% (285/285), 45.01 MiB | 20.63 MiB/s, done.\n",
            "Resolving deltas: 100% (96/96), done.\n",
            "Checking out files: 100% (218/218), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HLTCHKUST/Xpersona.git\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "with open('Xpersona/dataset/Fr_persona_train_corrected.json','r') as f:\n",
        "   train_data = json.load(f)\n",
        "\n",
        "dialogs_train = pd.DataFrame(train_data)['dialogue'].tolist()\n",
        "\n",
        "with open('Xpersona/dataset/Fr_persona_split_valid_human_annotated.json','r') as f:\n",
        "   valid_data = json.load(f)\n",
        "\n",
        "dialogs_valid = pd.DataFrame(valid_data)['dialogue'].tolist()\n",
        "\n",
        "with open('Xpersona/dataset/Fr_persona_split_test_human_annotated.json','r') as f:\n",
        "   test_data = json.load(f)\n",
        "\n",
        "dialogs_test = pd.DataFrame(test_data)['dialogue'].tolist()\n",
        "\n",
        "# dialogs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plw61KMBJU4I",
        "outputId": "6754feae-1328-4645-e1e7-6ab296a5e8f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/dataset_french_xpersona/': No such file or directory\n",
            "33756\n",
            "496\n",
            "498\n"
          ]
        }
      ],
      "source": [
        "data_path = \"/content/dataset_french_xpersona/\"\n",
        "!rm -R $data_path\n",
        "!mkdir $data_path\n",
        "\n",
        "def convert_xpersona_dialogs_to_parlai_format_file_and_double_sided(dialogs, filename):\n",
        "    all_dialogs_parlai_format = []\n",
        "    import numpy as np\n",
        "    for d in dialogs:\n",
        "        turns = np.reshape(d, (-1)).tolist()\n",
        "        all_dialogs_parlai_format.append(transfer_list_of_turns_to_dialog(turns))\n",
        "        all_dialogs_parlai_format.append(transfer_list_of_turns_to_dialog(turns[1:]))\n",
        "\n",
        "    print(len(all_dialogs_parlai_format))\n",
        "\n",
        "    with open(f\"{data_path}{filename}\",\"w\") as f:\n",
        "        f.writelines(all_dialogs_parlai_format)\n",
        "\n",
        "convert_xpersona_dialogs_to_parlai_format_file_and_double_sided(dialogs_train, \"train.txt\")\n",
        "convert_xpersona_dialogs_to_parlai_format_file_and_double_sided(dialogs_valid, \"valid.txt\")\n",
        "convert_xpersona_dialogs_to_parlai_format_file_and_double_sided(dialogs_test, \"test.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKlGi0f08zQc"
      },
      "outputs": [],
      "source": [
        "# data_path = \"/content/dataset_french_xpersona/\"\n",
        "# !rm -R $data_path\n",
        "# !mkdir $data_path\n",
        "\n",
        "# #region Training\n",
        "# data_train = \"\"\n",
        "# for d in dialogs_train:\n",
        "#   data_train += transfer_list_of_pairs_to_dialog(d)\n",
        "\n",
        "# file_train = open(f\"{data_path}train.txt\",\"w\")\n",
        "# print(\"Training Set:\", file_train.write(data_train))\n",
        "# #endregion \n",
        "    \n",
        "# #region Validation\n",
        "# data_valid = \"\"\n",
        "# for d in dialogs_valid:\n",
        "#   data_valid += transfer_list_of_pairs_to_dialog(d)\n",
        "\n",
        "# file_valid = open(f\"{data_path}valid.txt\",\"w\")\n",
        "# print(\"Validation Set:\", file_valid.write(data_valid))\n",
        "# #endregion\n",
        "\n",
        "# #region Test\n",
        "# data_test = \"\"\n",
        "# for d in dialogs_test:\n",
        "#   data_test += transfer_list_of_pairs_to_dialog(d)\n",
        "\n",
        "# file_test = open(f\"{data_path}test.txt\",\"w\")\n",
        "# print(\"Test Set:\", file_test.write(data_test))\n",
        "# #endregion \n",
        "\n",
        "# # print(len(data_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoSv5zhs8ZIv"
      },
      "source": [
        "## ED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mISEjZbP8dN-",
        "outputId": "015ee6db-1546-4f72-8fe6-e4bf1eecf57a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/dataset_french_ed/': No such file or directory\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_empathetic_dialogues/test.txt' -> '/content/dataset_french_ed/test.txt'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_empathetic_dialogues/train.txt' -> '/content/dataset_french_ed/train.txt'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_empathetic_dialogues/valid.txt' -> '/content/dataset_french_ed/valid.txt'\n"
          ]
        }
      ],
      "source": [
        "googledrive_data_path = \"/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_empathetic_dialogues/\"\n",
        "data_path = \"/content/dataset_french_ed/\"\n",
        "!rm -R $data_path\n",
        "!mkdir $data_path\n",
        "!cp -rv $googledrive_data_path* $data_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNbq22L-Khmg",
        "outputId": "7183e24f-74a6-4386-c421-51b755e362c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64636\n",
            "39057 5537 5093 49687\n"
          ]
        }
      ],
      "source": [
        "# with open(f\"{googledrive_data_path}train.txt\") as f:\n",
        "#     train = f.readlines()\n",
        "\n",
        "# with open(f\"{googledrive_data_path}valid.txt\") as f:\n",
        "#     valid = f.readlines()\n",
        "\n",
        "# with open(f\"{googledrive_data_path}test.txt\") as f:\n",
        "#     test = f.readlines()\n",
        "\n",
        "\n",
        "# print(len(train))\n",
        "# a, b, c = sum([1 for a in train if 'episode_done:True' in a]), sum([1 for a in valid if 'episode_done:True' in a]), sum([1 for a in test if 'episode_done:True' in a])\n",
        "# print(a,b,c,a+b+c)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUxXs_Oe8dda"
      },
      "source": [
        "## BST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIRVhsq88e7A",
        "outputId": "ef3bc8f0-6edf-4c17-c987-672c06f468c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/dataset_french_bst/': No such file or directory\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/test.txt' -> '/content/dataset_french_bst/test.txt'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/train.txt' -> '/content/dataset_french_bst/train.txt'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/valid.txt' -> '/content/dataset_french_bst/valid.txt'\n"
          ]
        }
      ],
      "source": [
        "googledrive_data_path = \"/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/\"\n",
        "data_path = \"/content/dataset_french_bst/\"\n",
        "!rm -R $data_path\n",
        "!mkdir $data_path\n",
        "!cp -rv $googledrive_data_path* $data_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuQo9hiTRT0Y",
        "outputId": "4d567cbb-6f42-4df0-d826-b93dafcff83c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59700\n",
            "9638 2018 1958 13614\n"
          ]
        }
      ],
      "source": [
        "googledrive_data_path = \"/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_blended_skill_talk/\"\n",
        "with open(f\"{googledrive_data_path}train.txt\") as f:\n",
        "    train = f.readlines()\n",
        "\n",
        "with open(f\"{googledrive_data_path}valid.txt\") as f:\n",
        "    valid = f.readlines()\n",
        "\n",
        "with open(f\"{googledrive_data_path}test.txt\") as f:\n",
        "    test = f.readlines()\n",
        "\n",
        "\n",
        "print(len(train))\n",
        "a, b, c = sum([1 for a in train if 'episode_done:True' in a]), sum([1 for a in valid if 'episode_done:True' in a]), sum([1 for a in test if 'episode_done:True' in a])\n",
        "print(a, b, c, a+b+c)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l6gr-_0Ohlg"
      },
      "source": [
        "## WoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv1tbBZOOnW9"
      },
      "outputs": [],
      "source": [
        "# googledrive_data_path = \"/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_wizard_of_wikipedia/\"\n",
        "# data_path = \"/content/dataset_french_wow/\"\n",
        "# !rm -R $data_path\n",
        "# !mkdir $data_path\n",
        "# !cp -rv $googledrive_data_path* $data_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vj3Ii8TAknd",
        "outputId": "f5638954-1aca-49b3-fe96-fcea76ef6ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/dataset_french_wow/': No such file or directory\n",
            "17848 35696\n",
            "2231 4462\n",
            "2231 4462\n"
          ]
        }
      ],
      "source": [
        "# convert_xpersona_dialogs_to_parlai_format_file_and_double_sided(dialogs_train, \"train.txt\")\n",
        "googledrive_data_path = \"/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_wizard_of_wikipedia/\"\n",
        "data_path = \"/content/dataset_french_wow/\"\n",
        "!rm -R $data_path\n",
        "!mkdir $data_path\n",
        "\n",
        "with open(f\"{googledrive_data_path}train.txt\") as f:\n",
        "    train_lines = f.readlines()\n",
        "with open(f\"{googledrive_data_path}valid.txt\") as f:\n",
        "    valid_lines = f.readlines()\n",
        "with open(f\"{googledrive_data_path}test.txt\") as f:\n",
        "    test_lines = f.readlines()\n",
        "\n",
        "\n",
        "make_dataset_double_sided(train_lines, data_path, \"train.txt\")\n",
        "make_dataset_double_sided(valid_lines, data_path, \"valid.txt\")\n",
        "make_dataset_double_sided(test_lines, data_path, \"test.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jcuyswOBWrQ"
      },
      "outputs": [],
      "source": [
        "# googledrive_data_path = \"/content/drive/MyDrive/colabs/aliae-workspace/datasets/french_wizard_of_wikipedia/\"\n",
        "# with open(f\"{googledrive_data_path}train.txt\") as f:\n",
        "#     train = f.readlines()\n",
        "# with open(f\"{googledrive_data_path}valid.txt\") as f:\n",
        "#     valid = f.readlines()\n",
        "# with open(f\"{googledrive_data_path}test.txt\") as f:\n",
        "#     test = f.readlines()\n",
        "# print(len(train))\n",
        "# a, b, c = sum([1 for a in train if 'episode_done:True' in a]), sum([1 for a in valid if 'episode_done:True' in a]), sum([1 for a in test if 'episode_done:True' in a])\n",
        "# print(a, b, c, a+b+c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PQfT57Q8I2u"
      },
      "source": [
        "# 2.Creating new Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6oVPKrhO8ISe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103509cb-4f65-4f46-b146-e4e7b328e7e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/': No such file or directory\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/agents.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/agents.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/build.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/build.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/__init__.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/__init__.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/LICENSE_DOCUMENTATION' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/LICENSE_DOCUMENTATION'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/README.md' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/README.md'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test/empathetic_dialogues_test.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test/empathetic_dialogues_test.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test/empathetic_dialogues_train.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test/empathetic_dialogues_train.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test/empathetic_dialogues_valid.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test/empathetic_dialogues_valid.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/test.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/test.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/worlds.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_xpersona/worlds.py'\n",
            "rm: cannot remove '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/': No such file or directory\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/agents.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/agents.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/build.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/build.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/__init__.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/__init__.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/LICENSE_DOCUMENTATION' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/LICENSE_DOCUMENTATION'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/README.md' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/README.md'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test/empathetic_dialogues_test.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test/empathetic_dialogues_test.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test/empathetic_dialogues_train.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test/empathetic_dialogues_train.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test/empathetic_dialogues_valid.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test/empathetic_dialogues_valid.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/test.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/test.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/worlds.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_empathetic_dialogues/worlds.py'\n",
            "rm: cannot remove '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/': No such file or directory\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/agents.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/agents.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/build.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/build.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/__init__.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/__init__.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/LICENSE_DOCUMENTATION' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/LICENSE_DOCUMENTATION'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/README.md' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/README.md'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test/empathetic_dialogues_test.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test/empathetic_dialogues_test.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test/empathetic_dialogues_train.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test/empathetic_dialogues_train.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test/empathetic_dialogues_valid.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test/empathetic_dialogues_valid.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/test.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/test.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/worlds.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_blended_skill_talk/worlds.py'\n",
            "rm: cannot remove '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_wizard_of_wikipedia/': No such file or directory\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_wizard_of_wikipedia/agents.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_wizard_of_wikipedia/agents.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_wizard_of_wikipedia/build.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_wizard_of_wikipedia/build.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_wizard_of_wikipedia/__init__.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_wizard_of_wikipedia/__init__.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_wizard_of_wikipedia/LICENSE_DOCUMENTATION' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_wizard_of_wikipedia/LICENSE_DOCUMENTATION'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_wizard_of_wikipedia/README.md' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_wizard_of_wikipedia/README.md'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_wizard_of_wikipedia/test' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_wizard_of_wikipedia/test'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_wizard_of_wikipedia/test/empathetic_dialogues_test.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_wizard_of_wikipedia/test/empathetic_dialogues_test.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_wizard_of_wikipedia/test/empathetic_dialogues_train.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_wizard_of_wikipedia/test/empathetic_dialogues_train.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_wizard_of_wikipedia/test/empathetic_dialogues_valid.yml' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_wizard_of_wikipedia/test/empathetic_dialogues_valid.yml'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_wizard_of_wikipedia/test.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_wizard_of_wikipedia/test.py'\n",
            "'/content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_wizard_of_wikipedia/worlds.py' -> '/usr/local/lib/python3.7/dist-packages/parlai/tasks/french_wizard_of_wikipedia/worlds.py'\n"
          ]
        }
      ],
      "source": [
        "#region XPersona\n",
        "task_path = \"/usr/local/lib/python3.7/dist-packages/parlai/tasks/\"\n",
        "\n",
        "!rm -R $task_path'french_xpersona/'\n",
        "!mkdir $task_path'french_xpersona'\n",
        "!cp -ruv /content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_xpersona/* $task_path'french_xpersona/'\n",
        "#endregion\n",
        "\n",
        "\n",
        "#region ED\n",
        "task_path = \"/usr/local/lib/python3.7/dist-packages/parlai/tasks/\"\n",
        "\n",
        "!rm -R $task_path'french_empathetic_dialogues/'\n",
        "!mkdir $task_path'french_empathetic_dialogues'\n",
        "!cp -ruv /content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_empathetic_dialogues/* $task_path'french_empathetic_dialogues/'\n",
        "#endregion\n",
        "\n",
        "\n",
        "#region BST\n",
        "task_path = \"/usr/local/lib/python3.7/dist-packages/parlai/tasks/\"\n",
        "\n",
        "!rm -R $task_path'french_blended_skill_talk/'\n",
        "!mkdir $task_path'french_blended_skill_talk'\n",
        "!cp -ruv /content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_blended_skill_talk/* $task_path'french_blended_skill_talk/'\n",
        "#endregion\n",
        "\n",
        "#region WoW\n",
        "task_path = \"/usr/local/lib/python3.7/dist-packages/parlai/tasks/\"\n",
        "\n",
        "!rm -R $task_path'french_wizard_of_wikipedia/'\n",
        "!mkdir $task_path'french_wizard_of_wikipedia'\n",
        "!cp -ruv /content/drive/MyDrive/colabs/aliae-workspace/parlai-tasks/french_wizard_of_wikipedia/* $task_path'french_wizard_of_wikipedia/'\n",
        "#endregion "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uDe0BBqqChqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14fbe1a7-822d-4509-e9e0-3c156d262e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:21:17 | Opt:\n",
            "22:21:17 |     allow_missing_init_opts: False\n",
            "22:21:17 |     batchsize: 1\n",
            "22:21:17 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "22:21:17 |     datatype: train:ordered\n",
            "22:21:17 |     dict_class: None\n",
            "22:21:17 |     display_add_fields: \n",
            "22:21:17 |     download_path: None\n",
            "22:21:17 |     dynamic_batching: None\n",
            "22:21:17 |     hide_labels: False\n",
            "22:21:17 |     ignore_agent_reply: True\n",
            "22:21:17 |     image_cropsize: 224\n",
            "22:21:17 |     image_mode: raw\n",
            "22:21:17 |     image_size: 256\n",
            "22:21:17 |     init_model: None\n",
            "22:21:17 |     init_opt: None\n",
            "22:21:17 |     is_debug: False\n",
            "22:21:17 |     loglevel: info\n",
            "22:21:17 |     max_display_len: 1000\n",
            "22:21:17 |     model: None\n",
            "22:21:17 |     model_file: None\n",
            "22:21:17 |     multitask_weights: [1]\n",
            "22:21:17 |     mutators: None\n",
            "22:21:17 |     num_examples: 10\n",
            "22:21:17 |     override: \"{'task': 'french_blended_skill_talk'}\"\n",
            "22:21:17 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "22:21:17 |     starttime: Jun23_22-21\n",
            "22:21:17 |     task: french_blended_skill_talk\n",
            "22:21:17 |     verbose: False\n",
            "22:21:17 | creating task(s): french_blended_skill_talk\n",
            "22:21:17 | Loading ParlAI text data: /content/dataset_french_bst/train.txt\n",
            "\u001b[1;31m- - - NEW EPISODE: french_blended_skill_talk - - -\u001b[0;0m\n",
            "\u001b[0mJ'aime la musique live, c'est pourquoi j'essaie d'aller aux concerts.\u001b[0;0m\n",
            "   \u001b[1;94mMoi aussi. Qu'est-ce que tu aimes ?\u001b[0;0m\n",
            "\u001b[0mJ'aime jouer la comédie, j'espère être un acteur, et vous ?\u001b[0;0m\n",
            "   \u001b[1;94mC'est bon. Vous avez des enfants ?\u001b[0;0m\n",
            "\u001b[0mNon, mais un jour.\u001b[0;0m\n",
            "   \u001b[1;94mc'est bien. J'ai 2\u001b[0;0m\n",
            "\u001b[0mLorsque j'aurai terminé mes études, je compte fonder une famille.\u001b[0;0m\n",
            "   \u001b[1;94mc'est génial ! tu seras prête\u001b[0;0m\n",
            "\u001b[0mJe l'espère, quel âge ont vos enfants ?\u001b[0;0m\n",
            "   \u001b[1;94m5 & 7. Ils me prennent beaucoup de temps.\u001b[0;0m\n",
            "\u001b[0mJ'imagine. Je suis sûr qu'ils sont de grands enfants.\u001b[0;0m\n",
            "   \u001b[1;94mheureusement, ils aiment les fleurs tout autant que moi. Nous passons beaucoup de temps dans le jardin.\u001b[0;0m\n",
            "\u001b[0mJ'aimerais avoir plus de temps pour faire ce genre de choses. L'école de médecine est épuisante. \u001b[0;0m\n",
            "   \u001b[1;94mOn dirait bien. As-tu trouvé un travail d'actrice, cependant ?\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: french_blended_skill_talk - - -\u001b[0;0m\n",
            "\u001b[0mMoi aussi. Qu'est-ce que tu aimes ?\u001b[0;0m\n",
            "   \u001b[1;94mJ'aime jouer la comédie, j'espère être un acteur, et vous ?\u001b[0;0m\n",
            "\u001b[0mC'est bon. Vous avez des enfants ?\u001b[0;0m\n",
            "   \u001b[1;94mNon, mais un jour.\u001b[0;0m\n",
            "\u001b[0mc'est bien. J'ai 2\u001b[0;0m\n",
            "   \u001b[1;94mLorsque j'aurai terminé mes études, je compte fonder une famille.\u001b[0;0m\n",
            "22:21:18 | loaded 9638 episodes with a total of 59700 examples\n"
          ]
        }
      ],
      "source": [
        "# !parlai display_data --task french_empathetic_dialogues\n",
        "# !parlai display_data --task french_xpersona \n",
        "# !parlai display_data --task french_blended_skill_talk \n",
        "# !parlai display_data --task french_wizard_of_wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGoTqdFD7x_3"
      },
      "source": [
        "# 3.Finetuning + Multitasking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "65rK6pfj70Px",
        "outputId": "3f9cbbd3-fa28-45d0-c720-23fdc4058525"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/colabs/blender-models/finetuned-reddit_LELU-4tasks-90m'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# finetuned_model_path = f'{mydrive_path}finetuned-reddit_LELU-4tasks-400m'\n",
        "# init_model = 'zoo:blender/blender_400Mdistill/model'\n",
        "# dict_file  = 'zoo:blender/blender_400Mdistill/model.dict'\n",
        "\n",
        "finetuned_model_path = f'{mydrive_path}finetuned-reddit_LELU-4tasks-90m'\n",
        "init_model = 'zoo:blender/blender_90M/model'\n",
        "dict_file  = 'zoo:blender/blender_90M/model.dict'\n",
        "finetuned_model_path\n",
        "# from os import path\n",
        "# path.exists(f\"{finetuned_model_path}model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zArppuSCGS7"
      },
      "outputs": [],
      "source": [
        "# !mkdir copied_dataset_french_bst\n",
        "# !cp dataset_french_bst/* copied_dataset_french_bst\n",
        "# !mv copied_dataset_french_bst/test.txt copied_dataset_french_bst/_test.txt\n",
        "# !mv copied_dataset_french_bst/train.txt copied_dataset_french_bst/_train.txt\n",
        "# !mv copied_dataset_french_bst/valid.txt copied_dataset_french_bst/_valid.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pipze3fDlXpD",
        "outputId": "82aec687-fcab-42fd-c8ae-e660b4ffe278"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.19-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.28.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.6.0-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=ec14826faccb5bd39531a9a23053c604dfd5080671665cf0a693547686f1a53c\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: shortuuid, setproctitle, sentry-sdk, pathtools, docker-pycreds, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 pathtools-0.1.2 sentry-sdk-1.6.0 setproctitle-1.2.3 shortuuid-1.0.9 wandb-0.12.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "X7vLiYpF8HbF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eaa88650-982b-44c0-a6ff-62380cd023bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                                 /@&%###%&&@@#\n",
            "                      .,*/((((##@@@&%%#%%&&@@@&%%#/*.\n",
            "             #@@&&&%%%%##(((///*****//(((###%%%&&&@@@@@&&%#%%#.\n",
            "         .%&@@@@@&&&%%%####((((////((((####%%%&&&@@@@@&&%%#%%####,\n",
            "           ./,,#(//**,,.....,,,,***////((((########%%%%%%%%###(((\n",
            "              /*(//**,,,....,,,,***////((((########%%%%%%%%###(#%*\n",
            "               (*,...      ...,,,***//////((((((///////(/*...,/#@@@(\n",
            "               **,,..         ...,,,,,,,,,,........,,*///*...*(#@@@@&&*\n",
            "               ./,,..          ...,,,,,,,,,........,,*//*,...*#/,,,,,/%#\n",
            "                (*,..          ...,,,,,,,,,........,,*//*,..,/(      .,#(\n",
            "                **,..          ...,,,,,,,,,.........,*//*,..,((       .,(#\n",
            "                 /*,..          ....,,,,,,,.....  ..,***,,,,(#         ..#&\n",
            "                 **,..          ....,,,,,,,....   ..,***,,,*#.         .,%@\n",
            "                 ./,...       B l e n d e r B o t ...***,,,*#          .*%@\n",
            "                  /*,..          ...,,,,,,,....    .,**,,,,/#         ..(%/\n",
            "                  /*,,..         ...,,,,,,,...    ..,*,,,,,(.         ..#&\n",
            "                  ,/*,..         ...,,,,,,,...    ..,*,,,,*#         ..*%(\n",
            "                   /*,..         ...,,,,,.....    ..,*,*,,/(         ..#&\n",
            "                   /**,..        ...,,,,.....    ...,***,*(.       ,,(%.\n",
            "                    (/*,,..      ....,,.....     ...,****(&@@@&&&#,\n",
            "                     (/*,,...   .....,,......     ..,****#@,\n",
            "                     *(/*,,/....*(###%(,(%%##(*.  ./,,**(\n",
            "                      ,//**(,........,/((#.........*,**(\n",
            "                      .(#//*,,,,,,.*.,/((%/,,.....,,*/@\n",
            "                    ((######//****,/.,/(#%#***,***(&@@@@@(\n",
            "                   *&%%#####%%%%%%%#//(#%&%%&&@@@@@@@@@@@@*\n",
            "                   &&%%%###((((((####%%%%&&&&&@@@@@@@@@@&&@.\n",
            "                  *##%%%##(((((((####%%%%%&&&&@@@@@@@@@&#/*,\n",
            "                 .(##%#/,  .,*((##%%%&&&&%%%#####%&&@&&%#(/*.\n",
            "                 /(###(,   .,*/(##%%%&&&&%%%######%&&&&%#(/*,\n",
            "                */((((*.  ..,//((##%%%%%%%%#######%&&&&%%#(/*,\n",
            "               .//(((/,   .,*//((###%%%%%%########%%&&&%%#((/,.\n",
            "              .&####(((((((((######%%%%%%%%&&&&&&&@@@@@@@@@@@@@#\n",
            "               *&#.   .*/((((#######%%%%%%&&&&&&&@@@@@#/.   (&/\n",
            "22:22:16 | building data: /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/BST0B.tgz\n",
            "22:22:16 | Downloading http://parl.ai/downloads/_models/blender/BST0B.tgz to /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/BST0B.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading BST0B.tgz: 100%|██████████| 161M/161M [00:03<00:00, 50.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:22:23 | building dictionary first...\n",
            "22:22:23 | No model with opt yet at: /content/drive/MyDrive/colabs/blender-models/finetuned-reddit_LELU-4tasks-90mmodel(.opt)\n",
            "22:22:23 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: full,verbose: True,is_debug: False,datapath: /usr/local/lib/python3.7/dist-packages/data,final_extra_opt: ,eval_dynamic_batching: None,num_workers: 0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_steps: -1,load_from_checkpoint: True,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_logdir: None,wandb_log: True,wandb_name: None,wandb_project: None,wandb_entity: None,mutators: None,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,checkpoint_activations: False,beam_block_full_context: True,beam_delay: 30,beam_block_list_filename: None,temperature: 1.0,interactive_mode: False,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None\u001b[0m\n",
            "22:22:23 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
            "--show-advanced-args False --task internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues --numthreads 1 --batchsize 16 --num-epochs -1 --save-every-n-secs 60.0 --validation-every-n-epochs 0.25 --validation-max-exs 20000 --validation-patience 15 --log-every-n-secs 2 --label-type response --include-knowledge True --include-checked-sentence True --include-knowledge-separator False --num-topics 5 --train-experiencer-only False --dropout 0.1 --learn-positional-embeddings True --beam-size 10 --beam-min-length 20 --beam-context-block-ngram 3 --beam-block-ngram 3 --skip-generation False --inference beam --fp16-impl apex --optimizer adamax --learningrate 7.5e-06 --max-lr-steps -1 --warmup-updates -1 --parlai-home /private/home/edinan/ParlAI\u001b[0m\n",
            "22:22:23 | Using CUDA\n",
            "22:22:23 | loading dictionary from /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model.dict\n",
            "22:22:23 | num words = 54944\n",
            "22:22:24 | \u001b[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001b[0m\n",
            "22:22:38 | Total parameters: 87,508,992 (86,984,704 trainable)\n",
            "22:22:38 | Loading existing model params from /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model\n",
            "22:22:38 | \u001b[33mDetected a fine-tune run. Resetting the optimizer.\u001b[0m\n",
            "22:22:38 | \u001b[33mOptimizer was reset. Also resetting LR scheduler.\u001b[0m\n",
            "22:22:38 | Opt:\n",
            "22:22:38 |     activation: gelu\n",
            "22:22:38 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "22:22:38 |     adam_eps: 1e-08\n",
            "22:22:38 |     add_p1_after_newln: False\n",
            "22:22:38 |     aggregate_micro: False\n",
            "22:22:38 |     allow_missing_init_opts: False\n",
            "22:22:38 |     attention_dropout: 0.0\n",
            "22:22:38 |     batchsize: 8\n",
            "22:22:38 |     beam_block_full_context: True\n",
            "22:22:38 |     beam_block_list_filename: None\n",
            "22:22:38 |     beam_block_ngram: -1\n",
            "22:22:38 |     beam_context_block_ngram: -1\n",
            "22:22:38 |     beam_delay: 30\n",
            "22:22:38 |     beam_length_penalty: 0.65\n",
            "22:22:38 |     beam_min_length: 1\n",
            "22:22:38 |     beam_size: 1\n",
            "22:22:38 |     betas: '(0.9, 0.999)'\n",
            "22:22:38 |     bpe_add_prefix_space: None\n",
            "22:22:38 |     bpe_debug: False\n",
            "22:22:38 |     bpe_dropout: None\n",
            "22:22:38 |     bpe_merge: None\n",
            "22:22:38 |     bpe_vocab: None\n",
            "22:22:38 |     checkpoint_activations: False\n",
            "22:22:38 |     compute_tokenized_bleu: False\n",
            "22:22:38 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "22:22:38 |     datatype: train\n",
            "22:22:38 |     delimiter: '\\n'\n",
            "22:22:38 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "22:22:38 |     dict_endtoken: __end__\n",
            "22:22:38 |     dict_file: /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model.dict\n",
            "22:22:38 |     dict_include_test: False\n",
            "22:22:38 |     dict_include_valid: False\n",
            "22:22:38 |     dict_initpath: None\n",
            "22:22:38 |     dict_language: english\n",
            "22:22:38 |     dict_loaded: True\n",
            "22:22:38 |     dict_lower: True\n",
            "22:22:38 |     dict_max_ngram_size: -1\n",
            "22:22:38 |     dict_maxexs: -1\n",
            "22:22:38 |     dict_maxtokens: -1\n",
            "22:22:38 |     dict_minfreq: 0\n",
            "22:22:38 |     dict_nulltoken: __null__\n",
            "22:22:38 |     dict_starttoken: __start__\n",
            "22:22:38 |     dict_textfields: text,labels\n",
            "22:22:38 |     dict_tokenizer: bpe\n",
            "22:22:38 |     dict_unktoken: __unk__\n",
            "22:22:38 |     display_examples: False\n",
            "22:22:38 |     download_path: None\n",
            "22:22:38 |     dropout: 0.0\n",
            "22:22:38 |     dynamic_batching: full\n",
            "22:22:38 |     embedding_projection: random\n",
            "22:22:38 |     embedding_size: 512\n",
            "22:22:38 |     embedding_type: random\n",
            "22:22:38 |     embeddings_scale: True\n",
            "22:22:38 |     eval_batchsize: None\n",
            "22:22:38 |     eval_dynamic_batching: None\n",
            "22:22:38 |     evaltask: None\n",
            "22:22:38 |     ffn_size: 2048\n",
            "22:22:38 |     final_extra_opt: \n",
            "22:22:38 |     force_fp16_tokens: False\n",
            "22:22:38 |     fp16: True\n",
            "22:22:38 |     fp16_impl: mem_efficient\n",
            "22:22:38 |     gpu: -1\n",
            "22:22:38 |     gradient_clip: 0.1\n",
            "22:22:38 |     hide_labels: False\n",
            "22:22:38 |     history_add_global_end_token: None\n",
            "22:22:38 |     history_reversed: False\n",
            "22:22:38 |     history_size: -1\n",
            "22:22:38 |     image_cropsize: 224\n",
            "22:22:38 |     image_mode: raw\n",
            "22:22:38 |     image_size: 256\n",
            "22:22:38 |     inference: greedy\n",
            "22:22:38 |     init_model: /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model\n",
            "22:22:38 |     init_opt: None\n",
            "22:22:38 |     interactive_mode: False\n",
            "22:22:38 |     invsqrt_lr_decay_gamma: -1\n",
            "22:22:38 |     is_debug: False\n",
            "22:22:38 |     label_truncate: 128\n",
            "22:22:38 |     learn_positional_embeddings: False\n",
            "22:22:38 |     learningrate: 1e-05\n",
            "22:22:38 |     load_from_checkpoint: True\n",
            "22:22:38 |     log_every_n_secs: 180.0\n",
            "22:22:38 |     log_every_n_steps: 50\n",
            "22:22:38 |     log_keep_fields: all\n",
            "22:22:38 |     loglevel: info\n",
            "22:22:38 |     lr_scheduler: reduceonplateau\n",
            "22:22:38 |     lr_scheduler_decay: 0.5\n",
            "22:22:38 |     lr_scheduler_patience: 3\n",
            "22:22:38 |     max_train_steps: -1\n",
            "22:22:38 |     max_train_time: -1\n",
            "22:22:38 |     metrics: default\n",
            "22:22:38 |     model: transformer/generator\n",
            "22:22:38 |     model_file: /content/drive/MyDrive/colabs/blender-models/finetuned-reddit_LELU-4tasks-90mmodel\n",
            "22:22:38 |     model_parallel: False\n",
            "22:22:38 |     momentum: 0\n",
            "22:22:38 |     multitask_weights: '(1.0, 3.0, 3.0, 3.0)'\n",
            "22:22:38 |     mutators: None\n",
            "22:22:38 |     n_decoder_layers: -1\n",
            "22:22:38 |     n_encoder_layers: -1\n",
            "22:22:38 |     n_heads: 16\n",
            "22:22:38 |     n_layers: 8\n",
            "22:22:38 |     n_positions: 512\n",
            "22:22:38 |     n_segments: 0\n",
            "22:22:38 |     nesterov: True\n",
            "22:22:38 |     no_cuda: False\n",
            "22:22:38 |     num_epochs: 10.0\n",
            "22:22:38 |     num_workers: 0\n",
            "22:22:38 |     nus: (0.7,)\n",
            "22:22:38 |     optimizer: mem_eff_adam\n",
            "22:22:38 |     output_scaling: 1.0\n",
            "22:22:38 |     override: \"{'task': 'french_blended_skill_talk,french_wizard_of_wikipedia,french_xpersona,french_empathetic_dialogues', 'multitask_weights': (1.0, 3.0, 3.0, 3.0), 'model': 'transformer/generator', 'model_file': '/content/drive/MyDrive/colabs/blender-models/finetuned-reddit_LELU-4tasks-90mmodel', 'init_model': 'zoo:blender/blender_90M/model', 'dict_file': '/usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model.dict', 'n_heads': 16, 'n_layers': 8, 'n_positions': 512, 'text_truncate': 512, 'label_truncate': 128, 'ffn_size': 2048, 'embedding_size': 512, 'activation': 'gelu', 'variant': 'xlm', 'dict_lower': True, 'dict_tokenizer': 'bpe', 'validation_every_n_epochs': 0.1, 'num_epochs': 10.0, 'log_every_n_secs': 180.0, 'verbose': True, 'batchsize': 8, 'fp16': True, 'fp16_impl': 'mem_efficient', 'save_after_valid': True, 'wandb_log': True, 'skip_generation': True, 'validation_patience': 10, 'validation_metric': 'ppl', 'validation_metric_mode': 'min', 'dynamic_batching': 'full', 'learningrate': 1e-05, 'optimizer': 'adam', 'attention_dropout': 0.0, 'model_parallel': False, 'warmup_updates': 100}\"\n",
            "22:22:38 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "22:22:38 |     person_tokens: False\n",
            "22:22:38 |     rank_candidates: False\n",
            "22:22:38 |     relu_dropout: 0.0\n",
            "22:22:38 |     save_after_valid: True\n",
            "22:22:38 |     save_every_n_secs: -1\n",
            "22:22:38 |     save_format: conversations\n",
            "22:22:38 |     share_word_embeddings: True\n",
            "22:22:38 |     short_final_eval: False\n",
            "22:22:38 |     skip_generation: True\n",
            "22:22:38 |     special_tok_lst: None\n",
            "22:22:38 |     split_lines: False\n",
            "22:22:38 |     starttime: Jun23_22-22\n",
            "22:22:38 |     task: french_blended_skill_talk,french_wizard_of_wikipedia,french_xpersona,french_empathetic_dialogues\n",
            "22:22:38 |     temperature: 1.0\n",
            "22:22:38 |     tensorboard_log: False\n",
            "22:22:38 |     tensorboard_logdir: None\n",
            "22:22:38 |     text_truncate: 512\n",
            "22:22:38 |     topk: 10\n",
            "22:22:38 |     topp: 0.9\n",
            "22:22:38 |     truncate: -1\n",
            "22:22:38 |     update_freq: 1\n",
            "22:22:38 |     use_reply: label\n",
            "22:22:38 |     validation_cutoff: 1.0\n",
            "22:22:38 |     validation_every_n_epochs: 0.1\n",
            "22:22:38 |     validation_every_n_secs: -1\n",
            "22:22:38 |     validation_every_n_steps: -1\n",
            "22:22:38 |     validation_max_exs: -1\n",
            "22:22:38 |     validation_metric: ppl\n",
            "22:22:38 |     validation_metric_mode: min\n",
            "22:22:38 |     validation_patience: 10\n",
            "22:22:38 |     validation_share_agent: False\n",
            "22:22:38 |     variant: xlm\n",
            "22:22:38 |     verbose: True\n",
            "22:22:38 |     wandb_entity: None\n",
            "22:22:38 |     wandb_log: True\n",
            "22:22:38 |     wandb_name: None\n",
            "22:22:38 |     wandb_project: None\n",
            "22:22:38 |     warmup_rate: 0.0001\n",
            "22:22:38 |     warmup_updates: 100\n",
            "22:22:38 |     weight_decay: None\n",
            "22:22:38 |     world_logs: \n",
            "22:22:39 | creating task(s): french_blended_skill_talk,french_wizard_of_wikipedia,french_xpersona,french_empathetic_dialogues\n",
            "22:22:39 | Loading ParlAI text data: /content/dataset_french_bst/train.txt\n",
            "22:22:39 | Loading ParlAI text data: /content/dataset_french_wow/train.txt\n",
            "22:22:41 | Loading ParlAI text data: /content/dataset_french_xpersona/train.txt\n",
            "22:22:43 | Loading ParlAI text data: /content/dataset_french_ed/train.txt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/logs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt, model)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# last second to import it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wandb'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f6b6723823f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mattention_dropout\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mmodel_parallel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mwarmup_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# customized parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_kwargs\u001b[0;34m(cls, kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_from_parser_and_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_from_parser_and_opt\u001b[0;34m(cls, opt, parser)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wandb_log'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_primary_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwb_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWandbLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/logs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt, model)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please run `pip install wandb`.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wandb_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Please run `pip install wandb`.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# 90M settings\n",
        "# !rm -rf $finetuned_model_path\n",
        "!mkdir -p $finetuned_model_path\n",
        "\n",
        "\n",
        "from parlai.scripts.train_model import TrainModel\n",
        "\n",
        "TrainModel.main(\n",
        "    # task\n",
        "    task= \"french_blended_skill_talk,french_wizard_of_wikipedia,french_xpersona,french_empathetic_dialogues\",\n",
        "    multitask_weights= \"1,3,3,3\",\n",
        "\n",
        "    # task='fromfile:parlaiformat', \n",
        "    # fromfile_datapath= f'{data_path}data',\n",
        "    # fromfile_datatype_extension=True,\n",
        "\n",
        "    model='transformer/generator',\n",
        "    model_file= f'{finetuned_model_path}model',\n",
        "    \n",
        "    # initialize with a pretrained model\n",
        "    init_model= init_model,\n",
        "    dict_file=dict_file,\n",
        "    \n",
        "    # arguments we get from the pretrained model.\n",
        "    # Unfortunately, these must be looked up separately for each model.\n",
        "    n_heads=16, n_layers=8, n_positions=512, text_truncate=512,\n",
        "    label_truncate=128, ffn_size=2048, embedding_size=512,\n",
        "    activation='gelu', variant='xlm',\n",
        "    dict_lower=True, dict_tokenizer='bpe',\n",
        "    \n",
        "    # depend on your gpu. \n",
        "    \n",
        "    validation_every_n_epochs=0.1,\n",
        "    num_epochs = 10,\n",
        "    log_every_n_secs= 180,\n",
        "    verbose = True,\n",
        "    batchsize= 8, \n",
        "    fp16= True, fp16_impl= \"mem_efficient\",\n",
        "    save_after_valid = True,\n",
        "    wandb_log = True,\n",
        "    \n",
        "    # arguments we get from the pretrained model.\n",
        "    \n",
        "    # speeds up validation\n",
        "    skip_generation=True,\n",
        "    vp= 10,\n",
        "    validation_metric= \"ppl\", #vmt = \"ppl\"\n",
        "    validation_metric_mode= \"min\", # vmm= \"min\"\n",
        "    \n",
        "    # helps us cram more examples into our gpu at a time\n",
        "    dynamic_batching='full',\n",
        "\n",
        "    \n",
        "    # some training arguments, specific to this fine-tuning\n",
        "    lr=1e-5, optimizer='adam',\n",
        "    attention_dropout= 0.0, \n",
        "    model_parallel= False,\n",
        "    warmup_updates=100,\n",
        "\n",
        "    # customized parameters\n",
        "    # inference= \"beam\"\n",
        "    # beam_min_length= 20,\n",
        "    # beam_block_ngram= 3,\n",
        "    # beam_context_block_ngram= 3,\n",
        "    # beam_size= 10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxL0-1x1YsQe"
      },
      "outputs": [],
      "source": [
        "# mydrive_path = '/content/finetuned-multitask-400m-double-sided-2epochs'\n",
        "# mydrive_path = '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "jNZE5ta2pO-X",
        "outputId": "850d4938-cdea-4a4d-da47-0c8ec8f89200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "08:17:05 | building dictionary first...\n",
            "08:17:05 | \u001b[33mOverriding opt[\"multitask_weights\"] to (1.0, 3.0, 3.0, 3.0) (previously: [1.0, 3.0, 3.0, 3.0])\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"dict_file\"] to /usr/local/lib/python3.7/dist-packages/data/models/blender/blender_90M/model.dict (previously: /content/drive/MyDrive/colabs/blender-models/finetuned-reddit-90m--finetuned-4tasks-5epochs/model.dict)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"num_epochs\"] to 10.0 (previously: 5.0)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"log_every_n_secs\"] to 300.0 (previously: 180.0)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"batchsize\"] to 16 (previously: 8)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"save_after_valid\"] to True (previously: False)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"embedding_size\"] to 1280 (previously: 512)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"ffn_size\"] to 5120 (previously: 2048)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"variant\"] to prelayernorm (previously: xlm)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"n_heads\"] to 32 (previously: 16)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"n_positions\"] to 128 (previously: 512)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"n_encoder_layers\"] to 2 (previously: -1)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"n_decoder_layers\"] to 12 (previously: -1)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"text_truncate\"] to 128 (previously: 512)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"truncate\"] to 128 (previously: -1)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"history_add_global_end_token\"] to end (previously: None)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"delimiter\"] to    (previously: \n",
            ")\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"dict_tokenizer\"] to bytelevelbpe (previously: bpe)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"dropout\"] to 0.1 (previously: 0.0)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"learningrate\"] to 7e-06 (previously: 1e-05)\u001b[0m\n",
            "08:17:05 | \u001b[33mOverriding opt[\"update_freq\"] to 2 (previously: 1)\u001b[0m\n",
            "08:17:05 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: full,is_debug: False,final_extra_opt: ,eval_dynamic_batching: None,num_workers: 0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_steps: -1,world_logs: ,save_format: conversations,log_keep_fields: all,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,mutators: None,fromfile_datapath: /content/drive/MyDrive/colabs/aliae-workspace/datasets/french_reddit/data,fromfile_datatype_extension: True,n_encoder_layers: 2,n_decoder_layers: 12,model_parallel: False,checkpoint_activations: False,beam_block_full_context: True,beam_delay: 30,beam_block_list_filename: None,temperature: 1.0,history_reversed: False,history_add_global_end_token: end,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,dict_loaded: True,verbose: True,download_path: None,datapath: /usr/local/lib/python3.7/dist-packages/data,load_from_checkpoint: True,interactive_mode: False\u001b[0m\n",
            "08:17:05 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
            "--show-advanced-args False --task internal:blended_skill_talk,wizard_of_wikipedia,convai2,empathetic_dialogues --numthreads 1 --num-epochs -1 --save-every-n-secs 60.0 --validation-max-exs 20000 --validation-patience 15 --log-every-n-secs 2 --label-type response --include-knowledge True --include-checked-sentence True --include-knowledge-separator False --num-topics 5 --train-experiencer-only False --embedding-size 512 --ffn-size 2048 --n-heads 16 --learn-positional-embeddings True --n-positions 512 --variant xlm --beam-size 10 --beam-min-length 20 --beam-context-block-ngram 3 --beam-block-ngram 3 --skip-generation False --inference beam --fp16-impl apex --force-fp16-tokens False --optimizer adamax --learningrate 7.5e-06 --truncate -1 --text-truncate 512 --delimiter \n",
            " --dict-tokenizer bpe --max-lr-steps -1 --warmup-updates -1 --update-freq 1 --parlai-home /private/home/edinan/ParlAI\u001b[0m\n",
            "08:17:05 | Using CUDA\n",
            "08:17:05 | loading dictionary from /content/drive/MyDrive/colabs/blender-models/finetuned-reddit-90m--finetuned-4tasks-5epochs/model.dict\n",
            "08:17:05 | num words = 54944\n",
            "08:17:05 | \u001b[33mAre you sure you want to lower case your BPE dictionary?\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f4f20dc6b33e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mvp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mvalidation_metric\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"ppl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#vmt = \"ppl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mvalidation_metric_mode\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# vmm= \"min\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# customized parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_kwargs\u001b[0;34m(cls, kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_from_parser_and_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_from_parser_and_opt\u001b[0;34m(cls, opt, parser)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m# Create model and assign it to the specified task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/agents.py\u001b[0m in \u001b[0;36mcreate_agent\u001b[0;34m(opt, requireModelExists)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;31m# Attempt to load the model from the model file first (this way we do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;31m# not even have to specify the model name as a parameter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_agent_from_opt_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/agents.py\u001b[0m in \u001b[0;36mcreate_agent_from_opt_file\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;31m# loaded ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0mcompare_init_model_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_from_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_from_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/torch_generator_agent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt, shared)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0minit_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_finetune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_init_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beam_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/torch_agent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt, shared)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshared\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;31m# intialize any important structures from scratch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fp16'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'force_fp16_tokens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/torch_agent.py\u001b[0m in \u001b[0;36mbuild_dictionary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mplace\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdo\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \"\"\"\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_special_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_toks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/dict.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt, shared)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreebank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreebankWordTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'bpe'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bytelevelbpe'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'slow_bytelevel_bpe'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbpe_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_with_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/utils/bpe.py\u001b[0m in \u001b[0;36mbpe_factory\u001b[0;34m(opt, shared)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Attempt to instantiate HF tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mbpe_helper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuggingFaceBpeHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dict_loaded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/utils/bpe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt, shared)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_path\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             raise IOError(\n\u001b[0;32m--> 836\u001b[0;31m                 \u001b[0;34m'--bpe-vocab and --bpe-merge are mandatory with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m                 \u001b[0;34m'--dict-tokenizer bytelevelbpe'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             )\n",
            "\u001b[0;31mOSError\u001b[0m: --bpe-vocab and --bpe-merge are mandatory with --dict-tokenizer bytelevelbpe"
          ]
        }
      ],
      "source": [
        "# 400M settings\n",
        "# !rm -rf $finetuned_model_path\n",
        "!mkdir -p $finetuned_model_path\n",
        "\n",
        "\n",
        "from parlai.scripts.train_model import TrainModel\n",
        "\n",
        "TrainModel.main(\n",
        "    # task\n",
        "    task= \"french_blended_skill_talk,french_wizard_of_wikipedia,french_xpersona,french_empathetic_dialogues\",\n",
        "    multitask_weights= \"1,3,3,3\",\n",
        "\n",
        "    # task='fromfile:parlaiformat', \n",
        "    # fromfile_datapath= f'{data_path}data',\n",
        "    # fromfile_datatype_extension=True,\n",
        "\n",
        "    model='transformer/generator',\n",
        "    model_file= f'{finetuned_model_path}model',\n",
        "    \n",
        "    # initialize with a pretrained model\n",
        "    init_model= init_model,\n",
        "    dict_file=dict_file,\n",
        "    \n",
        "    # depend on your gpu\n",
        "    validation_every_n_epochs=0.25, # veps= 0.25, \n",
        "    num_epochs = 10,\n",
        "    log_every_n_secs= 300,\n",
        "    verbose = True,\n",
        "    attention_dropout= 0.0, \n",
        "    batchsize= 16, \n",
        "    fp16= True, fp16_impl= \"mem_efficient\",\n",
        "    # save_after_valid= True,\n",
        "\n",
        "    # arguments we get from the pretrained model. \"from recipes page for 2.7B model\" \n",
        "    embedding_size= 1280, ffn_size= 5120,\n",
        "    variant= \"prelayernorm\",\n",
        "    n_heads= 32, n_positions= 128, \n",
        "    n_encoder_layers= 2, n_decoder_layers= 12,\n",
        "\n",
        "    label_truncate= 128, text_truncate= 128, truncate= 128,\n",
        "    activation= \"gelu\",\n",
        "    history_add_global_end_token= \"end\", \n",
        "    delimiter= '  ', \n",
        "    dict_tokenizer= \"bytelevelbpe\",\n",
        "    dropout= 0.1,\n",
        "    \n",
        "    # some training arguments, specific to this fine-tuning\n",
        "    lr= 7e-06, lr_scheduler= \"reduceonplateau\", lr_scheduler_patience= 3,\n",
        "    optimizer= \"mem_eff_adam\",\n",
        "    relu_dropout= 0.0, \n",
        "    model_parallel= False,\n",
        "    warmup_updates= 100,\n",
        "    update_freq= 2,\n",
        "    gradient_clip= 0.1, \n",
        "\n",
        "    # speeds up validation\n",
        "    skip_generation= True,\n",
        "    vp= 10,\n",
        "    validation_metric= \"ppl\", #vmt = \"ppl\"\n",
        "    validation_metric_mode= \"min\", # vmm= \"min\"\n",
        "\n",
        "    # customized parameters\n",
        "    # inference = 'topk', \n",
        "    # temperature = 0.7, \n",
        "    # topk=30, \n",
        "    # beam_length_penalty=1.03\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1S0kRk3W63i"
      },
      "outputs": [],
      "source": [
        "# !cp -rv /content/finetuned-multitask-400m-double-sided-2epochs/* /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-400m-double-sided/\n",
        "# !ls -lah /content/finetuned-multitask-400m-double-sided-2epochs/\n",
        "# !ls -lah /content/finetuned-multitask-400m-double-sided/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVPS6p4XzPh4"
      },
      "source": [
        "# 4.Display Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9FBtnZZzPPg"
      },
      "outputs": [],
      "source": [
        "from parlai.scripts.display_model import DisplayModel\n",
        "DisplayModel.main(\n",
        "    task='french_blended_skill_talk',\n",
        "    model_file= f'{finetuned_model_path}/model',\n",
        "    num_examples=20,\n",
        "    skip_generation=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_model_path = f'{mydrive_path}finetuned-multitask-90m/'\n",
        "finetuned_model_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O7IUsHgd-Jbq",
        "outputId": "a09e2773-1f14-4a33-9a52-a38033bffae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap-cP0uzFF4y",
        "outputId": "3c438278-a75a-4c92-b793-91baaee8bc0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14:42:28 | \u001b[33mOverriding opt[\"task\"] to french_blended_skill_talk (previously: french_blended_skill_talk,french_xpersona,french_empathetic_dialogues,french_wizard_of_wikipedia)\u001b[0m\n",
            "14:42:28 | \u001b[33mOverriding opt[\"datatype\"] to test (previously: train)\u001b[0m\n",
            "14:42:28 | \u001b[33mOverriding opt[\"skip_generation\"] to False (previously: True)\u001b[0m\n",
            "14:42:28 | \u001b[33mOverriding opt[\"beam_block_ngram\"] to 2 (previously: -1)\u001b[0m\n",
            "14:42:28 | \u001b[33mOverriding opt[\"beam_context_block_ngram\"] to 3 (previously: -1)\u001b[0m\n",
            "14:42:28 | \u001b[33mOverriding opt[\"beam_length_penalty\"] to 1.0 (previously: 0.65)\u001b[0m\n",
            "14:42:28 | \u001b[33mOverriding opt[\"beam_min_length\"] to 10 (previously: 1)\u001b[0m\n",
            "14:42:28 | \u001b[33mOverriding opt[\"beam_size\"] to 20 (previously: 1)\u001b[0m\n",
            "14:42:28 | \u001b[33mOverriding opt[\"inference\"] to topk (previously: greedy)\u001b[0m\n",
            "14:42:28 | \u001b[33mOverriding opt[\"temperature\"] to 0.5 (previously: 1.0)\u001b[0m\n",
            "14:42:28 | \u001b[33mOverriding opt[\"topk\"] to 20 (previously: 10)\u001b[0m\n",
            "14:42:28 | Using CUDA\n",
            "14:42:28 | loading dictionary from /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m/model.dict\n",
            "14:42:28 | num words = 54944\n",
            "14:42:30 | Total parameters: 87,508,992 (86,984,704 trainable)\n",
            "14:42:30 | Loading existing model params from /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m/model\n",
            "14:42:32 | creating task(s): french_blended_skill_talk\n",
            "14:42:32 | Loading ParlAI text data: /content/dataset_french_bst/test.txt\n",
            "14:42:32 | Opt:\n",
            "14:42:32 |     activation: gelu\n",
            "14:42:32 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "14:42:32 |     adam_eps: 1e-08\n",
            "14:42:32 |     add_p1_after_newln: False\n",
            "14:42:32 |     aggregate_micro: False\n",
            "14:42:32 |     allow_missing_init_opts: False\n",
            "14:42:32 |     attention_dropout: 0.0\n",
            "14:42:32 |     batchsize: 8\n",
            "14:42:32 |     beam_block_full_context: True\n",
            "14:42:32 |     beam_block_list_filename: None\n",
            "14:42:32 |     beam_block_ngram: 2\n",
            "14:42:32 |     beam_context_block_ngram: 3\n",
            "14:42:32 |     beam_delay: 30\n",
            "14:42:32 |     beam_length_penalty: 1.0\n",
            "14:42:32 |     beam_min_length: 10\n",
            "14:42:32 |     beam_size: 20\n",
            "14:42:32 |     betas: '[0.9, 0.999]'\n",
            "14:42:32 |     bpe_add_prefix_space: None\n",
            "14:42:32 |     bpe_debug: False\n",
            "14:42:32 |     bpe_dropout: None\n",
            "14:42:32 |     bpe_merge: None\n",
            "14:42:32 |     bpe_vocab: None\n",
            "14:42:32 |     checkpoint_activations: False\n",
            "14:42:32 |     compute_tokenized_bleu: False\n",
            "14:42:32 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "14:42:32 |     datatype: test\n",
            "14:42:32 |     delimiter: '\\n'\n",
            "14:42:32 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "14:42:32 |     dict_endtoken: __end__\n",
            "14:42:32 |     dict_file: /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m/model.dict\n",
            "14:42:32 |     dict_include_test: False\n",
            "14:42:32 |     dict_include_valid: False\n",
            "14:42:32 |     dict_initpath: None\n",
            "14:42:32 |     dict_language: english\n",
            "14:42:32 |     dict_loaded: True\n",
            "14:42:32 |     dict_lower: True\n",
            "14:42:32 |     dict_max_ngram_size: -1\n",
            "14:42:32 |     dict_maxexs: -1\n",
            "14:42:32 |     dict_maxtokens: -1\n",
            "14:42:32 |     dict_minfreq: 0\n",
            "14:42:32 |     dict_nulltoken: __null__\n",
            "14:42:32 |     dict_starttoken: __start__\n",
            "14:42:32 |     dict_textfields: text,labels\n",
            "14:42:32 |     dict_tokenizer: bpe\n",
            "14:42:32 |     dict_unktoken: __unk__\n",
            "14:42:32 |     display_add_fields: \n",
            "14:42:32 |     display_examples: False\n",
            "14:42:32 |     download_path: None\n",
            "14:42:32 |     dropout: 0.0\n",
            "14:42:32 |     dynamic_batching: full\n",
            "14:42:32 |     embedding_projection: random\n",
            "14:42:32 |     embedding_size: 512\n",
            "14:42:32 |     embedding_type: random\n",
            "14:42:32 |     embeddings_scale: True\n",
            "14:42:32 |     eval_batchsize: None\n",
            "14:42:32 |     eval_dynamic_batching: None\n",
            "14:42:32 |     evaltask: None\n",
            "14:42:32 |     ffn_size: 2048\n",
            "14:42:32 |     final_extra_opt: \n",
            "14:42:32 |     force_fp16_tokens: True\n",
            "14:42:32 |     fp16: True\n",
            "14:42:32 |     fp16_impl: mem_efficient\n",
            "14:42:32 |     gpu: -1\n",
            "14:42:32 |     gradient_clip: 0.1\n",
            "14:42:32 |     hide_labels: False\n",
            "14:42:32 |     history_add_global_end_token: None\n",
            "14:42:32 |     history_reversed: False\n",
            "14:42:32 |     history_size: -1\n",
            "14:42:32 |     image_cropsize: 224\n",
            "14:42:32 |     image_mode: raw\n",
            "14:42:32 |     image_size: 256\n",
            "14:42:32 |     inference: topk\n",
            "14:42:32 |     init_model: zoo:blender/blender_90M/model\n",
            "14:42:32 |     init_opt: None\n",
            "14:42:32 |     interactive_mode: False\n",
            "14:42:32 |     invsqrt_lr_decay_gamma: -1\n",
            "14:42:32 |     is_debug: False\n",
            "14:42:32 |     label_truncate: 128\n",
            "14:42:32 |     learn_positional_embeddings: False\n",
            "14:42:32 |     learningrate: 1e-05\n",
            "14:42:32 |     log_every_n_secs: 60.0\n",
            "14:42:32 |     log_every_n_steps: 50\n",
            "14:42:32 |     log_keep_fields: all\n",
            "14:42:32 |     loglevel: info\n",
            "14:42:32 |     lr_scheduler: reduceonplateau\n",
            "14:42:32 |     lr_scheduler_decay: 0.5\n",
            "14:42:32 |     lr_scheduler_patience: 3\n",
            "14:42:32 |     max_train_steps: -1\n",
            "14:42:32 |     max_train_time: -1\n",
            "14:42:32 |     metrics: default\n",
            "14:42:32 |     model: transformer/generator\n",
            "14:42:32 |     model_file: /content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m/model\n",
            "14:42:32 |     model_parallel: False\n",
            "14:42:32 |     momentum: 0\n",
            "14:42:32 |     multitask_weights: '[1.0, 3.0, 3.0, 3.0]'\n",
            "14:42:32 |     mutators: None\n",
            "14:42:32 |     n_decoder_layers: -1\n",
            "14:42:32 |     n_encoder_layers: -1\n",
            "14:42:32 |     n_heads: 16\n",
            "14:42:32 |     n_layers: 8\n",
            "14:42:32 |     n_positions: 512\n",
            "14:42:32 |     n_segments: 0\n",
            "14:42:32 |     nesterov: True\n",
            "14:42:32 |     no_cuda: False\n",
            "14:42:32 |     num_epochs: 5.0\n",
            "14:42:32 |     num_examples: 20\n",
            "14:42:32 |     num_workers: 0\n",
            "14:42:32 |     nus: [0.7]\n",
            "14:42:32 |     optimizer: mem_eff_adam\n",
            "14:42:32 |     output_scaling: 1.0\n",
            "14:42:32 |     override: \"{'task': 'french_blended_skill_talk', 'datatype': 'test', 'model_file': '/content/drive/MyDrive/colabs/blender-models/finetuned-multitask-90m/model', 'num_examples': '20', 'skip_generation': False, 'beam_block_ngram': 2, 'beam_context_block_ngram': 3, 'beam_length_penalty': 1.0, 'beam_min_length': 10, 'beam_size': 20, 'inference': 'topk', 'temperature': 0.5, 'topk': 20, 'topp': 0.9}\"\n",
            "14:42:32 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "14:42:32 |     person_tokens: False\n",
            "14:42:32 |     rank_candidates: False\n",
            "14:42:32 |     relu_dropout: 0.0\n",
            "14:42:32 |     save_after_valid: False\n",
            "14:42:32 |     save_every_n_secs: -1\n",
            "14:42:32 |     save_format: conversations\n",
            "14:42:32 |     share_word_embeddings: True\n",
            "14:42:32 |     short_final_eval: False\n",
            "14:42:32 |     skip_generation: False\n",
            "14:42:32 |     special_tok_lst: None\n",
            "14:42:32 |     split_lines: False\n",
            "14:42:32 |     starttime: May24_08-21\n",
            "14:42:32 |     task: french_blended_skill_talk\n",
            "14:42:32 |     temperature: 0.5\n",
            "14:42:32 |     tensorboard_log: False\n",
            "14:42:32 |     tensorboard_logdir: None\n",
            "14:42:32 |     text_truncate: 512\n",
            "14:42:32 |     topk: 20\n",
            "14:42:32 |     topp: 0.9\n",
            "14:42:32 |     truncate: -1\n",
            "14:42:32 |     update_freq: 1\n",
            "14:42:32 |     use_reply: label\n",
            "14:42:32 |     validation_cutoff: 1.0\n",
            "14:42:32 |     validation_every_n_epochs: 0.25\n",
            "14:42:32 |     validation_every_n_secs: -1\n",
            "14:42:32 |     validation_every_n_steps: -1\n",
            "14:42:32 |     validation_max_exs: -1\n",
            "14:42:32 |     validation_metric: ppl\n",
            "14:42:32 |     validation_metric_mode: min\n",
            "14:42:32 |     validation_patience: 10\n",
            "14:42:32 |     validation_share_agent: False\n",
            "14:42:32 |     variant: xlm\n",
            "14:42:32 |     verbose: False\n",
            "14:42:32 |     wandb_entity: None\n",
            "14:42:32 |     wandb_log: False\n",
            "14:42:32 |     wandb_name: None\n",
            "14:42:32 |     wandb_project: None\n",
            "14:42:32 |     warmup_rate: 0.0001\n",
            "14:42:32 |     warmup_updates: 100\n",
            "14:42:32 |     weight_decay: None\n",
            "14:42:32 |     world_logs: \n",
            "\u001b[1;31m- - - NEW EPISODE: french_blended_skill_talk- - -\u001b[0;0m\n",
            "\u001b[0mWow, je ne suis jamais timide. Vous êtes anxieux ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Oui. Je finis par transpirer et rougir et j'ai l'impression que je vais vomir.\u001b[0;0m\n",
            "\u001b[0;95m     model: oui , je suis un peu ennuyeux .\u001b[0;0m\n",
            "\u001b[0met pourquoi ça ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Je pense que c'est parce que dans ma tête, je pense que tout le monde me juge. Je commence à transpirer et j'ai mal au ventre.\u001b[0;0m\n",
            "\u001b[0;95m     model: c ' est un peu effra__unk__ mais je suis content que tout soit bien .\u001b[0;0m\n",
            "\u001b[0mintéressant mais je sais ce que tu ressens, surtout le fait que les gens te disent que c'est dans ta tête. \u001b[0;0m\n",
            "\u001b[1;94m    labels: Je n'ai pas vraiment de gens qui me le disent dans ma tête, plutôt dans mon dos.\u001b[0;0m\n",
            "\u001b[0;95m     model: merci . je suis d ' accord .\u001b[0;0m\n",
            "\u001b[0mDang, c'est vrai. Mais je comprends aussi ça. J'ai des gens qui parlent dans mon dos à cause de certaines choses auxquelles je crois. \u001b[0;0m\n",
            "\u001b[1;94m    labels: Moi aussi ! En quoi crois-tu ? Je crois aux dragons... Je viens de finir de regarder Game of Thrones. Mec, ces choses sont géniales\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis désolé d ' entendre ça .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: french_blended_skill_talk- - -\u001b[0;0m\n",
            "\u001b[0mOui. Je finis par transpirer et rougir et j'ai l'impression que je vais vomir.\u001b[0;0m\n",
            "\u001b[1;94m    labels: et pourquoi ça ?\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis désolé d ' entendre ça .\u001b[0;0m\n",
            "\u001b[0mJe pense que c'est parce que dans ma tête, je pense que tout le monde me juge. Je commence à transpirer et j'ai mal au ventre.\u001b[0;0m\n",
            "\u001b[1;94m    labels: intéressant mais je sais ce que tu ressens, surtout le fait que les gens te disent que c'est dans ta tête. \u001b[0;0m\n",
            "\u001b[0;95m     model: je suis désolé d ' entendre ça .\u001b[0;0m\n",
            "\u001b[0mJe n'ai pas vraiment de gens qui me le disent dans ma tête, plutôt dans mon dos.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Dang, c'est vrai. Mais je comprends aussi ça. J'ai des gens qui parlent dans mon dos à cause de certaines choses auxquelles je crois. \u001b[0;0m\n",
            "\u001b[0;95m     model: je suis désolé que tu aies dû faire ça .\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: french_blended_skill_talk- - -\u001b[0;0m\n",
            "\u001b[0mMa tortue s'est enfuie aujourd'hui.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Oh mon dieu. Vous vous êtes disputés ?\u001b[0;0m\n",
            "\u001b[0;95m     model: oh non ! je suis désolé d ' entendre ça .\u001b[0;0m\n",
            "\u001b[0mC'est drôle. Non. Je le laisse errer dans la maison.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Que mange ta tortue ?  Est-il difficile de s'occuper d'une tortue ?\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis désolé d ' entendre ça .\u001b[0;0m\n",
            "\u001b[0mIl mange des insectes, des feuilles et des graines de tournesol. C'est facile. Il n'a pas besoin de marcher et le nettoyage est simple. Avez-vous des animaux domestiques ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Non, pas pour le moment.  J'ai 3 filles et elles ont assez d'ennuis ! LOL\u001b[0;0m\n",
            "\u001b[0;95m     model: non , je ne le fais pas . je suis un homme de compagnie .\u001b[0;0m\n",
            "\u001b[0mFélicitations. Venez-vous d'une grande famille ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Je n'en ai pas, juste 2 frères et sœurs.  Mais ma femme voulait beaucoup d'enfants. Donc, voilà.\u001b[0;0m\n",
            "\u001b[0;95m     model: oui , je l ' ai fait . et vous ?\u001b[0;0m\n",
            "\u001b[0mWow. cool. Combien de fois utilisez-vous des ordinateurs ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: J'utilise un Mac pour mon travail - je suis professeur de musique.  Je le trouve très utile.  Et vous ?  Utilisez-vous beaucoup l'ordinateur ?\u001b[0;0m\n",
            "\u001b[0;95m     model: 3 et 4 . ils sont très amusants .\u001b[0;0m\n",
            "\u001b[0mSouvent. Je les utilise au travail pour le montage. Je suis à la recherche d'un moyen de diffuser des vidéos ou des films depuis la bibliothèque locale.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Stream de la bibliothèque - maintenant, cela semble intéressant. Ma femme et moi faisons de la plongée sous-marine et nous voulons commencer à filmer sous l'eau. Vous avez déjà essayé ?\u001b[0;0m\n",
            "\u001b[0;95m     model: oh , c ' était sympa de te parler . je ne suis pas un enfant de compagnie .\u001b[0;0m\n",
            "\u001b[0mNon, mais j'ai fait du snorkeling.\u001b[0;0m\n",
            "\u001b[1;94m    labels: C'est cool aussi. C'est comme ça qu'on a commencé.  J'ai vu beaucoup de Tortues !  LOL\u001b[0;0m\n",
            "\u001b[0;95m     model: oh , ça a l ' air très amusant !\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: french_blended_skill_talk- - -\u001b[0;0m\n",
            "\u001b[0mOh mon dieu. Vous vous êtes disputés ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: C'est drôle. Non. Je le laisse errer dans la maison.\u001b[0;0m\n",
            "\u001b[0;95m     model: non , je suis en train de trouver un nouveau travail .\u001b[0;0m\n",
            "\u001b[0mQue mange ta tortue ?  Est-il difficile de s'occuper d'une tortue ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Il mange des insectes, des feuilles et des graines de tournesol. C'est facile. Il n'a pas besoin de marcher et le nettoyage est simple. Avez-vous des animaux domestiques ?\u001b[0;0m\n",
            "\u001b[0;95m     model: je ne sais pas . je suis désolé .\u001b[0;0m\n",
            "\u001b[0mNon, pas pour le moment.  J'ai 3 filles et elles ont assez d'ennuis ! LOL\u001b[0;0m\n",
            "\u001b[1;94m    labels: Félicitations. Venez-vous d'une grande famille ?\u001b[0;0m\n",
            "\u001b[0;95m     model: oh , je suis désolé d ' entendre ça .\u001b[0;0m\n",
            "\u001b[0mJe n'en ai pas, juste 2 frères et sœurs.  Mais ma femme voulait beaucoup d'enfants. Donc, voilà.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Wow. cool. Combien de fois utilisez-vous des ordinateurs ?\u001b[0;0m\n",
            "\u001b[0;95m     model: je suis désolé . vous avez un enfant ?\u001b[0;0m\n",
            "\u001b[0mJ'utilise un Mac pour mon travail - je suis professeur de musique.  Je le trouve très utile.  Et vous ?  Utilisez-vous beaucoup l'ordinateur ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Souvent. Je les utilise au travail pour le montage. Je suis à la recherche d'un moyen de diffuser des vidéos ou des films depuis la bibliothèque locale.\u001b[0;0m\n",
            "\u001b[0;95m     model: je travaille dans un magasin de compagnie .\u001b[0;0m\n",
            "\u001b[0mStream de la bibliothèque - maintenant, cela semble intéressant. Ma femme et moi faisons de la plongée sous-marine et nous voulons commencer à filmer sous l'eau. Vous avez déjà essayé ?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Non, mais j'ai fait du snorkeling.\u001b[0;0m\n",
            "\u001b[0;95m     model: non , je ne l ' ai pas fait .\u001b[0;0m\n"
          ]
        }
      ],
      "source": [
        "from parlai.scripts.display_model import DisplayModel\n",
        "DisplayModel.main(\n",
        "    task='french_blended_skill_talk',\n",
        "    # task='fromfile:parlaiformat', \n",
        "    # fromfile_datapath= f'{data_path}data',\n",
        "    # fromfile_datatype_extension=True,\n",
        "    datatype= \"test\",\n",
        "\n",
        "    model_file= f'{finetuned_model_path}model',\n",
        "    num_examples=20,\n",
        "    skip_generation=False,\n",
        "\n",
        "    # the result of grid search on 400M model and BST dataset when inference=topk\n",
        "    beam_block_ngram= 2,\n",
        "\tbeam_context_block_ngram= 3,\n",
        "\tbeam_length_penalty= 1,\n",
        "\tbeam_min_length= 10,\n",
        "\tbeam_size= 20,\n",
        "\tinference= \"topk\",\n",
        "\ttemperature= 0.5,\n",
        "\ttopk= 20,\n",
        "\ttopp= 0.9\n",
        "\n",
        "    # # Farnaz sent me\n",
        "    # beam_block_ngram= 3,\n",
        "    # beam_context_block_ngram= 3,\n",
        "    # beam_min_length= 20, \n",
        "    # beam_size= 10,\n",
        "    # inference =  'topk',  \n",
        "    # topk=20, \n",
        "    # temperature = 0.5, \n",
        "    # beam_length_penalty=0.8\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Display Data"
      ],
      "metadata": {
        "id": "qtVH017ArR6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from parlai.scripts.display_data import DisplayData\n",
        "DisplayData.main(\n",
        "    task='blended_skill_talk',\n",
        "    num_examples=50\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yswHy-pbrUTn",
        "outputId": "a4b882a9-e5bc-428d-ce51-f8094e5cb55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09:51:55 | Opt:\n",
            "09:51:55 |     allow_missing_init_opts: False\n",
            "09:51:55 |     batchsize: 1\n",
            "09:51:55 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "09:51:55 |     datatype: train:ordered\n",
            "09:51:55 |     dict_class: None\n",
            "09:51:55 |     display_add_fields: \n",
            "09:51:55 |     download_path: None\n",
            "09:51:55 |     dynamic_batching: None\n",
            "09:51:55 |     hide_labels: False\n",
            "09:51:55 |     ignore_agent_reply: True\n",
            "09:51:55 |     image_cropsize: 224\n",
            "09:51:55 |     image_mode: raw\n",
            "09:51:55 |     image_size: 256\n",
            "09:51:55 |     init_model: None\n",
            "09:51:55 |     init_opt: None\n",
            "09:51:55 |     is_debug: False\n",
            "09:51:55 |     loglevel: info\n",
            "09:51:55 |     max_display_len: 1000\n",
            "09:51:55 |     model: None\n",
            "09:51:55 |     model_file: None\n",
            "09:51:55 |     multitask_weights: [1]\n",
            "09:51:55 |     mutators: None\n",
            "09:51:55 |     num_examples: 50\n",
            "09:51:55 |     override: \"{'task': 'blended_skill_talk', 'num_examples': 50}\"\n",
            "09:51:55 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "09:51:55 |     starttime: Jun15_09-51\n",
            "09:51:55 |     task: blended_skill_talk\n",
            "09:51:55 |     verbose: False\n",
            "09:51:55 | creating task(s): blended_skill_talk\n",
            "09:51:55 | Loading ParlAI text data: /usr/local/lib/python3.7/dist-packages/data/blended_skill_talk/train.txt\n",
            "\u001b[1;31m- - - NEW EPISODE: blended_skill_talk - - -\u001b[0;0m\n",
            "\u001b[0myour persona: i've 2 kids.\n",
            "your persona: i love flowers.\n",
            "I love live music, that's why I try to go to concerts\n",
            "I do too. Wat do you like?\n",
            "I like acting, I hope to be an actor, what about you?\u001b[0;0m\n",
            "   \u001b[1;94mthat is ok.  have any kids?\u001b[0;0m\n",
            "\u001b[0mNo, but someday.\u001b[0;0m\n",
            "   \u001b[1;94mthat is good. I have 2\u001b[0;0m\n",
            "\u001b[0mAfter I am done with school I plan to have a family.\u001b[0;0m\n",
            "   \u001b[1;94mthat is great! you will be ready\u001b[0;0m\n",
            "\u001b[0mI hope so, how old are your kids?\u001b[0;0m\n",
            "   \u001b[1;94m5 & 7.  they take up a lot of my time\u001b[0;0m\n",
            "\u001b[0mI would imagine. I am sure they a great kids.\u001b[0;0m\n",
            "   \u001b[1;94mluckily, they love flowers just as much as I do.  we spend a lot of time in the garden\u001b[0;0m\n",
            "\u001b[0mI wish I had more time to do stuff like that. Medical school is exhausting. \u001b[0;0m\n",
            "   \u001b[1;94msounds like it. have you gotten any acting jobs, though?\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: blended_skill_talk - - -\u001b[0;0m\n",
            "\u001b[0myour persona: i just bought a new house with my partner.\n",
            "your persona: i like to make my own coffee.\n",
            "Lasagne\n",
            "Oh, I love lasagne. I make my own noodles as well as the sauce. \n",
            "Wow.  That's amazing.  I read where lasagne originated in Italy during the Middle Ages.  \n",
            "Oh really!? That is interesting. I am actually italian myself.\u001b[0;0m\n",
            "   \u001b[1;94mAwesome. Me and my partner just bought a house. I can't wait to cook in my kitchen.\u001b[0;0m\n",
            "\u001b[0mMoving in a new place can be a lot of fun. Are you a good cook?\u001b[0;0m\n",
            "   \u001b[1;94mI like to think so. I love to make coffee for an after dinner treat too.\u001b[0;0m\n",
            "\u001b[0mMmm That sounds delicious right now.\u001b[0;0m\n",
            "   \u001b[1;94mWhat do you like to do?\u001b[0;0m\n",
            "\u001b[0mWell I like tattoos and piercings, I am working on my next one right now.\u001b[0;0m\n",
            "   \u001b[1;94mpiercings are cool . i do not have any tattoos though. Too scared. I want some\u001b[0;0m\n",
            "\u001b[0mWhat would you get?\u001b[0;0m\n",
            "   \u001b[1;94mMaybe something for my kids. I've always wanted an anarchy symbol.\u001b[0;0m\n",
            "\u001b[0mHaha that is a cool idea.\u001b[0;0m\n",
            "   \u001b[1;94mI like to think I'm cool too. Hopefully one day.\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: blended_skill_talk - - -\u001b[0;0m\n",
            "\u001b[0myour persona: my parents were divorced.\n",
            "your persona: i'm a widow.\n",
            "My neighbors dog won't stop barking at me. Ugh!\n",
            "Thats the worst, is it a big dog or little dog? \n",
            "It's a little dog. Why is it the little ones always bark the most?\u001b[0;0m\n",
            "   \u001b[1;94mI believe it is due to their behavior and internal and external stimuli.\u001b[0;0m\n",
            "\u001b[0mI'd like to introduce that dog to my pet snakes. I think they'd eat him though!\u001b[0;0m\n",
            "   \u001b[1;94mOh no! But I think black snakes are good? They eat nasty bugs and rodents!\u001b[0;0m\n",
            "\u001b[0mMy snakes are both pythons. I feed them mice. Do you have any pets?\u001b[0;0m\n",
            "   \u001b[1;94mNo, but I would love to have a cat for it to hunt mice in my house lol\u001b[0;0m\n",
            "\u001b[0mYou have mice running around your house? Yikes! I think I'd rather have the barking dogs than that.\u001b[0;0m\n",
            "   \u001b[1;94mLol, but they do make great companions at times.I give them bread and they leave me alone for the most part. \u001b[0;0m\n",
            "\u001b[0mHave you given them names? If not, maybe we can come up with some.\u001b[0;0m\n",
            "   \u001b[1;94mi just called them all Jerry, Big Jerry, Always hungry Jerry and then there's the Tiny Jerry. \u001b[0;0m\n",
            "\u001b[0mNow you really do need to get a cat and call him Tom.\u001b[0;0m\n",
            "   \u001b[1;94mYep that would completely the collection! I am widow so I need all the companions I can get haha\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: blended_skill_talk - - -\u001b[0;0m\n",
            "\u001b[0myour persona: i have blue eyes and curly brown hair.\n",
            "your persona: i love to snack between meals.\n",
            "I took the train to work the other day and it was so crowded. I was feeling really claustrophobic.\n",
            "I would have been too! Do you always take it to work? \n",
            "yes i do because i do not have a car\u001b[0;0m\n",
            "   \u001b[1;94mif you could have a car what would it be?\u001b[0;0m\n",
            "\u001b[0ma honda because they are affordable and reliable\u001b[0;0m\n",
            "   \u001b[1;94mi love the oscar mier wiener-mobile. it reminds me of snacking when i'm not having a meal. would you drive the oscar meir weiner mobile?\u001b[0;0m\n",
            "\u001b[0mi do not think so, what about you?\u001b[0;0m\n",
            "   \u001b[1;94mi lost my driver's liscense, ufortunately, but i would if i could\u001b[0;0m\n",
            "\u001b[0mhow did you lose it?\u001b[0;0m\n",
            "   \u001b[1;94mi did some bad stuff, but that's not important\u001b[0;0m\n",
            "\u001b[0mim saving up to buy a new camera to take pictures of people who lost their licenses actually\u001b[0;0m\n",
            "   \u001b[1;94mdo you take pictures of people with curly hair like mine?\u001b[0;0m\n",
            "\u001b[0mno, only people with long hair like mine\u001b[0;0m\n",
            "   \u001b[1;94mwell, you got to do you, brother. i'm proud of you anyway!\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: blended_skill_talk - - -\u001b[0;0m\n",
            "\u001b[0myour persona: i always answer my cellphone.\n",
            "your persona: i work in sales.\n",
            "that is good . i'm nursing a cold and vitamin c does nothing lol\n",
            "oh sorry about that . taking lots of fluids ?\n",
            "Yes, thank you. I think I just need some time to make it pass.\u001b[0;0m\n",
            "   \u001b[1;94mShould always be drinking water anyways, your body needs it!\u001b[0;0m\n",
            "\u001b[0mYes it does, especially during summer.\u001b[0;0m\n",
            "   \u001b[1;94mWhat do you do for a living?  I try my best in sales.\u001b[0;0m\n",
            "\u001b[0mI work at a ski resort. I love it!\u001b[0;0m\n",
            "   \u001b[1;94mI heard Mount Tom Ski Area in Holyoke, Mass is a great resort to visit\u001b[0;0m\n",
            "\u001b[0mI have never been but I have heard the same. I love snow and the mountains.\u001b[0;0m\n",
            "   \u001b[1;94mI wish I could enjoy the snow and mountains, I would be afraid I could not answer my cellphone!\u001b[0;0m\n",
            "\u001b[0mHaha, these days it is amazing where you can get cell service.\u001b[0;0m\n",
            "   \u001b[1;94mi agree ! that is the main reason I have a phone !\u001b[0;0m\n",
            "\u001b[0mDo you have any plans this weekend?\u001b[0;0m\n",
            "   \u001b[1;94mNo plans yet, I'm just happy to sleep in for once!\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: blended_skill_talk - - -\u001b[0;0m\n",
            "\u001b[0myour persona: i love to go out to eat with my family.\n",
            "your persona: i like to go to the movies.\n",
            "He's a good worker but not as reliable as I am. He is always calling in or not putting much effort into his work. I feel I should have gotten that position.\n",
            "That's a shame, if that's the case then I agree.\n",
            "Yea, but to be perfectly honest, I actually don't work hard either.\u001b[0;0m\n",
            "   \u001b[1;94moh i see . i am really reliable in my job on other things i am not\u001b[0;0m\n",
            "\u001b[0mWell my problem is that I just never had to really work. I always had money. What things are you not reliable in?\u001b[0;0m\n",
            "   \u001b[1;94mMostly jobs and children.\u001b[0;0m\n",
            "\u001b[0mWhat do you mean children?\u001b[0;0m\n",
            "   \u001b[1;94mThey are food, shelter, child care, health care, transportation, and utilities.\u001b[0;0m\n",
            "\u001b[0mOk, Im pretty confused as to what you mean, but that sounds like a lot.\u001b[0;0m\n",
            "   \u001b[1;94mit is a lot to take care of because kids are a lot of responsibility\u001b[0;0m\n",
            "\u001b[0mI see. Well good luck with that, I wouldn't know because I don't have kids yet.\u001b[0;0m\n",
            "   \u001b[1;94moh well thank you . what else should i know about you ?\u001b[0;0m\n",
            "\u001b[0mWell, Im going through some drama right now with my sister in law, she hates me. \u001b[0;0m\n",
            "   \u001b[1;94mFamily conflict is always hard.  Maybe you should be the bigger man and work for peace \u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: blended_skill_talk - - -\u001b[0;0m\n",
            "\u001b[0myour persona: i work as a teacher and love my job.\n",
            "your persona: i've two dogs who are like my babies.\n",
            "My boss earns way more money than me for less work.\n",
            "That must be so annoying. You should ask for a pay raise.\n",
            "yeah, i think i will!\u001b[0;0m\n",
            "   \u001b[1;94mI love my job as a teacher but would also like to assk for a raise\u001b[0;0m\n",
            "\u001b[0mwho do you ask? aren't teacher salaries decided by some sort of... thing, or whatever? i love my family.\u001b[0;0m\n",
            "   \u001b[1;94mI would ask the school board they base it on how long you've been there and test scores\u001b[0;0m\n",
            "\u001b[0mhow would the principal feel about you going behind his back?\u001b[0;0m\n",
            "   \u001b[1;94mNot sure, I suppose I could sit down and discuss it with him. What kind of work do you do?\u001b[0;0m\n",
            "\u001b[0mi'm a garbage man, although i'm a woman. my boss drives the truck, but i'm more qualified, really.\u001b[0;0m\n",
            "   \u001b[1;94mI've never driven a truck, only small vehicles! How's that working out for you? My two dogs would love to ride along if I did that\u001b[0;0m\n",
            "\u001b[0mdogs would for sure love a big truck full of garbage. i thik i'm the top 20 or so best garbage men in the area\u001b[0;0m\n",
            "   \u001b[1;94moh wow that is impressive . must be an extremely difficult job .\u001b[0;0m\n",
            "\u001b[0mno.literally anyone could do it. you just pick up garbage. it's not as easy as teaching, im sure, buts ittakes no skill\u001b[0;0m\n",
            "   \u001b[1;94mIf you have patience teaching is great but they test your nerves every day\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: blended_skill_talk - - -\u001b[0;0m\n",
            "\u001b[0myour persona: i have woman calling me all the time.\n",
            "your persona: i was once offered to play basketball professionally.\n",
            "I got really joyful when my dad got me my first vehicle. It was just a happy feeling\n",
            "Yeah. I know that feeling., although I had to buy my own.\n",
            "The vehicle was exactly what I wanted, a newer model sports car.\u001b[0;0m\n",
            "   \u001b[1;94mThat was a good choice, What kind of car was it?\u001b[0;0m\n",
            "\u001b[0mA Mustang GT, convertible\u001b[0;0m\n",
            "   \u001b[1;94mNice! Too bad you couldn't get  your hands on a 1963 Mustang II. That's my favorite car.\u001b[0;0m\n",
            "\u001b[0mA few years ago I helped with a restoration on a 67. It was absolutely gorgeous.\u001b[0;0m\n",
            "   \u001b[1;94mThat sounds awesome. Did you restore it with your dad?\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: blended_skill_talk - - -\u001b[0;0m\n",
            "\u001b[0myour persona: dancing is my passion.\n",
            "your persona: i'm terrible at math.\n",
            "Dance\n",
            "I enjoy dance a lot as well, my daughter does tap dancing. What kind of dancing do you like most?\n",
            "I don't have a particular favorite style, but I've always thought tap was the odd one, even though you see it all the time on Broadway.\n",
            "Tap is pretty odd compared to the others. My daughter loves ballet.\u001b[0;0m\n",
            "   \u001b[1;94mi love broadway shows , so this was the closest thing i had .\u001b[0;0m\n",
            "\u001b[0mYea, well keep it up, maybe one day you'll be on broadway.\u001b[0;0m\n",
            "   \u001b[1;94mi hope so. i'm so bad at math. they count 5,6,7,8! at the beginning, and i wish they would stick to smaller numbers\u001b[0;0m\n",
            "\u001b[0mhahah that's funny. I believe in you though, you can overcome that. \u001b[0;0m\n",
            "   \u001b[1;94mit's like a chorus line. the musical with actor michael douglass. have you seen it/\u001b[0;0m\n",
            "\u001b[0mNo I haven't, I don't watch movies very often. Im usually out at clubs people watching.\u001b[0;0m\n",
            "   \u001b[1;94mwhen do you think you'll get a chance to catch up on some film? I love dancing, but when I'm not treading the boards, I love watching tv\u001b[0;0m\n",
            "\u001b[0mProbably not for a while. I just bought a new jaguar and I try to get out and just drive around and show it off as much as possible. \u001b[0;0m\n",
            "   \u001b[1;94mwow, i love animals. What does it eat?\u001b[0;0m\n",
            "09:51:56 | loaded 4819 episodes with a total of 27018 examples\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "blender-90m-400m-multitask-double-sided.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPy8tE5nRfT3AIkJsPy5jS+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}